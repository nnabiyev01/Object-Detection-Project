{"cells":[{"cell_type":"markdown","metadata":{"id":"QUANWN3rpfC9"},"source":["# 0. Setup Paths"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":434,"status":"ok","timestamp":1665214338038,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"146BB11JpfDA"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665214338527,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"42hJEdo_pfDB"},"outputs":[],"source":["CUSTOM_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite' \n","PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n","PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n","TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n","LABEL_MAP_NAME = 'label_map.pbtxt'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665214338983,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"hbPhYVy_pfDB"},"outputs":[],"source":["paths = {\n","    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n","    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n","    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n","    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n","    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n","    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n","    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n","    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n","    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n","    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n","    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n","    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n"," }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VqRgSv7ivkbN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665214339952,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"LwhWZMI0pfDC"},"outputs":[],"source":["files = {\n","    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n","    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n","    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n","}"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1247,"status":"ok","timestamp":1665214341686,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"HR-TfDGrpfDC"},"outputs":[],"source":["for path in paths.values():\n","    if not os.path.exists(path):\n","        if os.name == 'posix':\n","            !mkdir -p {path}\n","        if os.name == 'nt':\n","            !mkdir {path}"]},{"cell_type":"markdown","metadata":{"id":"OLU-rs_ipfDE"},"source":["# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665214343045,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"ch3zMsZV5pxn"},"outputs":[],"source":["# https://www.tensorflow.org/install/source_windows"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665214343513,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"K-Cmz2edpfDE","scrolled":true},"outputs":[],"source":["if os.name=='nt':\n","    !pip install wget\n","    import wget"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23646,"status":"ok","timestamp":1665214367560,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"iA1DIq5OpfDE","outputId":"3158c67f-ee5c-4756-9b5f-71c1bccefeed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Tensorflow/models'...\n","remote: Enumerating objects: 77774, done.\u001b[K\n","remote: Counting objects: 100% (153/153), done.\u001b[K\n","remote: Compressing objects: 100% (83/83), done.\u001b[K\n","remote: Total 77774 (delta 81), reused 126 (delta 70), pack-reused 77621\u001b[K\n","Receiving objects: 100% (77774/77774), 593.44 MiB | 29.25 MiB/s, done.\n","Resolving deltas: 100% (55256/55256), done.\n"]}],"source":["if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n","    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117130,"status":"ok","timestamp":1665214484686,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"rJjMHbnDs3Tv","outputId":"e81cd12c-5b9f-4a6b-ed50-889c4de5df4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/Tensorflow/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.41.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n","\u001b[K     |████████████████████████████████| 10.9 MB 11.0 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 71.0 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.5)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n","\u001b[K     |████████████████████████████████| 25.0 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 7.8 MB/s \n","\u001b[?25hCollecting sacrebleu<=2.2.0\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","\u001b[K     |████████████████████████████████| 116 kB 75.5 MB/s \n","\u001b[?25hCollecting portalocker\n","  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n","Collecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n","\u001b[K     |████████████████████████████████| 238 kB 75.0 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n","\u001b[?25hCollecting immutabledict\n","  Downloading immutabledict-2.2.1-py3-none-any.whl (4.0 kB)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 50.4 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 58.5 MB/s \n","\u001b[?25hCollecting tensorflow-text~=2.10.0\n","  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 53.5 MB/s \n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Collecting tensorflow~=2.10.0\n","  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n","\u001b[?25hCollecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 46.3 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n","Collecting opencv-python-headless==4.5.2.52\n","  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n","\u001b[K     |████████████████████████████████| 38.2 MB 1.2 MB/s \n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 12.1 MB/s \n","\u001b[?25hRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.4)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Collecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (22.9.24)\n","Collecting keras\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 59.1 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Collecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[K     |████████████████████████████████| 438 kB 70.7 MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.49.1)\n","Collecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 46.3 MB/s \n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.27.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n","Collecting orjson<4.0\n","  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 77.9 MB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 58.5 MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[K     |████████████████████████████████| 2.4 MB 51.3 MB/s \n","\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[K     |████████████████████████████████| 508 kB 70.4 MB/s \n","\u001b[?25hCollecting cloudpickle<3,>=2.1.0\n","  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n","\u001b[?25hCollecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n","\u001b[K     |████████████████████████████████| 47 kB 5.6 MB/s \n","\u001b[?25hCollecting docopt\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","Collecting protobuf<4.0.0dev,>=3.12.0\n","  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 64.0 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.9.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.10.0)\n","Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.8.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, docopt, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696220 sha256=6df8c3b967efea6735a3db3019ee39447be8eafda7588e23d2412920756e7c51\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-6ea2vful/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=e008627fd1b5d3f4181d8836d4dfea9f62e8254200194f7c457a0252f9e4edc8\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=4875e9132d307f725cf671e36c339adb1b7bccb4c5299ea3084f2504720464bf\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=a698128d8354aeae6124329988b2d7c328ef8972468c15834a12833cee283f9e\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=b6859eade7c1d8708460a969c0afe7d262c9277291b6628a5b64753747d93d6b\n","  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=6dcc98645134245d66ef65f2014612a0e2ea290cc855ad4fc71f80f208fa8d2a\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 docopt seqeval\n","Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, gast, tensorflow, portalocker, docopt, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, immutabledict, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.9\n","    Uninstalling pyparsing-3.0.9:\n","      Successfully uninstalled pyparsing-3.0.9\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220929150707\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220929150707:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220929150707\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.5.1\n","    Uninstalling dill-0.3.5.1:\n","      Successfully uninstalled dill-0.3.5.1\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.2.0\n","    Uninstalling pymongo-4.2.0:\n","      Successfully uninstalled pymongo-4.2.0\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.6.0.66\n","    Uninstalling opencv-python-headless-4.6.0.66:\n","      Successfully uninstalled opencv-python-headless-4.6.0.66\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.5.0\n","    Uninstalling cloudpickle-1.5.0:\n","      Successfully uninstalled cloudpickle-1.5.0\n","Successfully installed apache-beam-2.41.0 avro-python3-1.10.2 cloudpickle-2.2.0 colorama-0.4.5 dill-0.3.1.1 docopt-0.6.2 fastavro-1.6.1 gast-0.4.0 hdfs-2.7.0 immutabledict-2.2.1 keras-2.10.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.52 orjson-3.8.0 portalocker-2.5.1 proto-plus-1.22.1 protobuf-3.19.6 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.10.0 tensorflow-io-0.27.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.10.0 tf-models-official-2.10.0 tf-slim-1.1.0\n"]}],"source":["# Install Tensorflow Object Detection \n","if os.name=='posix':  \n","    !apt-get install protobuf-compiler\n","    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n","    \n","if os.name=='nt':\n","    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n","    wget.download(url)\n","    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n","    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n","    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n","    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n","    !cd Tensorflow/models/research/slim && pip install -e . "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":847,"status":"ok","timestamp":1665214485526,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"4XWmBJOB5pxy","outputId":"117fac99-b94f-4905-e9c4-51f0cb4f346b","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Package                       Version\n","----------------------------- ----------------------\n","absl-py                       1.2.0\n","aeppl                         0.0.33\n","aesara                        2.7.9\n","aiohttp                       3.8.3\n","aiosignal                     1.2.0\n","alabaster                     0.7.12\n","albumentations                1.2.1\n","altair                        4.2.0\n","apache-beam                   2.41.0\n","appdirs                       1.4.4\n","arviz                         0.12.1\n","astor                         0.8.1\n","astropy                       4.3.1\n","astunparse                    1.6.3\n","async-timeout                 4.0.2\n","asynctest                     0.13.0\n","atari-py                      0.2.9\n","atomicwrites                  1.4.1\n","attrs                         22.1.0\n","audioread                     3.0.0\n","autograd                      1.5\n","avro-python3                  1.10.2\n","Babel                         2.10.3\n","backcall                      0.2.0\n","beautifulsoup4                4.6.3\n","bleach                        5.0.1\n","blis                          0.7.8\n","bokeh                         2.3.3\n","branca                        0.5.0\n","bs4                           0.0.1\n","CacheControl                  0.12.11\n","cached-property               1.5.2\n","cachetools                    4.2.4\n","catalogue                     2.0.8\n","certifi                       2022.9.24\n","cffi                          1.15.1\n","cftime                        1.6.2\n","chardet                       3.0.4\n","charset-normalizer            2.1.1\n","click                         7.1.2\n","clikit                        0.6.2\n","cloudpickle                   2.2.0\n","cmake                         3.22.6\n","cmdstanpy                     1.0.7\n","colorama                      0.4.5\n","colorcet                      3.0.1\n","colorlover                    0.3.0\n","community                     1.0.0b1\n","confection                    0.0.2\n","cons                          0.4.5\n","contextlib2                   0.5.5\n","convertdate                   2.4.0\n","crashtest                     0.3.1\n","crcmod                        1.7\n","cufflinks                     0.17.3\n","cupy-cuda11x                  11.0.0\n","cvxopt                        1.3.0\n","cvxpy                         1.2.1\n","cycler                        0.11.0\n","cymem                         2.0.6\n","Cython                        0.29.32\n","daft                          0.0.4\n","dask                          2022.2.0\n","datascience                   0.17.5\n","debugpy                       1.0.0\n","decorator                     4.4.2\n","defusedxml                    0.7.1\n","descartes                     1.1.0\n","dill                          0.3.1.1\n","distributed                   2022.2.0\n","dlib                          19.24.0\n","dm-tree                       0.1.7\n","docopt                        0.6.2\n","docutils                      0.17.1\n","dopamine-rl                   1.0.5\n","earthengine-api               0.1.326\n","easydict                      1.10\n","ecos                          2.0.10\n","editdistance                  0.5.3\n","en-core-web-sm                3.4.0\n","entrypoints                   0.4\n","ephem                         4.1.3\n","et-xmlfile                    1.1.0\n","etils                         0.8.0\n","etuples                       0.3.8\n","fa2                           0.3.5\n","fastai                        2.7.9\n","fastavro                      1.6.1\n","fastcore                      1.5.27\n","fastdownload                  0.0.7\n","fastdtw                       0.3.4\n","fastjsonschema                2.16.2\n","fastprogress                  1.0.3\n","fastrlock                     0.8\n","feather-format                0.4.1\n","filelock                      3.8.0\n","firebase-admin                4.4.0\n","fix-yahoo-finance             0.0.22\n","Flask                         1.1.4\n","flatbuffers                   22.9.24\n","folium                        0.12.1.post1\n","frozenlist                    1.3.1\n","fsspec                        2022.8.2\n","future                        0.16.0\n","gast                          0.4.0\n","GDAL                          2.2.2\n","gdown                         4.4.0\n","gensim                        3.6.0\n","geographiclib                 1.52\n","geopy                         1.17.0\n","gin-config                    0.5.0\n","glob2                         0.7\n","google                        2.0.3\n","google-api-core               1.31.6\n","google-api-python-client      1.12.11\n","google-auth                   1.35.0\n","google-auth-httplib2          0.0.4\n","google-auth-oauthlib          0.4.6\n","google-cloud-bigquery         1.21.0\n","google-cloud-bigquery-storage 1.1.2\n","google-cloud-core             1.0.3\n","google-cloud-datastore        1.8.0\n","google-cloud-firestore        1.7.0\n","google-cloud-language         1.2.0\n","google-cloud-storage          1.18.1\n","google-cloud-translate        1.5.0\n","google-colab                  1.0.0\n","google-pasta                  0.2.0\n","google-resumable-media        0.4.1\n","googleapis-common-protos      1.56.4\n","googledrivedownloader         0.4\n","graphviz                      0.10.1\n","greenlet                      1.1.3\n","grpcio                        1.49.1\n","gspread                       3.4.2\n","gspread-dataframe             3.0.8\n","gym                           0.25.2\n","gym-notices                   0.0.8\n","h5py                          3.1.0\n","hdfs                          2.7.0\n","HeapDict                      1.0.1\n","hijri-converter               2.2.4\n","holidays                      0.16\n","holoviews                     1.14.9\n","html5lib                      1.0.1\n","httpimport                    0.5.18\n","httplib2                      0.17.4\n","httplib2shim                  0.0.3\n","httpstan                      4.6.1\n","humanize                      0.5.1\n","hyperopt                      0.1.2\n","idna                          2.10\n","imageio                       2.9.0\n","imagesize                     1.4.1\n","imbalanced-learn              0.8.1\n","imblearn                      0.0\n","imgaug                        0.4.0\n","immutabledict                 2.2.1\n","importlib-metadata            5.0.0\n","importlib-resources           5.9.0\n","imutils                       0.5.4\n","inflect                       2.1.0\n","intel-openmp                  2022.2.0\n","intervaltree                  2.1.0\n","ipykernel                     5.3.4\n","ipython                       7.9.0\n","ipython-genutils              0.2.0\n","ipython-sql                   0.3.9\n","ipywidgets                    7.7.1\n","itsdangerous                  1.1.0\n","jax                           0.3.21\n","jaxlib                        0.3.20+cuda11.cudnn805\n","jieba                         0.42.1\n","Jinja2                        2.11.3\n","joblib                        1.2.0\n","jpeg4py                       0.1.4\n","jsonschema                    4.3.3\n","jupyter-client                6.1.12\n","jupyter-console               6.1.0\n","jupyter-core                  4.11.1\n","jupyterlab-widgets            3.0.3\n","kaggle                        1.5.12\n","kapre                         0.3.7\n","keras                         2.10.0\n","Keras-Preprocessing           1.1.2\n","keras-vis                     0.4.1\n","kiwisolver                    1.4.4\n","korean-lunar-calendar         0.3.1\n","langcodes                     3.3.0\n","libclang                      14.0.6\n","librosa                       0.8.1\n","lightgbm                      2.2.3\n","llvmlite                      0.39.1\n","lmdb                          0.99\n","locket                        1.0.0\n","logical-unification           0.4.5\n","LunarCalendar                 0.0.9\n","lvis                          0.5.3\n","lxml                          4.9.1\n","Markdown                      3.4.1\n","MarkupSafe                    2.0.1\n","marshmallow                   3.18.0\n","matplotlib                    3.2.2\n","matplotlib-venn               0.11.7\n","miniKanren                    1.0.3\n","missingno                     0.5.1\n","mistune                       0.8.4\n","mizani                        0.7.3\n","mkl                           2019.0\n","mlxtend                       0.14.0\n","more-itertools                8.14.0\n","moviepy                       0.2.3.5\n","mpmath                        1.2.1\n","msgpack                       1.0.4\n","multidict                     6.0.2\n","multipledispatch              0.6.0\n","multitasking                  0.0.11\n","murmurhash                    1.0.8\n","music21                       5.5.0\n","natsort                       5.5.0\n","nbconvert                     5.6.1\n","nbformat                      5.6.1\n","netCDF4                       1.6.1\n","networkx                      2.6.3\n","nibabel                       3.0.2\n","nltk                          3.7\n","notebook                      5.3.1\n","numba                         0.56.2\n","numexpr                       2.8.3\n","numpy                         1.21.6\n","oauth2client                  4.1.3\n","oauthlib                      3.2.1\n","object-detection              0.1\n","okgrade                       0.4.3\n","opencv-contrib-python         4.6.0.66\n","opencv-python                 4.6.0.66\n","opencv-python-headless        4.5.2.52\n","openpyxl                      3.0.10\n","opt-einsum                    3.3.0\n","orjson                        3.8.0\n","osqp                          0.6.2.post0\n","packaging                     21.3\n","palettable                    3.3.0\n","pandas                        1.3.5\n","pandas-datareader             0.9.0\n","pandas-gbq                    0.13.3\n","pandas-profiling              1.4.1\n","pandocfilters                 1.5.0\n","panel                         0.12.1\n","param                         1.12.2\n","parso                         0.8.3\n","partd                         1.3.0\n","pastel                        0.2.1\n","pathlib                       1.0.1\n","pathy                         0.6.2\n","patsy                         0.5.2\n","pep517                        0.13.0\n","pexpect                       4.8.0\n","pickleshare                   0.7.5\n","Pillow                        7.1.2\n","pip                           21.1.3\n","pip-tools                     6.2.0\n","plotly                        5.5.0\n","plotnine                      0.8.0\n","pluggy                        0.7.1\n","pooch                         1.6.0\n","portalocker                   2.5.1\n","portpicker                    1.3.9\n","prefetch-generator            1.0.1\n","preshed                       3.0.7\n","prettytable                   3.4.1\n","progressbar2                  3.38.0\n","promise                       2.3\n","prompt-toolkit                2.0.10\n","prophet                       1.1.1\n","proto-plus                    1.22.1\n","protobuf                      3.19.6\n","psutil                        5.4.8\n","psycopg2                      2.9.3\n","ptyprocess                    0.7.0\n","py                            1.11.0\n","py-cpuinfo                    8.0.0\n","pyarrow                       6.0.1\n","pyasn1                        0.4.8\n","pyasn1-modules                0.2.8\n","pycocotools                   2.0.5\n","pycparser                     2.21\n","pyct                          0.4.8\n","pydantic                      1.9.2\n","pydata-google-auth            1.4.0\n","pydot                         1.3.0\n","pydot-ng                      2.0.0\n","pydotplus                     2.0.2\n","PyDrive                       1.3.1\n","pyemd                         0.5.1\n","pyerfa                        2.0.0.1\n","Pygments                      2.6.1\n","pygobject                     3.26.1\n","pylev                         1.4.0\n","pymc                          4.1.4\n","PyMeeus                       0.5.11\n","pymongo                       3.12.3\n","pymystem3                     0.2.0\n","PyOpenGL                      3.1.6\n","pyparsing                     2.4.7\n","pyrsistent                    0.18.1\n","pysimdjson                    3.2.0\n","pysndfile                     1.3.8\n","PySocks                       1.7.1\n","pystan                        3.3.0\n","pytest                        3.6.4\n","python-apt                    0.0.0\n","python-chess                  0.23.11\n","python-dateutil               2.8.2\n","python-louvain                0.16\n","python-slugify                6.1.2\n","python-utils                  3.3.3\n","pytz                          2022.4\n","pyviz-comms                   2.2.1\n","PyWavelets                    1.3.0\n","PyYAML                        5.4.1\n","pyzmq                         23.2.1\n","qdldl                         0.1.5.post2\n","qudida                        0.0.4\n","regex                         2022.6.2\n","requests                      2.28.1\n","requests-oauthlib             1.3.1\n","resampy                       0.4.2\n","rpy2                          3.4.5\n","rsa                           4.9\n","sacrebleu                     2.2.0\n","scikit-image                  0.18.3\n","scikit-learn                  1.0.2\n","scipy                         1.7.3\n","screen-resolution-extra       0.0.0\n","scs                           3.2.0\n","seaborn                       0.11.2\n","Send2Trash                    1.8.0\n","sentencepiece                 0.1.97\n","seqeval                       1.2.2\n","setuptools                    57.4.0\n","setuptools-git                1.2\n","Shapely                       1.8.4\n","six                           1.15.0\n","sklearn-pandas                1.8.0\n","smart-open                    5.2.1\n","snowballstemmer               2.2.0\n","sortedcontainers              2.4.0\n","soundfile                     0.11.0\n","spacy                         3.4.1\n","spacy-legacy                  3.0.10\n","spacy-loggers                 1.0.3\n","Sphinx                        1.8.6\n","sphinxcontrib-serializinghtml 1.1.5\n","sphinxcontrib-websupport      1.2.4\n","SQLAlchemy                    1.4.41\n","sqlparse                      0.4.3\n","srsly                         2.4.4\n","statsmodels                   0.12.2\n","sympy                         1.7.1\n","tables                        3.7.0\n","tabulate                      0.8.10\n","tblib                         1.7.0\n","tenacity                      8.1.0\n","tensorboard                   2.10.1\n","tensorboard-data-server       0.6.1\n","tensorboard-plugin-wit        1.8.1\n","tensorflow                    2.10.0\n","tensorflow-addons             0.18.0\n","tensorflow-datasets           4.6.0\n","tensorflow-estimator          2.10.0\n","tensorflow-gcs-config         2.8.0\n","tensorflow-hub                0.12.0\n","tensorflow-io                 0.27.0\n","tensorflow-io-gcs-filesystem  0.27.0\n","tensorflow-metadata           1.10.0\n","tensorflow-model-optimization 0.7.3\n","tensorflow-probability        0.16.0\n","tensorflow-text               2.10.0\n","termcolor                     2.0.1\n","terminado                     0.13.3\n","testpath                      0.6.0\n","text-unidecode                1.3\n","textblob                      0.15.3\n","tf-models-official            2.10.0\n","tf-slim                       1.1.0\n","thinc                         8.1.2\n","threadpoolctl                 3.1.0\n","tifffile                      2021.11.2\n","toml                          0.10.2\n","tomli                         2.0.1\n","toolz                         0.12.0\n","torch                         1.12.1+cu113\n","torchaudio                    0.12.1+cu113\n","torchsummary                  1.5.1\n","torchtext                     0.13.1\n","torchvision                   0.13.1+cu113\n","tornado                       5.1.1\n","tqdm                          4.64.1\n","traitlets                     5.1.1\n","tweepy                        3.10.0\n","typeguard                     2.7.1\n","typer                         0.4.2\n","typing-extensions             4.1.1\n","tzlocal                       1.5.1\n","ujson                         5.5.0\n","uritemplate                   3.0.1\n","urllib3                       1.24.3\n","vega-datasets                 0.9.0\n","wasabi                        0.10.1\n","wcwidth                       0.2.5\n","webargs                       8.2.0\n","webencodings                  0.5.1\n","Werkzeug                      1.0.1\n","wheel                         0.37.1\n","widgetsnbextension            3.6.1\n","wordcloud                     1.8.2.2\n","wrapt                         1.14.1\n","xarray                        0.20.2\n","xarray-einstats               0.2.2\n","xgboost                       0.90\n","xkit                          0.0.0\n","xlrd                          1.1.0\n","xlwt                          1.3.0\n","yarl                          1.8.1\n","yellowbrick                   1.5\n","zict                          2.2.0\n","zipp                          3.8.1\n"]}],"source":["!pip list"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43689,"status":"ok","timestamp":1665214529193,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"ubPyqZTj5pxz","outputId":"6d1acd77-a298-45bd-94b4-cc592be1b316","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-10-08 07:34:45.213222: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-10-08 07:34:45.384440: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-10-08 07:34:46.340397: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-08 07:34:46.340571: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-08 07:34:46.340592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2022-10-08 07:34:48.832699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:34:48.989890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:34:48.990592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","Running tests under Python 3.7.14: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-10-08 07:34:48.999116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-10-08 07:34:48.999393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:34:49.000237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:34:49.001305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:34:50.238708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:34:50.239454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:34:50.240074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:34:50.240646: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-10-08 07:34:50.240699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13735 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","W1008 07:34:50.687143 140491198306176 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.12s\n","I1008 07:34:51.116355 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.12s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.98s\n","I1008 07:34:52.096749 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.98s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.43s\n","I1008 07:34:52.530687 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.43s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.57s\n","I1008 07:34:53.104397 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.57s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.1s\n","I1008 07:34:57.208756 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 4.1s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I1008 07:34:57.222848 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.09s\n","I1008 07:34:57.313961 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n","I1008 07:34:57.343281 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.07s\n","I1008 07:34:57.417591 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.07s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.44s\n","I1008 07:34:57.863797 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.44s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.34s\n","I1008 07:34:58.210193 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.34s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.37s\n","I1008 07:34:58.582591 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.37s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.37s\n","I1008 07:34:58.948819 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.37s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.34s\n","I1008 07:34:59.294625 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.34s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.12s\n","I1008 07:34:59.419768 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I1008 07:35:00.225345 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I1008 07:35:00.225555 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I1008 07:35:00.225661 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I1008 07:35:00.229009 140491198306176 efficientnet_model.py:143] round_filter input=32 output=32\n","I1008 07:35:00.342717 140491198306176 efficientnet_model.py:143] round_filter input=32 output=32\n","I1008 07:35:00.342910 140491198306176 efficientnet_model.py:143] round_filter input=16 output=16\n","I1008 07:35:00.617033 140491198306176 efficientnet_model.py:143] round_filter input=16 output=16\n","I1008 07:35:00.617254 140491198306176 efficientnet_model.py:143] round_filter input=24 output=24\n","I1008 07:35:01.347414 140491198306176 efficientnet_model.py:143] round_filter input=24 output=24\n","I1008 07:35:01.347702 140491198306176 efficientnet_model.py:143] round_filter input=40 output=40\n","I1008 07:35:02.075672 140491198306176 efficientnet_model.py:143] round_filter input=40 output=40\n","I1008 07:35:02.079391 140491198306176 efficientnet_model.py:143] round_filter input=80 output=80\n","I1008 07:35:02.896617 140491198306176 efficientnet_model.py:143] round_filter input=80 output=80\n","I1008 07:35:02.896818 140491198306176 efficientnet_model.py:143] round_filter input=112 output=112\n","I1008 07:35:03.537664 140491198306176 efficientnet_model.py:143] round_filter input=112 output=112\n","I1008 07:35:03.537867 140491198306176 efficientnet_model.py:143] round_filter input=192 output=192\n","I1008 07:35:04.096939 140491198306176 efficientnet_model.py:143] round_filter input=192 output=192\n","I1008 07:35:04.097146 140491198306176 efficientnet_model.py:143] round_filter input=320 output=320\n","I1008 07:35:04.230969 140491198306176 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I1008 07:35:04.291722 140491198306176 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1008 07:35:04.368467 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I1008 07:35:04.368653 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I1008 07:35:04.368748 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I1008 07:35:04.371015 140491198306176 efficientnet_model.py:143] round_filter input=32 output=32\n","I1008 07:35:04.396154 140491198306176 efficientnet_model.py:143] round_filter input=32 output=32\n","I1008 07:35:04.396302 140491198306176 efficientnet_model.py:143] round_filter input=16 output=16\n","I1008 07:35:04.587767 140491198306176 efficientnet_model.py:143] round_filter input=16 output=16\n","I1008 07:35:04.587955 140491198306176 efficientnet_model.py:143] round_filter input=24 output=24\n","I1008 07:35:04.954052 140491198306176 efficientnet_model.py:143] round_filter input=24 output=24\n","I1008 07:35:04.954258 140491198306176 efficientnet_model.py:143] round_filter input=40 output=40\n","I1008 07:35:05.321911 140491198306176 efficientnet_model.py:143] round_filter input=40 output=40\n","I1008 07:35:05.322111 140491198306176 efficientnet_model.py:143] round_filter input=80 output=80\n","I1008 07:35:05.792204 140491198306176 efficientnet_model.py:143] round_filter input=80 output=80\n","I1008 07:35:05.792371 140491198306176 efficientnet_model.py:143] round_filter input=112 output=112\n","I1008 07:35:06.162593 140491198306176 efficientnet_model.py:143] round_filter input=112 output=112\n","I1008 07:35:06.162768 140491198306176 efficientnet_model.py:143] round_filter input=192 output=192\n","I1008 07:35:06.612976 140491198306176 efficientnet_model.py:143] round_filter input=192 output=192\n","I1008 07:35:06.613208 140491198306176 efficientnet_model.py:143] round_filter input=320 output=320\n","I1008 07:35:06.809754 140491198306176 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I1008 07:35:06.846000 140491198306176 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1008 07:35:06.915573 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I1008 07:35:06.915746 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I1008 07:35:06.915855 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I1008 07:35:06.917913 140491198306176 efficientnet_model.py:143] round_filter input=32 output=32\n","I1008 07:35:06.937037 140491198306176 efficientnet_model.py:143] round_filter input=32 output=32\n","I1008 07:35:06.937182 140491198306176 efficientnet_model.py:143] round_filter input=16 output=16\n","I1008 07:35:07.080296 140491198306176 efficientnet_model.py:143] round_filter input=16 output=16\n","I1008 07:35:07.080449 140491198306176 efficientnet_model.py:143] round_filter input=24 output=24\n","I1008 07:35:07.357641 140491198306176 efficientnet_model.py:143] round_filter input=24 output=24\n","I1008 07:35:07.357808 140491198306176 efficientnet_model.py:143] round_filter input=40 output=48\n","I1008 07:35:07.624347 140491198306176 efficientnet_model.py:143] round_filter input=40 output=48\n","I1008 07:35:07.624508 140491198306176 efficientnet_model.py:143] round_filter input=80 output=88\n","I1008 07:35:07.983724 140491198306176 efficientnet_model.py:143] round_filter input=80 output=88\n","I1008 07:35:07.983891 140491198306176 efficientnet_model.py:143] round_filter input=112 output=120\n","I1008 07:35:08.349549 140491198306176 efficientnet_model.py:143] round_filter input=112 output=120\n","I1008 07:35:08.349724 140491198306176 efficientnet_model.py:143] round_filter input=192 output=208\n","I1008 07:35:08.791438 140491198306176 efficientnet_model.py:143] round_filter input=192 output=208\n","I1008 07:35:08.791604 140491198306176 efficientnet_model.py:143] round_filter input=320 output=352\n","I1008 07:35:08.972609 140491198306176 efficientnet_model.py:143] round_filter input=1280 output=1408\n","I1008 07:35:09.010845 140491198306176 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1008 07:35:09.077718 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I1008 07:35:09.077875 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I1008 07:35:09.077956 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I1008 07:35:09.079557 140491198306176 efficientnet_model.py:143] round_filter input=32 output=40\n","I1008 07:35:09.098992 140491198306176 efficientnet_model.py:143] round_filter input=32 output=40\n","I1008 07:35:09.099112 140491198306176 efficientnet_model.py:143] round_filter input=16 output=24\n","I1008 07:35:09.245921 140491198306176 efficientnet_model.py:143] round_filter input=16 output=24\n","I1008 07:35:09.246077 140491198306176 efficientnet_model.py:143] round_filter input=24 output=32\n","I1008 07:35:09.516039 140491198306176 efficientnet_model.py:143] round_filter input=24 output=32\n","I1008 07:35:09.516210 140491198306176 efficientnet_model.py:143] round_filter input=40 output=48\n","I1008 07:35:09.954787 140491198306176 efficientnet_model.py:143] round_filter input=40 output=48\n","I1008 07:35:09.954965 140491198306176 efficientnet_model.py:143] round_filter input=80 output=96\n","I1008 07:35:10.435615 140491198306176 efficientnet_model.py:143] round_filter input=80 output=96\n","I1008 07:35:10.435788 140491198306176 efficientnet_model.py:143] round_filter input=112 output=136\n","I1008 07:35:10.870996 140491198306176 efficientnet_model.py:143] round_filter input=112 output=136\n","I1008 07:35:10.871173 140491198306176 efficientnet_model.py:143] round_filter input=192 output=232\n","I1008 07:35:11.401073 140491198306176 efficientnet_model.py:143] round_filter input=192 output=232\n","I1008 07:35:11.401247 140491198306176 efficientnet_model.py:143] round_filter input=320 output=384\n","I1008 07:35:11.582975 140491198306176 efficientnet_model.py:143] round_filter input=1280 output=1536\n","I1008 07:35:11.621200 140491198306176 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1008 07:35:11.684695 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I1008 07:35:11.684830 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I1008 07:35:11.684909 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I1008 07:35:11.686364 140491198306176 efficientnet_model.py:143] round_filter input=32 output=48\n","I1008 07:35:11.704759 140491198306176 efficientnet_model.py:143] round_filter input=32 output=48\n","I1008 07:35:11.704880 140491198306176 efficientnet_model.py:143] round_filter input=16 output=24\n","I1008 07:35:11.844835 140491198306176 efficientnet_model.py:143] round_filter input=16 output=24\n","I1008 07:35:11.844967 140491198306176 efficientnet_model.py:143] round_filter input=24 output=32\n","I1008 07:35:12.206882 140491198306176 efficientnet_model.py:143] round_filter input=24 output=32\n","I1008 07:35:12.207051 140491198306176 efficientnet_model.py:143] round_filter input=40 output=56\n","I1008 07:35:12.576667 140491198306176 efficientnet_model.py:143] round_filter input=40 output=56\n","I1008 07:35:12.576836 140491198306176 efficientnet_model.py:143] round_filter input=80 output=112\n","I1008 07:35:13.119358 140491198306176 efficientnet_model.py:143] round_filter input=80 output=112\n","I1008 07:35:13.119527 140491198306176 efficientnet_model.py:143] round_filter input=112 output=160\n","I1008 07:35:13.651724 140491198306176 efficientnet_model.py:143] round_filter input=112 output=160\n","I1008 07:35:13.651891 140491198306176 efficientnet_model.py:143] round_filter input=192 output=272\n","I1008 07:35:14.354136 140491198306176 efficientnet_model.py:143] round_filter input=192 output=272\n","I1008 07:35:14.354329 140491198306176 efficientnet_model.py:143] round_filter input=320 output=448\n","I1008 07:35:14.539327 140491198306176 efficientnet_model.py:143] round_filter input=1280 output=1792\n","I1008 07:35:14.574621 140491198306176 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1008 07:35:14.648795 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I1008 07:35:14.648934 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I1008 07:35:14.649005 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I1008 07:35:14.650474 140491198306176 efficientnet_model.py:143] round_filter input=32 output=48\n","I1008 07:35:14.668143 140491198306176 efficientnet_model.py:143] round_filter input=32 output=48\n","I1008 07:35:14.668294 140491198306176 efficientnet_model.py:143] round_filter input=16 output=24\n","I1008 07:35:14.869412 140491198306176 efficientnet_model.py:143] round_filter input=16 output=24\n","I1008 07:35:14.869570 140491198306176 efficientnet_model.py:143] round_filter input=24 output=40\n","I1008 07:35:15.291984 140491198306176 efficientnet_model.py:143] round_filter input=24 output=40\n","I1008 07:35:15.292146 140491198306176 efficientnet_model.py:143] round_filter input=40 output=64\n","I1008 07:35:15.728192 140491198306176 efficientnet_model.py:143] round_filter input=40 output=64\n","I1008 07:35:15.728349 140491198306176 efficientnet_model.py:143] round_filter input=80 output=128\n","I1008 07:35:16.564294 140491198306176 efficientnet_model.py:143] round_filter input=80 output=128\n","I1008 07:35:16.564467 140491198306176 efficientnet_model.py:143] round_filter input=112 output=176\n","I1008 07:35:17.185601 140491198306176 efficientnet_model.py:143] round_filter input=112 output=176\n","I1008 07:35:17.185771 140491198306176 efficientnet_model.py:143] round_filter input=192 output=304\n","I1008 07:35:17.985189 140491198306176 efficientnet_model.py:143] round_filter input=192 output=304\n","I1008 07:35:17.985353 140491198306176 efficientnet_model.py:143] round_filter input=320 output=512\n","I1008 07:35:18.259121 140491198306176 efficientnet_model.py:143] round_filter input=1280 output=2048\n","I1008 07:35:18.295885 140491198306176 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1008 07:35:18.377136 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I1008 07:35:18.377300 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I1008 07:35:18.377376 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I1008 07:35:18.378841 140491198306176 efficientnet_model.py:143] round_filter input=32 output=56\n","I1008 07:35:18.398445 140491198306176 efficientnet_model.py:143] round_filter input=32 output=56\n","I1008 07:35:18.398575 140491198306176 efficientnet_model.py:143] round_filter input=16 output=32\n","I1008 07:35:18.618511 140491198306176 efficientnet_model.py:143] round_filter input=16 output=32\n","I1008 07:35:18.618674 140491198306176 efficientnet_model.py:143] round_filter input=24 output=40\n","I1008 07:35:19.131603 140491198306176 efficientnet_model.py:143] round_filter input=24 output=40\n","I1008 07:35:19.131811 140491198306176 efficientnet_model.py:143] round_filter input=40 output=72\n","I1008 07:35:19.658220 140491198306176 efficientnet_model.py:143] round_filter input=40 output=72\n","I1008 07:35:19.658381 140491198306176 efficientnet_model.py:143] round_filter input=80 output=144\n","I1008 07:35:20.363614 140491198306176 efficientnet_model.py:143] round_filter input=80 output=144\n","I1008 07:35:20.363779 140491198306176 efficientnet_model.py:143] round_filter input=112 output=200\n","I1008 07:35:21.063420 140491198306176 efficientnet_model.py:143] round_filter input=112 output=200\n","I1008 07:35:21.063602 140491198306176 efficientnet_model.py:143] round_filter input=192 output=344\n","I1008 07:35:22.006988 140491198306176 efficientnet_model.py:143] round_filter input=192 output=344\n","I1008 07:35:22.007173 140491198306176 efficientnet_model.py:143] round_filter input=320 output=576\n","I1008 07:35:22.266458 140491198306176 efficientnet_model.py:143] round_filter input=1280 output=2304\n","I1008 07:35:22.299218 140491198306176 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1008 07:35:22.396517 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I1008 07:35:22.396669 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I1008 07:35:22.396740 140491198306176 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I1008 07:35:22.398269 140491198306176 efficientnet_model.py:143] round_filter input=32 output=64\n","I1008 07:35:22.417352 140491198306176 efficientnet_model.py:143] round_filter input=32 output=64\n","I1008 07:35:22.417461 140491198306176 efficientnet_model.py:143] round_filter input=16 output=32\n","I1008 07:35:22.702083 140491198306176 efficientnet_model.py:143] round_filter input=16 output=32\n","I1008 07:35:22.702260 140491198306176 efficientnet_model.py:143] round_filter input=24 output=48\n","I1008 07:35:23.539942 140491198306176 efficientnet_model.py:143] round_filter input=24 output=48\n","I1008 07:35:23.540112 140491198306176 efficientnet_model.py:143] round_filter input=40 output=80\n","I1008 07:35:24.148677 140491198306176 efficientnet_model.py:143] round_filter input=40 output=80\n","I1008 07:35:24.148856 140491198306176 efficientnet_model.py:143] round_filter input=80 output=160\n","I1008 07:35:25.013859 140491198306176 efficientnet_model.py:143] round_filter input=80 output=160\n","I1008 07:35:25.014035 140491198306176 efficientnet_model.py:143] round_filter input=112 output=224\n","I1008 07:35:25.898835 140491198306176 efficientnet_model.py:143] round_filter input=112 output=224\n","I1008 07:35:25.899006 140491198306176 efficientnet_model.py:143] round_filter input=192 output=384\n","I1008 07:35:27.034987 140491198306176 efficientnet_model.py:143] round_filter input=192 output=384\n","I1008 07:35:27.035188 140491198306176 efficientnet_model.py:143] round_filter input=320 output=640\n","I1008 07:35:27.393196 140491198306176 efficientnet_model.py:143] round_filter input=1280 output=2560\n","I1008 07:35:27.437642 140491198306176 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.12s\n","I1008 07:35:27.544132 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.12s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I1008 07:35:27.569487 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I1008 07:35:27.571148 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I1008 07:35:27.571656 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I1008 07:35:27.573064 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I1008 07:35:27.574569 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I1008 07:35:27.574998 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I1008 07:35:27.575921 140491198306176 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 38.581s\n","\n","OK (skipped=1)\n"]}],"source":["VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n","# Verify Installation\n","!python {VERIFICATION_SCRIPT}"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1665214529193,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"DMCZp4jJ5px2"},"outputs":[],"source":["import object_detection"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":630,"status":"ok","timestamp":1665214529810,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"csofht2npfDE","outputId":"7c2c1fee-a5a4-4412-ac01-0513dfde4637"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-10-08 07:35:29--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.142.128, 2607:f8b0:400e:c08::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.142.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20518283 (20M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n","\n","ssd_mobilenet_v2_fp 100%[===================>]  19.57M   120MB/s    in 0.2s    \n","\n","2022-10-08 07:35:29 (120 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n","\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"]}],"source":["if os.name =='posix':\n","    !wget {PRETRAINED_MODEL_URL}\n","    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n","if os.name == 'nt':\n","    wget.download(PRETRAINED_MODEL_URL)\n","    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"]},{"cell_type":"markdown","metadata":{"id":"M5KJTnkfpfDC"},"source":["# 2. Create Label Map"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1665214529812,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"p1BVDWo7pfDC"},"outputs":[],"source":["labels = [{'name':'object', 'id':1}]\n","\n","with open(files['LABELMAP'], 'w') as f:\n","    for label in labels:\n","        f.write('item { \\n')\n","        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n","        f.write('\\tid:{}\\n'.format(label['id']))\n","        f.write('}\\n')"]},{"cell_type":"markdown","metadata":{"id":"C88zyVELpfDC"},"source":["# 3. Create TF records"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28178,"status":"ok","timestamp":1665214557982,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"HvnVNQF6KKvV","outputId":"0f22b778-2c02-47df-d6f9-36eee65ce87f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5702,"status":"ok","timestamp":1665214563677,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"kvf5WccwrFGq","outputId":"b197fc2f-b767-4808-d52b-edef8c47158e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /content/drive/MyDrive/inventory_images.zip\n","   creating: inventory_images/\n","   creating: inventory_images/test/\n","  inflating: inventory_images/test/test_0.jpg  \n","  inflating: inventory_images/test/test_1.jpg  \n","  inflating: inventory_images/test/test_10.jpg  \n","  inflating: inventory_images/test/test_11.jpg  \n","  inflating: inventory_images/test/test_12.jpg  \n","  inflating: inventory_images/test/test_13.jpg  \n","  inflating: inventory_images/test/test_14.jpg  \n","  inflating: inventory_images/test/test_15.jpg  \n","  inflating: inventory_images/test/test_16.jpg  \n","  inflating: inventory_images/test/test_17.jpg  \n","  inflating: inventory_images/test/test_18.jpg  \n","  inflating: inventory_images/test/test_19.jpg  \n","  inflating: inventory_images/test/test_2.jpg  \n","  inflating: inventory_images/test/test_20.jpg  \n","  inflating: inventory_images/test/test_21.jpg  \n","  inflating: inventory_images/test/test_22.jpg  \n","  inflating: inventory_images/test/test_23.jpg  \n","  inflating: inventory_images/test/test_24.jpg  \n","  inflating: inventory_images/test/test_25.jpg  \n","  inflating: inventory_images/test/test_26.jpg  \n","  inflating: inventory_images/test/test_27.jpg  \n","  inflating: inventory_images/test/test_28.jpg  \n","  inflating: inventory_images/test/test_29.jpg  \n","  inflating: inventory_images/test/test_3.jpg  \n","  inflating: inventory_images/test/test_30.jpg  \n","  inflating: inventory_images/test/test_31.jpg  \n","  inflating: inventory_images/test/test_32.jpg  \n","  inflating: inventory_images/test/test_33.jpg  \n","  inflating: inventory_images/test/test_34.jpg  \n","  inflating: inventory_images/test/test_35.jpg  \n","  inflating: inventory_images/test/test_4.jpg  \n","  inflating: inventory_images/test/test_5.jpg  \n","  inflating: inventory_images/test/test_6.jpg  \n","  inflating: inventory_images/test/test_7.jpg  \n","  inflating: inventory_images/test/test_8.jpg  \n","  inflating: inventory_images/test/test_9.jpg  \n","   creating: inventory_images/train/\n","  inflating: inventory_images/train/train_0.jpg  \n","  inflating: inventory_images/train/train_1.jpg  \n","  inflating: inventory_images/train/train_10.jpg  \n","  inflating: inventory_images/train/train_100.jpg  \n","  inflating: inventory_images/train/train_101.jpg  \n","  inflating: inventory_images/train/train_102.jpg  \n","  inflating: inventory_images/train/train_103.jpg  \n","  inflating: inventory_images/train/train_104.jpg  \n","  inflating: inventory_images/train/train_105.jpg  \n","  inflating: inventory_images/train/train_106.jpg  \n","  inflating: inventory_images/train/train_107.jpg  \n","  inflating: inventory_images/train/train_108.jpg  \n","  inflating: inventory_images/train/train_109.jpg  \n","  inflating: inventory_images/train/train_11.jpg  \n","  inflating: inventory_images/train/train_110.jpg  \n","  inflating: inventory_images/train/train_111.jpg  \n","  inflating: inventory_images/train/train_112.jpg  \n","  inflating: inventory_images/train/train_113.jpg  \n","  inflating: inventory_images/train/train_114.jpg  \n","  inflating: inventory_images/train/train_115.jpg  \n","  inflating: inventory_images/train/train_116.jpg  \n","  inflating: inventory_images/train/train_117.jpg  \n","  inflating: inventory_images/train/train_118.jpg  \n","  inflating: inventory_images/train/train_119.jpg  \n","  inflating: inventory_images/train/train_12.jpg  \n","  inflating: inventory_images/train/train_120.jpg  \n","  inflating: inventory_images/train/train_121.jpg  \n","  inflating: inventory_images/train/train_122.jpg  \n","  inflating: inventory_images/train/train_123.jpg  \n","  inflating: inventory_images/train/train_124.jpg  \n","  inflating: inventory_images/train/train_125.jpg  \n","  inflating: inventory_images/train/train_126.jpg  \n","  inflating: inventory_images/train/train_127.jpg  \n","  inflating: inventory_images/train/train_128.jpg  \n","  inflating: inventory_images/train/train_129.jpg  \n","  inflating: inventory_images/train/train_13.jpg  \n","  inflating: inventory_images/train/train_130.jpg  \n","  inflating: inventory_images/train/train_131.jpg  \n","  inflating: inventory_images/train/train_132.jpg  \n","  inflating: inventory_images/train/train_133.jpg  \n","  inflating: inventory_images/train/train_134.jpg  \n","  inflating: inventory_images/train/train_135.jpg  \n","  inflating: inventory_images/train/train_136.jpg  \n","  inflating: inventory_images/train/train_137.jpg  \n","  inflating: inventory_images/train/train_138.jpg  \n","  inflating: inventory_images/train/train_139.jpg  \n","  inflating: inventory_images/train/train_14.jpg  \n","  inflating: inventory_images/train/train_140.jpg  \n","  inflating: inventory_images/train/train_141.jpg  \n","  inflating: inventory_images/train/train_142.jpg  \n","  inflating: inventory_images/train/train_143.jpg  \n","  inflating: inventory_images/train/train_144.jpg  \n","  inflating: inventory_images/train/train_145.jpg  \n","  inflating: inventory_images/train/train_146.jpg  \n","  inflating: inventory_images/train/train_147.jpg  \n","  inflating: inventory_images/train/train_148.jpg  \n","  inflating: inventory_images/train/train_149.jpg  \n","  inflating: inventory_images/train/train_15.jpg  \n","  inflating: inventory_images/train/train_150.jpg  \n","  inflating: inventory_images/train/train_151.jpg  \n","  inflating: inventory_images/train/train_152.jpg  \n","  inflating: inventory_images/train/train_153.jpg  \n","  inflating: inventory_images/train/train_154.jpg  \n","  inflating: inventory_images/train/train_155.jpg  \n","  inflating: inventory_images/train/train_156.jpg  \n","  inflating: inventory_images/train/train_157.jpg  \n","  inflating: inventory_images/train/train_158.jpg  \n","  inflating: inventory_images/train/train_159.jpg  \n","  inflating: inventory_images/train/train_16.jpg  \n","  inflating: inventory_images/train/train_160.jpg  \n","  inflating: inventory_images/train/train_161.jpg  \n","  inflating: inventory_images/train/train_162.jpg  \n","  inflating: inventory_images/train/train_163.jpg  \n","  inflating: inventory_images/train/train_164.jpg  \n","  inflating: inventory_images/train/train_165.jpg  \n","  inflating: inventory_images/train/train_166.jpg  \n","  inflating: inventory_images/train/train_167.jpg  \n","  inflating: inventory_images/train/train_168.jpg  \n","  inflating: inventory_images/train/train_169.jpg  \n","  inflating: inventory_images/train/train_17.jpg  \n","  inflating: inventory_images/train/train_170.jpg  \n","  inflating: inventory_images/train/train_171.jpg  \n","  inflating: inventory_images/train/train_172.jpg  \n","  inflating: inventory_images/train/train_173.jpg  \n","  inflating: inventory_images/train/train_174.jpg  \n","  inflating: inventory_images/train/train_175.jpg  \n","  inflating: inventory_images/train/train_176.jpg  \n","  inflating: inventory_images/train/train_177.jpg  \n","  inflating: inventory_images/train/train_178.jpg  \n","  inflating: inventory_images/train/train_179.jpg  \n","  inflating: inventory_images/train/train_18.jpg  \n","  inflating: inventory_images/train/train_180.jpg  \n","  inflating: inventory_images/train/train_181.jpg  \n","  inflating: inventory_images/train/train_182.jpg  \n","  inflating: inventory_images/train/train_183.jpg  \n","  inflating: inventory_images/train/train_184.jpg  \n","  inflating: inventory_images/train/train_185.jpg  \n","  inflating: inventory_images/train/train_186.jpg  \n","  inflating: inventory_images/train/train_187.jpg  \n","  inflating: inventory_images/train/train_188.jpg  \n","  inflating: inventory_images/train/train_189.jpg  \n","  inflating: inventory_images/train/train_19.jpg  \n","  inflating: inventory_images/train/train_190.jpg  \n","  inflating: inventory_images/train/train_191.jpg  \n","  inflating: inventory_images/train/train_192.jpg  \n","  inflating: inventory_images/train/train_193.jpg  \n","  inflating: inventory_images/train/train_194.jpg  \n","  inflating: inventory_images/train/train_195.jpg  \n","  inflating: inventory_images/train/train_196.jpg  \n","  inflating: inventory_images/train/train_197.jpg  \n","  inflating: inventory_images/train/train_198.jpg  \n","  inflating: inventory_images/train/train_199.jpg  \n","  inflating: inventory_images/train/train_2.jpg  \n","  inflating: inventory_images/train/train_20.jpg  \n","  inflating: inventory_images/train/train_200.jpg  \n","  inflating: inventory_images/train/train_22.jpg  \n","  inflating: inventory_images/train/train_23.jpg  \n","  inflating: inventory_images/train/train_24.jpg  \n","  inflating: inventory_images/train/train_25.jpg  \n","  inflating: inventory_images/train/train_26.jpg  \n","  inflating: inventory_images/train/train_27.jpg  \n","  inflating: inventory_images/train/train_28.jpg  \n","  inflating: inventory_images/train/train_29.jpg  \n","  inflating: inventory_images/train/train_3.jpg  \n","  inflating: inventory_images/train/train_30.jpg  \n","  inflating: inventory_images/train/train_31.jpg  \n","  inflating: inventory_images/train/train_32.jpg  \n","  inflating: inventory_images/train/train_33.jpg  \n","  inflating: inventory_images/train/train_34.jpg  \n","  inflating: inventory_images/train/train_35.jpg  \n","  inflating: inventory_images/train/train_36.jpg  \n","  inflating: inventory_images/train/train_37.jpg  \n","  inflating: inventory_images/train/train_38.jpg  \n","  inflating: inventory_images/train/train_39.jpg  \n","  inflating: inventory_images/train/train_4.jpg  \n","  inflating: inventory_images/train/train_41.jpg  \n","  inflating: inventory_images/train/train_42.jpg  \n","  inflating: inventory_images/train/train_43.jpg  \n","  inflating: inventory_images/train/train_44.jpg  \n","  inflating: inventory_images/train/train_45.jpg  \n","  inflating: inventory_images/train/train_46.jpg  \n","  inflating: inventory_images/train/train_47.jpg  \n","  inflating: inventory_images/train/train_48.jpg  \n","  inflating: inventory_images/train/train_49.jpg  \n","  inflating: inventory_images/train/train_5.jpg  \n","  inflating: inventory_images/train/train_50.jpg  \n","  inflating: inventory_images/train/train_51.jpg  \n","  inflating: inventory_images/train/train_52.jpg  \n","  inflating: inventory_images/train/train_53.jpg  \n","  inflating: inventory_images/train/train_54.jpg  \n","  inflating: inventory_images/train/train_55.jpg  \n","  inflating: inventory_images/train/train_56.jpg  \n","  inflating: inventory_images/train/train_57.jpg  \n","  inflating: inventory_images/train/train_58.jpg  \n","  inflating: inventory_images/train/train_59.jpg  \n","  inflating: inventory_images/train/train_6.jpg  \n","  inflating: inventory_images/train/train_60.jpg  \n","  inflating: inventory_images/train/train_61.jpg  \n","  inflating: inventory_images/train/train_62.jpg  \n","  inflating: inventory_images/train/train_63.jpg  \n","  inflating: inventory_images/train/train_64.jpg  \n","  inflating: inventory_images/train/train_65.jpg  \n","  inflating: inventory_images/train/train_66.jpg  \n","  inflating: inventory_images/train/train_67.jpg  \n","  inflating: inventory_images/train/train_68.jpg  \n","  inflating: inventory_images/train/train_69.jpg  \n","  inflating: inventory_images/train/train_7.jpg  \n","  inflating: inventory_images/train/train_70.jpg  \n","  inflating: inventory_images/train/train_71.jpg  \n","  inflating: inventory_images/train/train_72.jpg  \n","  inflating: inventory_images/train/train_73.jpg  \n","  inflating: inventory_images/train/train_74.jpg  \n","  inflating: inventory_images/train/train_75.jpg  \n","  inflating: inventory_images/train/train_76.jpg  \n","  inflating: inventory_images/train/train_77.jpg  \n","  inflating: inventory_images/train/train_78.jpg  \n","  inflating: inventory_images/train/train_79.jpg  \n","  inflating: inventory_images/train/train_8.jpg  \n","  inflating: inventory_images/train/train_80.jpg  \n","  inflating: inventory_images/train/train_81.jpg  \n","  inflating: inventory_images/train/train_82.jpg  \n","  inflating: inventory_images/train/train_83.jpg  \n","  inflating: inventory_images/train/train_84.jpg  \n","  inflating: inventory_images/train/train_85.jpg  \n","  inflating: inventory_images/train/train_86.jpg  \n","  inflating: inventory_images/train/train_87.jpg  \n","  inflating: inventory_images/train/train_88.jpg  \n","  inflating: inventory_images/train/train_89.jpg  \n","  inflating: inventory_images/train/train_9.jpg  \n","  inflating: inventory_images/train/train_90.jpg  \n","  inflating: inventory_images/train/train_91.jpg  \n","  inflating: inventory_images/train/train_92.jpg  \n","  inflating: inventory_images/train/train_93.jpg  \n","  inflating: inventory_images/train/train_94.jpg  \n","  inflating: inventory_images/train/train_95.jpg  \n","  inflating: inventory_images/train/train_96.jpg  \n","  inflating: inventory_images/train/train_97.jpg  \n","  inflating: inventory_images/train/train_98.jpg  \n","  inflating: inventory_images/train/train_99.jpg  \n","   creating: inventory_images/val/\n","  inflating: inventory_images/val/val_0.jpg  \n","  inflating: inventory_images/val/val_1.jpg  \n","  inflating: inventory_images/val/val_10.jpg  \n","  inflating: inventory_images/val/val_11.jpg  \n","  inflating: inventory_images/val/val_12.jpg  \n","  inflating: inventory_images/val/val_13.jpg  \n","  inflating: inventory_images/val/val_14.jpg  \n","  inflating: inventory_images/val/val_15.jpg  \n","  inflating: inventory_images/val/val_16.jpg  \n","  inflating: inventory_images/val/val_17.jpg  \n","  inflating: inventory_images/val/val_18.jpg  \n","  inflating: inventory_images/val/val_19.jpg  \n","  inflating: inventory_images/val/val_2.jpg  \n","  inflating: inventory_images/val/val_20.jpg  \n","  inflating: inventory_images/val/val_21.jpg  \n","  inflating: inventory_images/val/val_22.jpg  \n","  inflating: inventory_images/val/val_23.jpg  \n","  inflating: inventory_images/val/val_24.jpg  \n","  inflating: inventory_images/val/val_25.jpg  \n","  inflating: inventory_images/val/val_26.jpg  \n","  inflating: inventory_images/val/val_27.jpg  \n","  inflating: inventory_images/val/val_28.jpg  \n","  inflating: inventory_images/val/val_29.jpg  \n","  inflating: inventory_images/val/val_3.jpg  \n","  inflating: inventory_images/val/val_30.jpg  \n","  inflating: inventory_images/val/val_31.jpg  \n","  inflating: inventory_images/val/val_32.jpg  \n","  inflating: inventory_images/val/val_33.jpg  \n","  inflating: inventory_images/val/val_34.jpg  \n","  inflating: inventory_images/val/val_35.jpg  \n","  inflating: inventory_images/val/val_36.jpg  \n","  inflating: inventory_images/val/val_37.jpg  \n","  inflating: inventory_images/val/val_38.jpg  \n","  inflating: inventory_images/val/val_39.jpg  \n","  inflating: inventory_images/val/val_4.jpg  \n","  inflating: inventory_images/val/val_40.jpg  \n","  inflating: inventory_images/val/val_41.jpg  \n","  inflating: inventory_images/val/val_42.jpg  \n","  inflating: inventory_images/val/val_43.jpg  \n","  inflating: inventory_images/val/val_44.jpg  \n","  inflating: inventory_images/val/val_45.jpg  \n","  inflating: inventory_images/val/val_46.jpg  \n","  inflating: inventory_images/val/val_47.jpg  \n","  inflating: inventory_images/val/val_48.jpg  \n","  inflating: inventory_images/val/val_49.jpg  \n","  inflating: inventory_images/val/val_5.jpg  \n","  inflating: inventory_images/val/val_50.jpg  \n","  inflating: inventory_images/val/val_51.jpg  \n","  inflating: inventory_images/val/val_52.jpg  \n","  inflating: inventory_images/val/val_53.jpg  \n","  inflating: inventory_images/val/val_54.jpg  \n","  inflating: inventory_images/val/val_55.jpg  \n","  inflating: inventory_images/val/val_56.jpg  \n","  inflating: inventory_images/val/val_57.jpg  \n","  inflating: inventory_images/val/val_58.jpg  \n","  inflating: inventory_images/val/val_59.jpg  \n","  inflating: inventory_images/val/val_6.jpg  \n","  inflating: inventory_images/val/val_60.jpg  \n","  inflating: inventory_images/val/val_61.jpg  \n","  inflating: inventory_images/val/val_62.jpg  \n","  inflating: inventory_images/val/val_63.jpg  \n","  inflating: inventory_images/val/val_64.jpg  \n","  inflating: inventory_images/val/val_65.jpg  \n","  inflating: inventory_images/val/val_66.jpg  \n","  inflating: inventory_images/val/val_67.jpg  \n","  inflating: inventory_images/val/val_68.jpg  \n","  inflating: inventory_images/val/val_69.jpg  \n","  inflating: inventory_images/val/val_7.jpg  \n","  inflating: inventory_images/val/val_70.jpg  \n","  inflating: inventory_images/val/val_71.jpg  \n","  inflating: inventory_images/val/val_72.jpg  \n","  inflating: inventory_images/val/val_73.jpg  \n","  inflating: inventory_images/val/val_74.jpg  \n","  inflating: inventory_images/val/val_75.jpg  \n","  inflating: inventory_images/val/val_8.jpg  \n","  inflating: inventory_images/val/val_9.jpg  \n","   creating: annotations/\n","  inflating: annotations/test_labels.csv  \n","  inflating: annotations/train_labels.csv  \n","  inflating: annotations/val_labels.csv  \n"]}],"source":["# OPTIONAL IF RUNNING ON COLAB\n","!unzip \"/content/drive/MyDrive/inventory_images.zip\""]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665212682786,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"KWpb_BVUpfDD"},"outputs":[],"source":["if not os.path.exists(files['TF_RECORD_SCRIPT']):\n","    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5064,"status":"ok","timestamp":1665214568715,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"rl7retgQ4oh2","outputId":"c1d5b308-1612-417f-d41b-a16351423011"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-10-08 07:36:03.931196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-10-08 07:36:04.108185: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-10-08 07:36:04.775137: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-08 07:36:04.775254: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-08 07:36:04.775275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2022-10-08 07:36:06.141468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:36:06.162241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:36:06.162893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","Successfully created the TFRecords: /content/Tensorflow/workspace/annotations/train.record\n"]}],"source":["!python /content/Tensorflow/scripts/generate_tfrecord.py --csv_input=/content/annotations/train_labels.csv  --output_path=/content/Tensorflow/workspace/annotations/train.record --image_dir=/content/inventory_images/train"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3315,"status":"ok","timestamp":1665214572013,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"yv9Zesa0Leyk","outputId":"38eb3b0a-52fc-4a68-ee33-34579afbe0ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-10-08 07:36:09.101821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-10-08 07:36:09.271690: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-10-08 07:36:09.941079: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-08 07:36:09.941204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-08 07:36:09.941226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2022-10-08 07:36:11.326449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:36:11.333721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-10-08 07:36:11.334367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","Successfully created the TFRecords: /content/Tensorflow/workspace/annotations/test.record\n"]}],"source":["!python /content/Tensorflow/scripts/generate_tfrecord.py --csv_input=/content/annotations/test_labels.csv  --output_path=/content/Tensorflow/workspace/annotations/test.record --image_dir=/content/inventory_images/test"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3294,"status":"ok","timestamp":1665213254754,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"wwFjeLN45px5","outputId":"dcbaf151-c137-4e81-c1b2-4b13c8789c5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (2022.4)\n"]}],"source":["!pip install pytz"]},{"cell_type":"markdown","metadata":{"id":"qT4QU7pLpfDE"},"source":["# 4. Copy Model Config to Training Folder"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":411,"status":"ok","timestamp":1665214610136,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"cOjuTFbwpfDF"},"outputs":[],"source":["if os.name =='posix':\n","    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n","if os.name == 'nt':\n","    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"]},{"cell_type":"markdown","metadata":{"id":"Ga8gpNslpfDF"},"source":["# 5. Update Config For Transfer Learning"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":2432,"status":"ok","timestamp":1665214613148,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"Z9hRrO_ppfDF"},"outputs":[],"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665214613149,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"c2A0mn4ipfDF"},"outputs":[],"source":["config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1665214613150,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"uQA13-afpfDF","outputId":"75f80a0d-fb1d-4b44-bdea-67b0ca6909ee"},"outputs":[{"data":{"text/plain":["{'model': ssd {\n","   num_classes: 90\n","   image_resizer {\n","     fixed_shape_resizer {\n","       height: 640\n","       width: 640\n","     }\n","   }\n","   feature_extractor {\n","     type: \"ssd_mobilenet_v2_fpn_keras\"\n","     depth_multiplier: 1.0\n","     min_depth: 16\n","     conv_hyperparams {\n","       regularizer {\n","         l2_regularizer {\n","           weight: 3.9999998989515007e-05\n","         }\n","       }\n","       initializer {\n","         random_normal_initializer {\n","           mean: 0.0\n","           stddev: 0.009999999776482582\n","         }\n","       }\n","       activation: RELU_6\n","       batch_norm {\n","         decay: 0.996999979019165\n","         scale: true\n","         epsilon: 0.0010000000474974513\n","       }\n","     }\n","     use_depthwise: true\n","     override_base_feature_extractor_hyperparams: true\n","     fpn {\n","       min_level: 3\n","       max_level: 7\n","       additional_layer_depth: 128\n","     }\n","   }\n","   box_coder {\n","     faster_rcnn_box_coder {\n","       y_scale: 10.0\n","       x_scale: 10.0\n","       height_scale: 5.0\n","       width_scale: 5.0\n","     }\n","   }\n","   matcher {\n","     argmax_matcher {\n","       matched_threshold: 0.5\n","       unmatched_threshold: 0.5\n","       ignore_thresholds: false\n","       negatives_lower_than_unmatched: true\n","       force_match_for_each_row: true\n","       use_matmul_gather: true\n","     }\n","   }\n","   similarity_calculator {\n","     iou_similarity {\n","     }\n","   }\n","   box_predictor {\n","     weight_shared_convolutional_box_predictor {\n","       conv_hyperparams {\n","         regularizer {\n","           l2_regularizer {\n","             weight: 3.9999998989515007e-05\n","           }\n","         }\n","         initializer {\n","           random_normal_initializer {\n","             mean: 0.0\n","             stddev: 0.009999999776482582\n","           }\n","         }\n","         activation: RELU_6\n","         batch_norm {\n","           decay: 0.996999979019165\n","           scale: true\n","           epsilon: 0.0010000000474974513\n","         }\n","       }\n","       depth: 128\n","       num_layers_before_predictor: 4\n","       kernel_size: 3\n","       class_prediction_bias_init: -4.599999904632568\n","       share_prediction_tower: true\n","       use_depthwise: true\n","     }\n","   }\n","   anchor_generator {\n","     multiscale_anchor_generator {\n","       min_level: 3\n","       max_level: 7\n","       anchor_scale: 4.0\n","       aspect_ratios: 1.0\n","       aspect_ratios: 2.0\n","       aspect_ratios: 0.5\n","       scales_per_octave: 2\n","     }\n","   }\n","   post_processing {\n","     batch_non_max_suppression {\n","       score_threshold: 9.99999993922529e-09\n","       iou_threshold: 0.6000000238418579\n","       max_detections_per_class: 100\n","       max_total_detections: 100\n","       use_static_shapes: false\n","     }\n","     score_converter: SIGMOID\n","   }\n","   normalize_loss_by_num_matches: true\n","   loss {\n","     localization_loss {\n","       weighted_smooth_l1 {\n","       }\n","     }\n","     classification_loss {\n","       weighted_sigmoid_focal {\n","         gamma: 2.0\n","         alpha: 0.25\n","       }\n","     }\n","     classification_weight: 1.0\n","     localization_weight: 1.0\n","   }\n","   encode_background_as_zeros: true\n","   normalize_loc_loss_by_codesize: true\n","   inplace_batchnorm_update: true\n","   freeze_batchnorm: false\n"," }, 'train_config': batch_size: 128\n"," data_augmentation_options {\n","   random_horizontal_flip {\n","   }\n"," }\n"," data_augmentation_options {\n","   random_crop_image {\n","     min_object_covered: 0.0\n","     min_aspect_ratio: 0.75\n","     max_aspect_ratio: 3.0\n","     min_area: 0.75\n","     max_area: 1.0\n","     overlap_thresh: 0.0\n","   }\n"," }\n"," sync_replicas: true\n"," optimizer {\n","   momentum_optimizer {\n","     learning_rate {\n","       cosine_decay_learning_rate {\n","         learning_rate_base: 0.07999999821186066\n","         total_steps: 50000\n","         warmup_learning_rate: 0.026666000485420227\n","         warmup_steps: 1000\n","       }\n","     }\n","     momentum_optimizer_value: 0.8999999761581421\n","   }\n","   use_moving_average: false\n"," }\n"," fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n"," num_steps: 50000\n"," startup_delay_steps: 0.0\n"," replicas_to_aggregate: 8\n"," max_number_of_boxes: 100\n"," unpad_groundtruth_tensors: false\n"," fine_tune_checkpoint_type: \"classification\"\n"," fine_tune_checkpoint_version: V2, 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }, 'eval_config': metrics_set: \"coco_detection_metrics\"\n"," use_moving_averages: false, 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }\n"," ], 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["config"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665214613766,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"9vK5lotDpfDF"},"outputs":[],"source":["pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline_config)  "]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":411,"status":"ok","timestamp":1665214623163,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"rP43Ph0JpfDG"},"outputs":[],"source":["pipeline_config.model.ssd.num_classes = 1\n","pipeline_config.train_config.batch_size = 4\n","pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n","pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n","pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n","pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665214627039,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"oJvfgwWqpfDG"},"outputs":[],"source":["config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n","    f.write(config_text)   "]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665214627528,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"0DA052bTB4wh","outputId":"cbd11a9d-a4a0-4181-d0c4-086e85fbe595"},"outputs":[{"name":"stdout","output_type":"stream","text":["model {\n","  ssd {\n","    num_classes: 1\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 640\n","        width: 640\n","      }\n","    }\n","    feature_extractor {\n","      type: \"ssd_mobilenet_v2_fpn_keras\"\n","      depth_multiplier: 1.0\n","      min_depth: 16\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 4e-05\n","          }\n","        }\n","        initializer {\n","          random_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.01\n","          }\n","        }\n","        activation: RELU_6\n","        batch_norm {\n","          decay: 0.997\n","          scale: true\n","          epsilon: 0.001\n","        }\n","      }\n","      use_depthwise: true\n","      override_base_feature_extractor_hyperparams: true\n","      fpn {\n","        min_level: 3\n","        max_level: 7\n","        additional_layer_depth: 128\n","      }\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 4e-05\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.01\n","            }\n","          }\n","          activation: RELU_6\n","          batch_norm {\n","            decay: 0.997\n","            scale: true\n","            epsilon: 0.001\n","          }\n","        }\n","        depth: 128\n","        num_layers_before_predictor: 4\n","        kernel_size: 3\n","        class_prediction_bias_init: -4.6\n","        share_prediction_tower: true\n","        use_depthwise: true\n","      }\n","    }\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        scales_per_octave: 2\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-08\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","        use_static_shapes: false\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 2.0\n","          alpha: 0.25\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","  }\n","}\n","train_config {\n","  batch_size: 4\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_crop_image {\n","      min_object_covered: 0.0\n","      min_aspect_ratio: 0.75\n","      max_aspect_ratio: 3.0\n","      min_area: 0.75\n","      max_area: 1.0\n","      overlap_thresh: 0.0\n","    }\n","  }\n","  sync_replicas: true\n","  optimizer {\n","    momentum_optimizer {\n","      learning_rate {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 0.08\n","          total_steps: 50000\n","          warmup_learning_rate: 0.026666\n","          warmup_steps: 1000\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n","  num_steps: 50000\n","  startup_delay_steps: 0.0\n","  replicas_to_aggregate: 8\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","  fine_tune_checkpoint_type: \"detection\"\n","  fine_tune_checkpoint_version: V2\n","}\n","train_input_reader {\n","  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"Tensorflow/workspace/annotations/train.record\"\n","  }\n","}\n","eval_config {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","}\n","eval_input_reader {\n","  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"Tensorflow/workspace/annotations/test.record\"\n","  }\n","}\n","\n"]}],"source":["print(config_text)"]},{"cell_type":"markdown","metadata":{"id":"Zr3ON7xMpfDG"},"source":["# 6. Train the model"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665214629344,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"B-Y2UQmQpfDG"},"outputs":[],"source":["TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665214631150,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"jMP2XDfQpfDH"},"outputs":[],"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1665214632372,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"A4OXXi-ApfDH","outputId":"1d1c2d75-f327-4125-dc23-ed89df43fc67"},"outputs":[{"name":"stdout","output_type":"stream","text":["python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/pipeline.config --num_train_steps=5000\n"]}],"source":["print(command)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54620,"status":"ok","timestamp":1665214688145,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"FGfahCn-Ogmj","outputId":"b66f9c7a-7530-4667-e949-e68351b5a1a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following packages will be REMOVED:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be DOWNGRADED:\n","  libcudnn8\n","0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 10 not upgraded.\n","Need to get 430 MB of archives.\n","After this operation, 1,392 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n","Fetched 430 MB in 7s (62.6 MB/s)\n","(Reading database ... 123934 files and directories currently installed.)\n","Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n","update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n","\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.1.1.33-1+cuda11.2 to 8.1.0.77-1+cuda11.2\n","(Reading database ... 123911 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n","Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.1.1.33-1+cuda11.2) ...\n","Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"]}],"source":["!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2140819,"status":"ok","timestamp":1665216828944,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"i3ZsJR-qpfDH","outputId":"6f5900f5-0cda-4346-f8b2-aae01bb595b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-10-08 07:38:08.401513: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-10-08 07:38:09.163704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-08 07:38:09.163813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-08 07:38:09.163833: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2022-10-08 07:38:12.605313: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I1008 07:38:12.629062 139898126976896 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: 5000\n","I1008 07:38:12.634365 139898126976896 config_util.py:552] Maybe overwriting train_steps: 5000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1008 07:38:12.634547 139898126976896 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W1008 07:38:12.662666 139898126976896 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n","I1008 07:38:12.670894 139898126976896 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n","I1008 07:38:12.671258 139898126976896 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1008 07:38:12.671368 139898126976896 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1008 07:38:12.671446 139898126976896 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W1008 07:38:12.678223 139898126976896 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1008 07:38:12.696066 139898126976896 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1008 07:38:19.337201 139898126976896 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W1008 07:38:22.165737 139898126976896 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1008 07:38:23.760585 139898126976896 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2022-10-08 07:38:28.269224: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 23970816 exceeds 10% of free system memory.\n","2022-10-08 07:38:28.328602: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29203200 exceeds 10% of free system memory.\n","2022-10-08 07:38:28.329021: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 23970816 exceeds 10% of free system memory.\n","2022-10-08 07:38:28.398070: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 23970816 exceeds 10% of free system memory.\n","2022-10-08 07:38:28.467963: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29203200 exceeds 10% of free system memory.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.735047 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.737832 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.740454 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.741488 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.744834 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.745857 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.749207 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.750245 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.752760 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1008 07:38:56.753845 139898126976896 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W1008 07:38:57.816892 139893678249728 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 100 per-step time 0.750s\n","I1008 07:40:12.564589 139898126976896 model_lib_v2.py:707] Step 100 per-step time 0.750s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2526369,\n"," 'Loss/localization_loss': 0.32185903,\n"," 'Loss/regularization_loss': 0.1513126,\n"," 'Loss/total_loss': 0.7258085,\n"," 'learning_rate': 0.0319994}\n","I1008 07:40:12.565202 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.2526369,\n"," 'Loss/localization_loss': 0.32185903,\n"," 'Loss/regularization_loss': 0.1513126,\n"," 'Loss/total_loss': 0.7258085,\n"," 'learning_rate': 0.0319994}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 200 per-step time 0.400s\n","I1008 07:40:52.496868 139898126976896 model_lib_v2.py:707] Step 200 per-step time 0.400s\n","INFO:tensorflow:{'Loss/classification_loss': 0.27408487,\n"," 'Loss/localization_loss': 0.31286186,\n"," 'Loss/regularization_loss': 0.15101452,\n"," 'Loss/total_loss': 0.73796123,\n"," 'learning_rate': 0.0373328}\n","I1008 07:40:52.497241 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.27408487,\n"," 'Loss/localization_loss': 0.31286186,\n"," 'Loss/regularization_loss': 0.15101452,\n"," 'Loss/total_loss': 0.73796123,\n"," 'learning_rate': 0.0373328}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 300 per-step time 0.436s\n","I1008 07:41:36.108761 139898126976896 model_lib_v2.py:707] Step 300 per-step time 0.436s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1972282,\n"," 'Loss/localization_loss': 0.18083116,\n"," 'Loss/regularization_loss': 0.15070549,\n"," 'Loss/total_loss': 0.52876484,\n"," 'learning_rate': 0.0426662}\n","I1008 07:41:36.109256 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.1972282,\n"," 'Loss/localization_loss': 0.18083116,\n"," 'Loss/regularization_loss': 0.15070549,\n"," 'Loss/total_loss': 0.52876484,\n"," 'learning_rate': 0.0426662}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 400 per-step time 0.403s\n","I1008 07:42:16.374745 139898126976896 model_lib_v2.py:707] Step 400 per-step time 0.403s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22629276,\n"," 'Loss/localization_loss': 0.22382253,\n"," 'Loss/regularization_loss': 0.15035446,\n"," 'Loss/total_loss': 0.60046977,\n"," 'learning_rate': 0.047999598}\n","I1008 07:42:16.375100 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.22629276,\n"," 'Loss/localization_loss': 0.22382253,\n"," 'Loss/regularization_loss': 0.15035446,\n"," 'Loss/total_loss': 0.60046977,\n"," 'learning_rate': 0.047999598}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 500 per-step time 0.408s\n","I1008 07:42:57.199335 139898126976896 model_lib_v2.py:707] Step 500 per-step time 0.408s\n","INFO:tensorflow:{'Loss/classification_loss': 0.24520744,\n"," 'Loss/localization_loss': 0.21666577,\n"," 'Loss/regularization_loss': 0.15000775,\n"," 'Loss/total_loss': 0.611881,\n"," 'learning_rate': 0.053333}\n","I1008 07:42:57.204234 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.24520744,\n"," 'Loss/localization_loss': 0.21666577,\n"," 'Loss/regularization_loss': 0.15000775,\n"," 'Loss/total_loss': 0.611881,\n"," 'learning_rate': 0.053333}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 600 per-step time 0.437s\n","I1008 07:43:40.947642 139898126976896 model_lib_v2.py:707] Step 600 per-step time 0.437s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22513631,\n"," 'Loss/localization_loss': 0.21678942,\n"," 'Loss/regularization_loss': 0.14965345,\n"," 'Loss/total_loss': 0.5915792,\n"," 'learning_rate': 0.0586664}\n","I1008 07:43:40.948050 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.22513631,\n"," 'Loss/localization_loss': 0.21678942,\n"," 'Loss/regularization_loss': 0.14965345,\n"," 'Loss/total_loss': 0.5915792,\n"," 'learning_rate': 0.0586664}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 700 per-step time 0.400s\n","I1008 07:44:20.944915 139898126976896 model_lib_v2.py:707] Step 700 per-step time 0.400s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18917626,\n"," 'Loss/localization_loss': 0.1543941,\n"," 'Loss/regularization_loss': 0.14930663,\n"," 'Loss/total_loss': 0.49287698,\n"," 'learning_rate': 0.0639998}\n","I1008 07:44:20.945348 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.18917626,\n"," 'Loss/localization_loss': 0.1543941,\n"," 'Loss/regularization_loss': 0.14930663,\n"," 'Loss/total_loss': 0.49287698,\n"," 'learning_rate': 0.0639998}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 800 per-step time 0.394s\n","I1008 07:45:00.385935 139898126976896 model_lib_v2.py:707] Step 800 per-step time 0.394s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18675375,\n"," 'Loss/localization_loss': 0.14911291,\n"," 'Loss/regularization_loss': 0.14892828,\n"," 'Loss/total_loss': 0.48479494,\n"," 'learning_rate': 0.069333196}\n","I1008 07:45:00.386309 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.18675375,\n"," 'Loss/localization_loss': 0.14911291,\n"," 'Loss/regularization_loss': 0.14892828,\n"," 'Loss/total_loss': 0.48479494,\n"," 'learning_rate': 0.069333196}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 900 per-step time 0.448s\n","I1008 07:45:45.222570 139898126976896 model_lib_v2.py:707] Step 900 per-step time 0.448s\n","INFO:tensorflow:{'Loss/classification_loss': 0.22203736,\n"," 'Loss/localization_loss': 0.17301838,\n"," 'Loss/regularization_loss': 0.14850987,\n"," 'Loss/total_loss': 0.54356563,\n"," 'learning_rate': 0.074666604}\n","I1008 07:45:45.222987 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.22203736,\n"," 'Loss/localization_loss': 0.17301838,\n"," 'Loss/regularization_loss': 0.14850987,\n"," 'Loss/total_loss': 0.54356563,\n"," 'learning_rate': 0.074666604}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 1000 per-step time 0.387s\n","I1008 07:46:23.958340 139898126976896 model_lib_v2.py:707] Step 1000 per-step time 0.387s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21025935,\n"," 'Loss/localization_loss': 0.17370003,\n"," 'Loss/regularization_loss': 0.1481548,\n"," 'Loss/total_loss': 0.53211415,\n"," 'learning_rate': 0.08}\n","I1008 07:46:23.958708 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.21025935,\n"," 'Loss/localization_loss': 0.17370003,\n"," 'Loss/regularization_loss': 0.1481548,\n"," 'Loss/total_loss': 0.53211415,\n"," 'learning_rate': 0.08}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 1100 per-step time 0.411s\n","I1008 07:47:05.025523 139898126976896 model_lib_v2.py:707] Step 1100 per-step time 0.411s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21503071,\n"," 'Loss/localization_loss': 0.19383168,\n"," 'Loss/regularization_loss': 0.14771286,\n"," 'Loss/total_loss': 0.5565753,\n"," 'learning_rate': 0.07999918}\n","I1008 07:47:05.025995 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.21503071,\n"," 'Loss/localization_loss': 0.19383168,\n"," 'Loss/regularization_loss': 0.14771286,\n"," 'Loss/total_loss': 0.5565753,\n"," 'learning_rate': 0.07999918}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 1200 per-step time 0.436s\n","I1008 07:47:48.645254 139898126976896 model_lib_v2.py:707] Step 1200 per-step time 0.436s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18799737,\n"," 'Loss/localization_loss': 0.15873657,\n"," 'Loss/regularization_loss': 0.14726457,\n"," 'Loss/total_loss': 0.4939985,\n"," 'learning_rate': 0.079996705}\n","I1008 07:47:48.645649 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.18799737,\n"," 'Loss/localization_loss': 0.15873657,\n"," 'Loss/regularization_loss': 0.14726457,\n"," 'Loss/total_loss': 0.4939985,\n"," 'learning_rate': 0.079996705}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 1300 per-step time 0.401s\n","I1008 07:48:28.768769 139898126976896 model_lib_v2.py:707] Step 1300 per-step time 0.401s\n","INFO:tensorflow:{'Loss/classification_loss': 0.27663192,\n"," 'Loss/localization_loss': 0.21286464,\n"," 'Loss/regularization_loss': 0.14684358,\n"," 'Loss/total_loss': 0.63634014,\n"," 'learning_rate': 0.0799926}\n","I1008 07:48:28.769130 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.27663192,\n"," 'Loss/localization_loss': 0.21286464,\n"," 'Loss/regularization_loss': 0.14684358,\n"," 'Loss/total_loss': 0.63634014,\n"," 'learning_rate': 0.0799926}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 1400 per-step time 0.389s\n","I1008 07:49:07.704265 139898126976896 model_lib_v2.py:707] Step 1400 per-step time 0.389s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17651322,\n"," 'Loss/localization_loss': 0.14015363,\n"," 'Loss/regularization_loss': 0.14638872,\n"," 'Loss/total_loss': 0.46305555,\n"," 'learning_rate': 0.07998685}\n","I1008 07:49:07.704615 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.17651322,\n"," 'Loss/localization_loss': 0.14015363,\n"," 'Loss/regularization_loss': 0.14638872,\n"," 'Loss/total_loss': 0.46305555,\n"," 'learning_rate': 0.07998685}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 1500 per-step time 0.450s\n","I1008 07:49:52.681176 139898126976896 model_lib_v2.py:707] Step 1500 per-step time 0.450s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18637572,\n"," 'Loss/localization_loss': 0.16324867,\n"," 'Loss/regularization_loss': 0.14597088,\n"," 'Loss/total_loss': 0.49559528,\n"," 'learning_rate': 0.07997945}\n","I1008 07:49:52.681663 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.18637572,\n"," 'Loss/localization_loss': 0.16324867,\n"," 'Loss/regularization_loss': 0.14597088,\n"," 'Loss/total_loss': 0.49559528,\n"," 'learning_rate': 0.07997945}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 1600 per-step time 0.388s\n","I1008 07:50:31.436272 139898126976896 model_lib_v2.py:707] Step 1600 per-step time 0.388s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1805606,\n"," 'Loss/localization_loss': 0.15561645,\n"," 'Loss/regularization_loss': 0.14551103,\n"," 'Loss/total_loss': 0.48168808,\n"," 'learning_rate': 0.079970405}\n","I1008 07:50:31.443373 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.1805606,\n"," 'Loss/localization_loss': 0.15561645,\n"," 'Loss/regularization_loss': 0.14551103,\n"," 'Loss/total_loss': 0.48168808,\n"," 'learning_rate': 0.079970405}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 1700 per-step time 0.394s\n","I1008 07:51:10.857643 139898126976896 model_lib_v2.py:707] Step 1700 per-step time 0.394s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14412254,\n"," 'Loss/localization_loss': 0.108108,\n"," 'Loss/regularization_loss': 0.14510363,\n"," 'Loss/total_loss': 0.39733416,\n"," 'learning_rate': 0.07995972}\n","I1008 07:51:10.858066 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.14412254,\n"," 'Loss/localization_loss': 0.108108,\n"," 'Loss/regularization_loss': 0.14510363,\n"," 'Loss/total_loss': 0.39733416,\n"," 'learning_rate': 0.07995972}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 1800 per-step time 0.441s\n","I1008 07:51:54.964679 139898126976896 model_lib_v2.py:707] Step 1800 per-step time 0.441s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14987297,\n"," 'Loss/localization_loss': 0.1120467,\n"," 'Loss/regularization_loss': 0.14462748,\n"," 'Loss/total_loss': 0.40654716,\n"," 'learning_rate': 0.0799474}\n","I1008 07:51:54.965416 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.14987297,\n"," 'Loss/localization_loss': 0.1120467,\n"," 'Loss/regularization_loss': 0.14462748,\n"," 'Loss/total_loss': 0.40654716,\n"," 'learning_rate': 0.0799474}\n","INFO:tensorflow:Step 1900 per-step time 0.399s\n","I1008 07:52:34.840034 139898126976896 model_lib_v2.py:707] Step 1900 per-step time 0.399s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15556052,\n"," 'Loss/localization_loss': 0.12359453,\n"," 'Loss/regularization_loss': 0.14412834,\n"," 'Loss/total_loss': 0.4232834,\n"," 'learning_rate': 0.07993342}\n","I1008 07:52:34.840749 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.15556052,\n"," 'Loss/localization_loss': 0.12359453,\n"," 'Loss/regularization_loss': 0.14412834,\n"," 'Loss/total_loss': 0.4232834,\n"," 'learning_rate': 0.07993342}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 2000 per-step time 0.398s\n","I1008 07:53:14.575525 139898126976896 model_lib_v2.py:707] Step 2000 per-step time 0.398s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15907331,\n"," 'Loss/localization_loss': 0.10431903,\n"," 'Loss/regularization_loss': 0.14360075,\n"," 'Loss/total_loss': 0.4069931,\n"," 'learning_rate': 0.07991781}\n","I1008 07:53:14.575903 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.15907331,\n"," 'Loss/localization_loss': 0.10431903,\n"," 'Loss/regularization_loss': 0.14360075,\n"," 'Loss/total_loss': 0.4069931,\n"," 'learning_rate': 0.07991781}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 2100 per-step time 0.428s\n","I1008 07:53:57.387830 139898126976896 model_lib_v2.py:707] Step 2100 per-step time 0.428s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15890065,\n"," 'Loss/localization_loss': 0.115349635,\n"," 'Loss/regularization_loss': 0.14309044,\n"," 'Loss/total_loss': 0.4173407,\n"," 'learning_rate': 0.07990056}\n","I1008 07:53:57.388762 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.15890065,\n"," 'Loss/localization_loss': 0.115349635,\n"," 'Loss/regularization_loss': 0.14309044,\n"," 'Loss/total_loss': 0.4173407,\n"," 'learning_rate': 0.07990056}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 2200 per-step time 0.418s\n","I1008 07:54:39.194341 139898126976896 model_lib_v2.py:707] Step 2200 per-step time 0.418s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17859872,\n"," 'Loss/localization_loss': 0.12060133,\n"," 'Loss/regularization_loss': 0.14262693,\n"," 'Loss/total_loss': 0.441827,\n"," 'learning_rate': 0.07988167}\n","I1008 07:54:39.194695 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.17859872,\n"," 'Loss/localization_loss': 0.12060133,\n"," 'Loss/regularization_loss': 0.14262693,\n"," 'Loss/total_loss': 0.441827,\n"," 'learning_rate': 0.07988167}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 2300 per-step time 0.394s\n","I1008 07:55:18.611344 139898126976896 model_lib_v2.py:707] Step 2300 per-step time 0.394s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15613194,\n"," 'Loss/localization_loss': 0.1182902,\n"," 'Loss/regularization_loss': 0.1421368,\n"," 'Loss/total_loss': 0.41655892,\n"," 'learning_rate': 0.07986114}\n","I1008 07:55:18.611707 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.15613194,\n"," 'Loss/localization_loss': 0.1182902,\n"," 'Loss/regularization_loss': 0.1421368,\n"," 'Loss/total_loss': 0.41655892,\n"," 'learning_rate': 0.07986114}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 2400 per-step time 0.408s\n","I1008 07:55:59.430075 139898126976896 model_lib_v2.py:707] Step 2400 per-step time 0.408s\n","INFO:tensorflow:{'Loss/classification_loss': 0.158428,\n"," 'Loss/localization_loss': 0.09961883,\n"," 'Loss/regularization_loss': 0.14159437,\n"," 'Loss/total_loss': 0.39964122,\n"," 'learning_rate': 0.07983897}\n","I1008 07:55:59.430481 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.158428,\n"," 'Loss/localization_loss': 0.09961883,\n"," 'Loss/regularization_loss': 0.14159437,\n"," 'Loss/total_loss': 0.39964122,\n"," 'learning_rate': 0.07983897}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 2500 per-step time 0.439s\n","I1008 07:56:43.355502 139898126976896 model_lib_v2.py:707] Step 2500 per-step time 0.439s\n","INFO:tensorflow:{'Loss/classification_loss': 0.15809153,\n"," 'Loss/localization_loss': 0.10803063,\n"," 'Loss/regularization_loss': 0.14109142,\n"," 'Loss/total_loss': 0.40721357,\n"," 'learning_rate': 0.079815164}\n","I1008 07:56:43.355887 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.15809153,\n"," 'Loss/localization_loss': 0.10803063,\n"," 'Loss/regularization_loss': 0.14109142,\n"," 'Loss/total_loss': 0.40721357,\n"," 'learning_rate': 0.079815164}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 2600 per-step time 0.394s\n","I1008 07:57:22.752958 139898126976896 model_lib_v2.py:707] Step 2600 per-step time 0.394s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13440242,\n"," 'Loss/localization_loss': 0.08377189,\n"," 'Loss/regularization_loss': 0.14060839,\n"," 'Loss/total_loss': 0.3587827,\n"," 'learning_rate': 0.07978972}\n","I1008 07:57:22.753349 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.13440242,\n"," 'Loss/localization_loss': 0.08377189,\n"," 'Loss/regularization_loss': 0.14060839,\n"," 'Loss/total_loss': 0.3587827,\n"," 'learning_rate': 0.07978972}\n","INFO:tensorflow:Step 2700 per-step time 0.398s\n","I1008 07:58:02.553803 139898126976896 model_lib_v2.py:707] Step 2700 per-step time 0.398s\n","INFO:tensorflow:{'Loss/classification_loss': 0.17418423,\n"," 'Loss/localization_loss': 0.13847855,\n"," 'Loss/regularization_loss': 0.14012942,\n"," 'Loss/total_loss': 0.4527922,\n"," 'learning_rate': 0.07976264}\n","I1008 07:58:02.554187 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.17418423,\n"," 'Loss/localization_loss': 0.13847855,\n"," 'Loss/regularization_loss': 0.14012942,\n"," 'Loss/total_loss': 0.4527922,\n"," 'learning_rate': 0.07976264}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 2800 per-step time 0.432s\n","I1008 07:58:45.716847 139898126976896 model_lib_v2.py:707] Step 2800 per-step time 0.432s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13261156,\n"," 'Loss/localization_loss': 0.086061,\n"," 'Loss/regularization_loss': 0.13962404,\n"," 'Loss/total_loss': 0.3582966,\n"," 'learning_rate': 0.07973392}\n","I1008 07:58:45.717337 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.13261156,\n"," 'Loss/localization_loss': 0.086061,\n"," 'Loss/regularization_loss': 0.13962404,\n"," 'Loss/total_loss': 0.3582966,\n"," 'learning_rate': 0.07973392}\n","INFO:tensorflow:Step 2900 per-step time 0.407s\n","I1008 07:59:26.428964 139898126976896 model_lib_v2.py:707] Step 2900 per-step time 0.407s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14207791,\n"," 'Loss/localization_loss': 0.10774038,\n"," 'Loss/regularization_loss': 0.13917221,\n"," 'Loss/total_loss': 0.38899052,\n"," 'learning_rate': 0.07970358}\n","I1008 07:59:26.429367 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.14207791,\n"," 'Loss/localization_loss': 0.10774038,\n"," 'Loss/regularization_loss': 0.13917221,\n"," 'Loss/total_loss': 0.38899052,\n"," 'learning_rate': 0.07970358}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3000 per-step time 0.393s\n","I1008 08:00:05.711834 139898126976896 model_lib_v2.py:707] Step 3000 per-step time 0.393s\n","INFO:tensorflow:{'Loss/classification_loss': 0.16642244,\n"," 'Loss/localization_loss': 0.108198434,\n"," 'Loss/regularization_loss': 0.13864526,\n"," 'Loss/total_loss': 0.41326615,\n"," 'learning_rate': 0.0796716}\n","I1008 08:00:05.712212 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.16642244,\n"," 'Loss/localization_loss': 0.108198434,\n"," 'Loss/regularization_loss': 0.13864526,\n"," 'Loss/total_loss': 0.41326615,\n"," 'learning_rate': 0.0796716}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3100 per-step time 0.451s\n","I1008 08:00:50.820852 139898126976896 model_lib_v2.py:707] Step 3100 per-step time 0.451s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11173227,\n"," 'Loss/localization_loss': 0.07681487,\n"," 'Loss/regularization_loss': 0.1381414,\n"," 'Loss/total_loss': 0.32668853,\n"," 'learning_rate': 0.07963799}\n","I1008 08:00:50.821366 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.11173227,\n"," 'Loss/localization_loss': 0.07681487,\n"," 'Loss/regularization_loss': 0.1381414,\n"," 'Loss/total_loss': 0.32668853,\n"," 'learning_rate': 0.07963799}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3200 per-step time 0.396s\n","I1008 08:01:30.398674 139898126976896 model_lib_v2.py:707] Step 3200 per-step time 0.396s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12691347,\n"," 'Loss/localization_loss': 0.08305205,\n"," 'Loss/regularization_loss': 0.13762867,\n"," 'Loss/total_loss': 0.3475942,\n"," 'learning_rate': 0.07960275}\n","I1008 08:01:30.399048 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.12691347,\n"," 'Loss/localization_loss': 0.08305205,\n"," 'Loss/regularization_loss': 0.13762867,\n"," 'Loss/total_loss': 0.3475942,\n"," 'learning_rate': 0.07960275}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3300 per-step time 0.387s\n","I1008 08:02:09.115831 139898126976896 model_lib_v2.py:707] Step 3300 per-step time 0.387s\n","INFO:tensorflow:{'Loss/classification_loss': 0.103907295,\n"," 'Loss/localization_loss': 0.07168484,\n"," 'Loss/regularization_loss': 0.13712755,\n"," 'Loss/total_loss': 0.31271967,\n"," 'learning_rate': 0.07956588}\n","I1008 08:02:09.116326 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.103907295,\n"," 'Loss/localization_loss': 0.07168484,\n"," 'Loss/regularization_loss': 0.13712755,\n"," 'Loss/total_loss': 0.31271967,\n"," 'learning_rate': 0.07956588}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3400 per-step time 0.448s\n","I1008 08:02:53.906412 139898126976896 model_lib_v2.py:707] Step 3400 per-step time 0.448s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11119428,\n"," 'Loss/localization_loss': 0.068153396,\n"," 'Loss/regularization_loss': 0.13664773,\n"," 'Loss/total_loss': 0.3159954,\n"," 'learning_rate': 0.079527386}\n","I1008 08:02:53.906785 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.11119428,\n"," 'Loss/localization_loss': 0.068153396,\n"," 'Loss/regularization_loss': 0.13664773,\n"," 'Loss/total_loss': 0.3159954,\n"," 'learning_rate': 0.079527386}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3500 per-step time 0.388s\n","I1008 08:03:32.735663 139898126976896 model_lib_v2.py:707] Step 3500 per-step time 0.388s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13015813,\n"," 'Loss/localization_loss': 0.09574801,\n"," 'Loss/regularization_loss': 0.13617408,\n"," 'Loss/total_loss': 0.36208022,\n"," 'learning_rate': 0.07948727}\n","I1008 08:03:32.736195 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.13015813,\n"," 'Loss/localization_loss': 0.09574801,\n"," 'Loss/regularization_loss': 0.13617408,\n"," 'Loss/total_loss': 0.36208022,\n"," 'learning_rate': 0.07948727}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3600 per-step time 0.403s\n","I1008 08:04:13.043257 139898126976896 model_lib_v2.py:707] Step 3600 per-step time 0.403s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12005806,\n"," 'Loss/localization_loss': 0.076624475,\n"," 'Loss/regularization_loss': 0.13569039,\n"," 'Loss/total_loss': 0.33237293,\n"," 'learning_rate': 0.079445526}\n","I1008 08:04:13.043628 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.12005806,\n"," 'Loss/localization_loss': 0.076624475,\n"," 'Loss/regularization_loss': 0.13569039,\n"," 'Loss/total_loss': 0.33237293,\n"," 'learning_rate': 0.079445526}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3700 per-step time 0.435s\n","I1008 08:04:56.494159 139898126976896 model_lib_v2.py:707] Step 3700 per-step time 0.435s\n","INFO:tensorflow:{'Loss/classification_loss': 0.14088869,\n"," 'Loss/localization_loss': 0.08771062,\n"," 'Loss/regularization_loss': 0.13519587,\n"," 'Loss/total_loss': 0.36379516,\n"," 'learning_rate': 0.07940216}\n","I1008 08:04:56.494516 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.14088869,\n"," 'Loss/localization_loss': 0.08771062,\n"," 'Loss/regularization_loss': 0.13519587,\n"," 'Loss/total_loss': 0.36379516,\n"," 'learning_rate': 0.07940216}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3800 per-step time 0.391s\n","I1008 08:05:35.567510 139898126976896 model_lib_v2.py:707] Step 3800 per-step time 0.391s\n","INFO:tensorflow:{'Loss/classification_loss': 0.10054169,\n"," 'Loss/localization_loss': 0.07047158,\n"," 'Loss/regularization_loss': 0.1346802,\n"," 'Loss/total_loss': 0.30569345,\n"," 'learning_rate': 0.079357184}\n","I1008 08:05:35.567867 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.10054169,\n"," 'Loss/localization_loss': 0.07047158,\n"," 'Loss/regularization_loss': 0.1346802,\n"," 'Loss/total_loss': 0.30569345,\n"," 'learning_rate': 0.079357184}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 3900 per-step time 0.376s\n","I1008 08:06:13.182244 139898126976896 model_lib_v2.py:707] Step 3900 per-step time 0.376s\n","INFO:tensorflow:{'Loss/classification_loss': 0.09547729,\n"," 'Loss/localization_loss': 0.063701674,\n"," 'Loss/regularization_loss': 0.13422228,\n"," 'Loss/total_loss': 0.29340124,\n"," 'learning_rate': 0.07931058}\n","I1008 08:06:13.182608 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.09547729,\n"," 'Loss/localization_loss': 0.063701674,\n"," 'Loss/regularization_loss': 0.13422228,\n"," 'Loss/total_loss': 0.29340124,\n"," 'learning_rate': 0.07931058}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 4000 per-step time 0.438s\n","I1008 08:06:56.993229 139898126976896 model_lib_v2.py:707] Step 4000 per-step time 0.438s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1335602,\n"," 'Loss/localization_loss': 0.09598027,\n"," 'Loss/regularization_loss': 0.13371903,\n"," 'Loss/total_loss': 0.3632595,\n"," 'learning_rate': 0.07926236}\n","I1008 08:06:56.993686 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.1335602,\n"," 'Loss/localization_loss': 0.09598027,\n"," 'Loss/regularization_loss': 0.13371903,\n"," 'Loss/total_loss': 0.3632595,\n"," 'learning_rate': 0.07926236}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 4100 per-step time 0.405s\n","I1008 08:07:37.458225 139898126976896 model_lib_v2.py:707] Step 4100 per-step time 0.405s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12071636,\n"," 'Loss/localization_loss': 0.07977131,\n"," 'Loss/regularization_loss': 0.13322754,\n"," 'Loss/total_loss': 0.3337152,\n"," 'learning_rate': 0.07921253}\n","I1008 08:07:37.458602 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.12071636,\n"," 'Loss/localization_loss': 0.07977131,\n"," 'Loss/regularization_loss': 0.13322754,\n"," 'Loss/total_loss': 0.3337152,\n"," 'learning_rate': 0.07921253}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 4200 per-step time 0.386s\n","I1008 08:08:16.083596 139898126976896 model_lib_v2.py:707] Step 4200 per-step time 0.386s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13825539,\n"," 'Loss/localization_loss': 0.090575635,\n"," 'Loss/regularization_loss': 0.13273829,\n"," 'Loss/total_loss': 0.36156932,\n"," 'learning_rate': 0.07916109}\n","I1008 08:08:16.083950 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.13825539,\n"," 'Loss/localization_loss': 0.090575635,\n"," 'Loss/regularization_loss': 0.13273829,\n"," 'Loss/total_loss': 0.36156932,\n"," 'learning_rate': 0.07916109}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 4300 per-step time 0.443s\n","I1008 08:09:00.374924 139898126976896 model_lib_v2.py:707] Step 4300 per-step time 0.443s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12469909,\n"," 'Loss/localization_loss': 0.070543,\n"," 'Loss/regularization_loss': 0.13226281,\n"," 'Loss/total_loss': 0.3275049,\n"," 'learning_rate': 0.07910804}\n","I1008 08:09:00.375603 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.12469909,\n"," 'Loss/localization_loss': 0.070543,\n"," 'Loss/regularization_loss': 0.13226281,\n"," 'Loss/total_loss': 0.3275049,\n"," 'learning_rate': 0.07910804}\n","INFO:tensorflow:Step 4400 per-step time 0.386s\n","I1008 08:09:38.997735 139898126976896 model_lib_v2.py:707] Step 4400 per-step time 0.386s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12952623,\n"," 'Loss/localization_loss': 0.09091555,\n"," 'Loss/regularization_loss': 0.13172121,\n"," 'Loss/total_loss': 0.35216302,\n"," 'learning_rate': 0.07905338}\n","I1008 08:09:38.998203 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.12952623,\n"," 'Loss/localization_loss': 0.09091555,\n"," 'Loss/regularization_loss': 0.13172121,\n"," 'Loss/total_loss': 0.35216302,\n"," 'learning_rate': 0.07905338}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 4500 per-step time 0.394s\n","I1008 08:10:18.409840 139898126976896 model_lib_v2.py:707] Step 4500 per-step time 0.394s\n","INFO:tensorflow:{'Loss/classification_loss': 0.10246262,\n"," 'Loss/localization_loss': 0.06391241,\n"," 'Loss/regularization_loss': 0.13124798,\n"," 'Loss/total_loss': 0.297623,\n"," 'learning_rate': 0.07899711}\n","I1008 08:10:18.410295 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.10246262,\n"," 'Loss/localization_loss': 0.06391241,\n"," 'Loss/regularization_loss': 0.13124798,\n"," 'Loss/total_loss': 0.297623,\n"," 'learning_rate': 0.07899711}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 4600 per-step time 0.431s\n","I1008 08:11:01.484806 139898126976896 model_lib_v2.py:707] Step 4600 per-step time 0.431s\n","INFO:tensorflow:{'Loss/classification_loss': 0.120818146,\n"," 'Loss/localization_loss': 0.09303743,\n"," 'Loss/regularization_loss': 0.13077976,\n"," 'Loss/total_loss': 0.3446353,\n"," 'learning_rate': 0.078939244}\n","I1008 08:11:01.485157 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.120818146,\n"," 'Loss/localization_loss': 0.09303743,\n"," 'Loss/regularization_loss': 0.13077976,\n"," 'Loss/total_loss': 0.3446353,\n"," 'learning_rate': 0.078939244}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 4700 per-step time 0.392s\n","I1008 08:11:40.651237 139898126976896 model_lib_v2.py:707] Step 4700 per-step time 0.392s\n","INFO:tensorflow:{'Loss/classification_loss': 0.113316976,\n"," 'Loss/localization_loss': 0.061347824,\n"," 'Loss/regularization_loss': 0.13027486,\n"," 'Loss/total_loss': 0.30493966,\n"," 'learning_rate': 0.07887978}\n","I1008 08:11:40.651602 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.113316976,\n"," 'Loss/localization_loss': 0.061347824,\n"," 'Loss/regularization_loss': 0.13027486,\n"," 'Loss/total_loss': 0.30493966,\n"," 'learning_rate': 0.07887978}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 4800 per-step time 0.386s\n","I1008 08:12:19.238391 139898126976896 model_lib_v2.py:707] Step 4800 per-step time 0.386s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11074046,\n"," 'Loss/localization_loss': 0.060273923,\n"," 'Loss/regularization_loss': 0.12978908,\n"," 'Loss/total_loss': 0.30080348,\n"," 'learning_rate': 0.07881871}\n","I1008 08:12:19.238802 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.11074046,\n"," 'Loss/localization_loss': 0.060273923,\n"," 'Loss/regularization_loss': 0.12978908,\n"," 'Loss/total_loss': 0.30080348,\n"," 'learning_rate': 0.07881871}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 4900 per-step time 0.385s\n","I1008 08:12:57.755969 139898126976896 model_lib_v2.py:707] Step 4900 per-step time 0.385s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11009794,\n"," 'Loss/localization_loss': 0.06781797,\n"," 'Loss/regularization_loss': 0.12930685,\n"," 'Loss/total_loss': 0.30722275,\n"," 'learning_rate': 0.07875605}\n","I1008 08:12:57.756333 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.11009794,\n"," 'Loss/localization_loss': 0.06781797,\n"," 'Loss/regularization_loss': 0.12930685,\n"," 'Loss/total_loss': 0.30722275,\n"," 'learning_rate': 0.07875605}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n","INFO:tensorflow:Step 5000 per-step time 0.436s\n","I1008 08:13:41.317323 139898126976896 model_lib_v2.py:707] Step 5000 per-step time 0.436s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11630413,\n"," 'Loss/localization_loss': 0.06662229,\n"," 'Loss/regularization_loss': 0.12881294,\n"," 'Loss/total_loss': 0.31173936,\n"," 'learning_rate': 0.078691795}\n","I1008 08:13:41.317715 139898126976896 model_lib_v2.py:708] {'Loss/classification_loss': 0.11630413,\n"," 'Loss/localization_loss': 0.06662229,\n"," 'Loss/regularization_loss': 0.12881294,\n"," 'Loss/total_loss': 0.31173936,\n"," 'learning_rate': 0.078691795}\n","Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n"]}],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"4_YRZu7npfDH"},"source":["# 7. Evaluate the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80L7-fdPpfDH"},"outputs":[],"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYsgEPx9pfDH","outputId":"57795864-a735-4810-e293-5b2afed82dab"},"outputs":[{"name":"stdout","output_type":"stream","text":["python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n"]}],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqTV2jGBpfDH","outputId":"589b9a05-6db7-4d8c-ef4a-91bc8809de5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["2021-08-01 01:30:55.699803: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0801 01:30:58.087321 140490526218112 model_lib_v2.py:1082] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I0801 01:30:58.087514 140490526218112 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0801 01:30:58.087595 140490526218112 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0801 01:30:58.087681 140490526218112 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0801 01:30:58.087795 140490526218112 model_lib_v2.py:1103] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","2021-08-01 01:30:58.093529: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n","2021-08-01 01:30:58.125008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-01 01:30:58.128085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-08-01 01:30:58.128332: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","2021-08-01 01:30:58.136890: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n","2021-08-01 01:30:58.136979: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n","2021-08-01 01:30:58.139539: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n","2021-08-01 01:30:58.140290: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n","2021-08-01 01:30:58.143411: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n","2021-08-01 01:30:58.144154: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n","2021-08-01 01:30:58.144432: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n","2021-08-01 01:30:58.144547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-01 01:30:58.145228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-01 01:30:58.145833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n","2021-08-01 01:30:58.146164: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-08-01 01:30:58.146415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-01 01:30:58.147030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n","coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n","2021-08-01 01:30:58.147117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-01 01:30:58.147782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-01 01:30:58.148376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n","2021-08-01 01:30:58.148432: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","2021-08-01 01:30:58.680093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-08-01 01:30:58.680153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n","2021-08-01 01:30:58.680171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n","2021-08-01 01:30:58.680381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-01 01:30:58.681075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-01 01:30:58.681753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-08-01 01:30:58.682345: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-08-01 01:30:58.682398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n","I0801 01:30:58.705155 140490526218112 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n","I0801 01:30:58.705394 140490526218112 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0801 01:30:58.705489 140490526218112 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0801 01:30:58.705563 140490526218112 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W0801 01:30:58.706863 140490526218112 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0801 01:30:58.724401 140490526218112 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0801 01:31:02.554151 140490526218112 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0801 01:31:03.711641 140490526218112 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n","I0801 01:31:06.414273 140490526218112 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n","INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-6\n","I0801 01:31:06.415407 140490526218112 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-6\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","2021-08-01 01:31:06.490237: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n","2021-08-01 01:31:06.490826: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000185000 Hz\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\n","    func_outputs = python_func(*func_args, **func_kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\n","    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 982, in wrapper\n","    user_requested=True,\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmpf90oju2d.py\", line 20, in tf__compute_eval_dict\n","    (losses_dict, prediction_dict) = ag__.converted_call(ag__.ld(_compute_losses_and_predictions_dicts), (ag__.ld(detection_model), ag__.ld(features), ag__.ld(labels), ag__.ld(add_regularization_loss)), None, fscope)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 446, in converted_call\n","    result = converted_f(*effective_args)\n","  File \"/tmp/tmpzdy6qrva.py\", line 14, in tf___compute_losses_and_predictions_dicts\n","    prediction_dict = ag__.converted_call(ag__.ld(model).predict, (ag__.ld(preprocessed_images), ag__.ld(features)[ag__.ld(fields).InputDataFields.true_image_shape]), dict(**ag__.converted_call(ag__.ld(model).get_side_inputs, (ag__.ld(features),), None, fscope)), fscope)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmp2odgn33d.py\", line 49, in tf__predict\n","    boxlist_list = ag__.converted_call(ag__.ld(self)._anchor_generator.generate, (ag__.ld(feature_map_spatial_dims),), dict(im_height=ag__.ld(image_shape)[1], im_width=ag__.ld(image_shape)[2]), fscope)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmp_ri1pd8i.py\", line 26, in tf__generate\n","    anchors_list = ag__.converted_call(ag__.ld(self)._generate, (ag__.ld(feature_map_shape_list),), dict(**ag__.ld(params)), fscope)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmpp8ci79jy.py\", line 124, in tf___generate\n","    ag__.for_stmt(ag__.converted_call(ag__.ld(zip), (ag__.ld(feature_map_shape_list), ag__.ld(self)._anchor_grid_info), None, fscope), None, loop_body, get_state_6, set_state_6, (), {'iterate_names': '(feat_shape, grid_info)'})\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 443, in for_stmt\n","    _py_for_stmt(iter_, extra_test, body, None, None)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 472, in _py_for_stmt\n","    body(target)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 458, in protected_body\n","    original_body(protected_iter)\n","  File \"/tmp/tmpp8ci79jy.py\", line 80, in loop_body\n","    (anchor_grid,) = ag__.converted_call(ag__.ld(ag).generate, (), dict(feature_map_shape_list=[(ag__.ld(feat_h), ag__.ld(feat_w))]), fscope)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmp_ri1pd8i.py\", line 26, in tf__generate\n","    anchors_list = ag__.converted_call(ag__.ld(self)._generate, (ag__.ld(feature_map_shape_list),), dict(**ag__.ld(params)), fscope)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n","    result = converted_f(*effective_args, **kwargs)\n","  File \"/tmp/tmp2kp3xnsz.py\", line 45, in tf___generate\n","    anchors = ag__.converted_call(ag__.ld(tile_anchors), (ag__.ld(grid_height), ag__.ld(grid_width), ag__.ld(scales_grid), ag__.ld(aspect_ratios_grid), ag__.ld(self)._base_anchor_size, ag__.ld(self)._anchor_stride, ag__.ld(self)._anchor_offset), None, fscope)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 446, in converted_call\n","    result = converted_f(*effective_args)\n","  File \"/tmp/tmpok0h1oe0.py\", line 18, in tf__tile_anchors\n","    (x_centers, y_centers) = ag__.converted_call(ag__.ld(ops).meshgrid, (ag__.ld(x_centers), ag__.ld(y_centers)), None, fscope)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 446, in converted_call\n","    result = converted_f(*effective_args)\n","  File \"/tmp/tmp5zx_n01n.py\", line 18, in tf__meshgrid\n","    ygrid = ag__.converted_call(ag__.ld(tf).tile, (ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(y), ag__.ld(y_exp_shape)), None, fscope), ag__.ld(x_exp_shape)), None, fscope)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 336, in converted_call\n","    return _call_unconverted(f, args, kwargs, options, False)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 464, in _call_unconverted\n","    return f(*args)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n","    return target(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 195, in reshape\n","    result = gen_array_ops.reshape(tensor, shape, name)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8398, in reshape\n","    \"Reshape\", tensor=tensor, shape=shape, name=name)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 750, in _apply_op_helper\n","    attrs=attr_protos, op_def=op_def)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 601, in _create_op_internal\n","    compute_device)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3565, in _create_op_internal\n","    op_def=op_def)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2042, in __init__\n","    control_input_ops, op_def)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1872, in _create_c_op\n","    for name, attr_value in node_def.attr.items():\n","  File \"/usr/lib/python3.7/_collections_abc.py\", line 744, in __iter__\n","    yield (key, self._mapping[key])\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 115, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 90, in main\n","    wait_interval=300, timeout=FLAGS.eval_timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1157, in eval_continuously\n","    global_step=global_step,\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 932, in eager_eval_loop\n","    compute_eval_dict, args=(features, labels))\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1285, in run\n","    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2833, in call_for_each_replica\n","    return self._call_for_each_replica(fn, args, kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 3608, in _call_for_each_replica\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\n","    self._initialize(args, kwds, add_initializers_to=initializers)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 764, in _initialize\n","    *args, **kwds))\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\n","    graph_function, _ = self._maybe_define_function(args, kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\n","    graph_function = self._create_graph_function(args, kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3289, in _create_graph_function\n","    capture_by_value=self._capture_by_value),\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1040, in func_graph_from_py_func\n","    func_graph.variables = variables\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\", line 411, in __exit__\n","    for inp, resource_type in _get_resource_inputs(op):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\", line 534, in _get_resource_inputs\n","    reads, writes = utils.get_read_write_resource_inputs(op)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\", line 109, in get_read_write_resource_inputs\n","    read_only_input_indices = op.get_attr(READ_ONLY_RESOURCE_INPUTS_ATTR)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2560, in get_attr\n","    pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 294, in __init__\n","    super(InvalidArgumentError, self).__init__(node_def, op, message,\n","KeyboardInterrupt\n"]}],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"orvRk02UpfDI"},"source":["# 8. Load Train Model From Checkpoint"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665216860313,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"8TYk4_oIpfDI"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import config_util"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665216860314,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"Wn1MHRE35pyC"},"outputs":[],"source":["# Prevent GPU complete consumption\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try: \n","        tf.config.experimental.set_virtual_device_configuration(\n","            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n","    except RunTimeError as e:\n","        print(e)"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":2082,"status":"ok","timestamp":1665216863249,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"tDnQg-cYpfDI"},"outputs":[],"source":["# Load pipeline config and build a detection model\n","configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n","detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-6')).expect_partial()\n","\n","@tf.function\n","def detect_fn(image):\n","    image, shapes = detection_model.preprocess(image)\n","    prediction_dict = detection_model.predict(image, shapes)\n","    detections = detection_model.postprocess(prediction_dict, shapes)\n","    return detections"]},{"cell_type":"markdown","metadata":{"id":"0EmsmbBZpfDI"},"source":["# 9. Detect from an Image"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665216864583,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"Y_MKiuZ4pfDI"},"outputs":[],"source":["import cv2 \n","import numpy as np\n","from matplotlib import pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665216866232,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"cBDbIhNapfDI"},"outputs":[],"source":["category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"]},{"cell_type":"code","execution_count":92,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665217890052,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"Lx3crOhOzITB"},"outputs":[],"source":["IMAGE_PATH = \"/content/inventory_images/test/test_10.jpg\""]},{"cell_type":"code","execution_count":93,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1665217890449,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"_Vfzm-lebt6q"},"outputs":[],"source":["from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"14poMtYwSKDYusGVxfqH140B-fMLWKk7C"},"executionInfo":{"elapsed":30925,"status":"ok","timestamp":1665217921367,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"Tpzn1SMry1yK","outputId":"ddffeaa3-3a0f-451a-b59f-bb5b46e0ef3d"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["img = cv2.imread(IMAGE_PATH)\n","image_np = np.array(img)\n","\n","input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","detections = detect_fn(input_tensor)\n","\n","num_detections = int(detections.pop('num_detections'))\n","detections = {key: value[0, :num_detections].numpy()\n","              for key, value in detections.items()}\n","detections['num_detections'] = num_detections\n","\n","# detection_classes should be ints.\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","label_id_offset = 1\n","image_np_with_detections = image_np.copy()\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","            image_np_with_detections,\n","            detections['detection_boxes'],\n","            detections['detection_classes']+label_id_offset,\n","            detections['detection_scores'],\n","            category_index,\n","            use_normalized_coordinates=True,\n","            max_boxes_to_draw=200,\n","            min_score_thresh=.2,\n","            agnostic_mode=False)\n","cv2_imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n","# plt.show()"]},{"cell_type":"code","execution_count":95,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1665217921369,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"1d2LzcuG5pyF","outputId":"57287eef-50ad-4d91-8751-c0c5ccce2a19"},"outputs":[{"data":{"text/plain":["dict_keys(['detection_boxes', 'detection_scores', 'detection_classes', 'raw_detection_boxes', 'raw_detection_scores', 'detection_multiclass_scores', 'detection_anchor_indices', 'num_detections'])"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["detections.keys()"]},{"cell_type":"code","execution_count":96,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1665217921370,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"XbQpM5JK9l6_"},"outputs":[],"source":["img_ = cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB)"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":582,"status":"ok","timestamp":1665217921939,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"OPAyldcK-GvF"},"outputs":[],"source":["from PIL import Image as im\n","# above array\n","data = im.fromarray(img_)\n","# saving the final output \n","# as a PNG file\n","data.save('ssd_mobilenet_v2_fpnlite2.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#end"]},{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1665217703546,"user":{"displayName":"lenovo tech","userId":"14760544972532443832"},"user_tz":-300},"id":"oEHzTPL7-4WL"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["4_YRZu7npfDH"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
