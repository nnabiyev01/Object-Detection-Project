{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch3zMsZV5pxn"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA1DIq5OpfDE",
        "outputId": "6f1c4309-991b-48f7-e78d-0e756be6409c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 77698, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 77698 (delta 36), reused 37 (delta 18), pack-reused 77621\u001b[K\n",
            "Receiving objects: 100% (77698/77698), 593.38 MiB | 39.31 MiB/s, done.\n",
            "Resolving deltas: 100% (55211/55211), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJjMHbnDs3Tv",
        "outputId": "8867c8c1-6718-498d-fd2f-2fac8fa348dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.41.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 75.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0 MB 85.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 78.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 71.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.10.0\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 61.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 75.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.1-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 63.3 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 109 kB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 11.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Collecting tensorflow~=2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.2.1)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.6.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.48.1)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 59.1 MB/s \n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.7)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Collecting keras\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 58.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 75.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 73.5 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 70.4 MB/s \n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 48.8 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.1.0\n",
            "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.9.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.10.0)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 55.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, docopt, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696118 sha256=335d1c6b08bcde4597976efe8994f9e1109ca4cbf1733c34d2a7600d788ef94b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bub_7xp3/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=6c5f21229b18d103c3291a22a009cde0341d9811999b7739a6ecefddb21c7a06\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=a38512aae17aeb0aadd3e353fadce09948a843dae7fdc5a2a80b60b10f39a0d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=6605c559ded16978148b3b7ccb724cae3dea2a21111b147a2ae906960dc84274\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=61a3806afb079bff6f0b77f3ad3829942caeccaa4f22e26975b41080719b583e\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=a5647c701230ed905b7d2407728a06ab112dc0a533491d73816f7d9ef61aef96\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 docopt seqeval\n",
            "Installing collected packages: requests, pyparsing, protobuf, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, keras, gast, tensorflow, portalocker, docopt, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, immutabledict, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.26.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.26.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.26.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.2.0\n",
            "    Uninstalling pymongo-4.2.0:\n",
            "      Successfully uninstalled pymongo-4.2.0\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "Successfully installed apache-beam-2.41.0 avro-python3-1.10.2 cloudpickle-2.2.0 colorama-0.4.5 dill-0.3.1.1 docopt-0.6.2 fastavro-1.6.1 gast-0.4.0 hdfs-2.7.0 immutabledict-2.2.1 keras-2.10.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.52 orjson-3.8.0 portalocker-2.5.1 proto-plus-1.22.1 protobuf-3.19.6 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.10.0 tensorflow-io-0.27.0 tensorflow-io-gcs-filesystem-0.27.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.10.0 tf-models-official-2.10.0 tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XWmBJOB5pxy",
        "outputId": "02737a1b-b9bf-48d0-cd1c-ea99e01d927f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                       Version\n",
            "----------------------------- ----------------------\n",
            "absl-py                       1.2.0\n",
            "aeppl                         0.0.33\n",
            "aesara                        2.7.9\n",
            "aiohttp                       3.8.1\n",
            "aiosignal                     1.2.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                1.2.1\n",
            "altair                        4.2.0\n",
            "apache-beam                   2.41.0\n",
            "appdirs                       1.4.4\n",
            "arviz                         0.12.1\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "async-timeout                 4.0.2\n",
            "asynctest                     0.13.0\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.1\n",
            "attrs                         22.1.0\n",
            "audioread                     3.0.0\n",
            "autograd                      1.4\n",
            "avro-python3                  1.10.2\n",
            "Babel                         2.10.3\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        5.0.1\n",
            "blis                          0.7.8\n",
            "bokeh                         2.3.3\n",
            "branca                        0.5.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.4\n",
            "catalogue                     2.0.8\n",
            "certifi                       2022.6.15\n",
            "cffi                          1.15.1\n",
            "cftime                        1.6.1\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.1.1\n",
            "click                         7.1.2\n",
            "clikit                        0.6.2\n",
            "cloudpickle                   2.2.0\n",
            "cmake                         3.22.6\n",
            "cmdstanpy                     1.0.7\n",
            "colorama                      0.4.5\n",
            "colorcet                      3.0.0\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "cons                          0.4.5\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "crashtest                     0.3.1\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda111                  9.4.0\n",
            "cvxopt                        1.3.0\n",
            "cvxpy                         1.2.1\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.6\n",
            "Cython                        0.29.32\n",
            "daft                          0.0.4\n",
            "dask                          2022.2.0\n",
            "datascience                   0.17.5\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   2022.2.0\n",
            "dlib                          19.24.0\n",
            "dm-tree                       0.1.7\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.323\n",
            "easydict                      1.9\n",
            "ecos                          2.0.10\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                3.4.0\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.3\n",
            "et-xmlfile                    1.1.0\n",
            "etils                         0.7.1\n",
            "etuples                       0.3.8\n",
            "fa2                           0.3.5\n",
            "fastai                        2.7.9\n",
            "fastavro                      1.6.1\n",
            "fastcore                      1.5.25\n",
            "fastdownload                  0.0.7\n",
            "fastdtw                       0.3.4\n",
            "fastjsonschema                2.16.1\n",
            "fastprogress                  1.0.3\n",
            "fastrlock                     0.8\n",
            "feather-format                0.4.1\n",
            "filelock                      3.8.0\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   2.0.7\n",
            "folium                        0.12.1.post1\n",
            "frozenlist                    1.3.1\n",
            "fsspec                        2022.8.2\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.31.6\n",
            "google-api-python-client      1.12.11\n",
            "google-auth                   1.35.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.2\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.56.4\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.3\n",
            "grpcio                        1.48.1\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.25.2\n",
            "gym-notices                   0.0.8\n",
            "h5py                          3.1.0\n",
            "hdfs                          2.7.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.4\n",
            "holidays                      0.15\n",
            "holoviews                     1.14.9\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "httpstan                      4.6.1\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "idna                          2.10\n",
            "imageio                       2.9.0\n",
            "imagesize                     1.4.1\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.4.0\n",
            "immutabledict                 2.2.1\n",
            "importlib-metadata            4.12.0\n",
            "importlib-resources           5.9.0\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "intel-openmp                  2022.1.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     5.3.4\n",
            "ipython                       7.9.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.1\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.3.17\n",
            "jaxlib                        0.3.15+cuda11.cudnn805\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.1.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter-client                6.1.12\n",
            "jupyter-console               6.1.0\n",
            "jupyter-core                  4.11.1\n",
            "jupyterlab-widgets            3.0.3\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.7\n",
            "keras                         2.10.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.4\n",
            "korean-lunar-calendar         0.2.1\n",
            "langcodes                     3.3.0\n",
            "libclang                      14.0.6\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.39.1\n",
            "lmdb                          0.99\n",
            "locket                        1.0.0\n",
            "logical-unification           0.4.5\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.9.1\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.0.1\n",
            "marshmallow                   3.17.1\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-venn               0.11.7\n",
            "miniKanren                    1.0.3\n",
            "missingno                     0.5.1\n",
            "mistune                       0.8.4\n",
            "mizani                        0.7.3\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.14.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.4\n",
            "multidict                     6.0.2\n",
            "multipledispatch              0.6.0\n",
            "multitasking                  0.0.11\n",
            "murmurhash                    1.0.8\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.4.0\n",
            "netCDF4                       1.6.0\n",
            "networkx                      2.6.3\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.7\n",
            "notebook                      5.3.1\n",
            "numba                         0.56.2\n",
            "numexpr                       2.8.3\n",
            "numpy                         1.21.6\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.0\n",
            "object-detection              0.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.6.0.66\n",
            "opencv-python                 4.6.0.66\n",
            "opencv-python-headless        4.5.2.52\n",
            "openpyxl                      3.0.10\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.8.0\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.3\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.2\n",
            "parso                         0.8.3\n",
            "partd                         1.3.0\n",
            "pastel                        0.2.1\n",
            "pathlib                       1.0.1\n",
            "pathy                         0.6.2\n",
            "patsy                         0.5.2\n",
            "pep517                        0.13.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.8.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portalocker                   2.5.1\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.7\n",
            "prettytable                   3.4.1\n",
            "progressbar2                  3.38.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                2.0.10\n",
            "prophet                       1.1\n",
            "proto-plus                    1.22.1\n",
            "protobuf                      3.19.6\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.9.3\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    8.0.0\n",
            "pyarrow                       6.0.1\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.4\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydantic                      1.9.2\n",
            "pydata-google-auth            1.4.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pylev                         1.4.0\n",
            "pymc                          4.1.4\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.3\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.18.1\n",
            "pysimdjson                    3.2.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        3.3.0\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                6.1.2\n",
            "python-utils                  3.3.3\n",
            "pytz                          2022.2.1\n",
            "pyviz-comms                   2.2.1\n",
            "PyWavelets                    1.3.0\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         23.2.1\n",
            "qdldl                         0.1.5.post2\n",
            "qudida                        0.0.4\n",
            "regex                         2022.6.2\n",
            "requests                      2.28.1\n",
            "requests-oauthlib             1.3.1\n",
            "resampy                       0.4.0\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.9\n",
            "sacrebleu                     2.2.0\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.7.3\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.0\n",
            "seaborn                       0.11.2\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.97\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.4\n",
            "six                           1.15.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.2.1\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "spacy                         3.4.1\n",
            "spacy-legacy                  3.0.10\n",
            "spacy-loggers                 1.0.3\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.41\n",
            "sqlparse                      0.4.2\n",
            "srsly                         2.4.4\n",
            "statsmodels                   0.12.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.10\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.0.1\n",
            "tensorboard                   2.10.1\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.10.0\n",
            "tensorflow-addons             0.18.0\n",
            "tensorflow-datasets           4.6.0\n",
            "tensorflow-estimator          2.10.0\n",
            "tensorflow-gcs-config         2.8.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io                 0.27.0\n",
            "tensorflow-io-gcs-filesystem  0.27.0\n",
            "tensorflow-metadata           1.10.0\n",
            "tensorflow-model-optimization 0.7.3\n",
            "tensorflow-probability        0.16.0\n",
            "tensorflow-text               2.10.0\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.13.3\n",
            "testpath                      0.6.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-models-official            2.10.0\n",
            "tf-slim                       1.1.0\n",
            "thinc                         8.1.0\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2021.11.2\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.1\n",
            "toolz                         0.12.0\n",
            "torch                         1.12.1+cu113\n",
            "torchaudio                    0.12.1+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.13.1\n",
            "torchvision                   0.13.1+cu113\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.64.1\n",
            "traitlets                     5.1.1\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typer                         0.4.2\n",
            "typing-extensions             4.1.1\n",
            "tzlocal                       1.5.1\n",
            "ujson                         5.4.0\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.10.1\n",
            "wcwidth                       0.2.5\n",
            "webargs                       8.2.0\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.37.1\n",
            "widgetsnbextension            3.6.1\n",
            "wordcloud                     1.8.2.2\n",
            "wrapt                         1.14.1\n",
            "xarray                        0.20.2\n",
            "xarray-einstats               0.2.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yarl                          1.8.1\n",
            "yellowbrick                   1.5\n",
            "zict                          2.2.0\n",
            "zipp                          3.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubPyqZTj5pxz",
        "outputId": "68399ddf-2677-4cad-d7b0-6eac847e2fcd",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-30 06:48:15.069163: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-30 06:48:15.256640: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-09-30 06:48:16.116985: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-30 06:48:16.117686: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-30 06:48:16.117722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-09-30 06:48:18.737137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:48:19.002482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:48:19.003250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Running tests under Python 3.7.14: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-09-30 06:48:19.012366: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-30 06:48:19.012673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:48:19.013614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:48:19.014512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:48:20.071617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:48:20.072339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:48:20.072971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:48:20.073515: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-09-30 06:48:20.073567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13735 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "W0930 06:48:20.446706 139757686822784 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.68s\n",
            "I0930 06:48:20.684973 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.68s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "I0930 06:48:21.185256 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n",
            "I0930 06:48:21.447567 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.35s\n",
            "I0930 06:48:21.800420 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.35s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.98s\n",
            "I0930 06:48:23.783542 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.98s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0930 06:48:23.789510 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0930 06:48:23.817168 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0930 06:48:23.832302 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0930 06:48:23.847502 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I0930 06:48:23.939500 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I0930 06:48:24.030259 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0930 06:48:24.121448 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0930 06:48:24.215642 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "I0930 06:48:24.315167 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0930 06:48:24.343691 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0930 06:48:24.508569 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0930 06:48:24.508720 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0930 06:48:24.508806 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0930 06:48:24.510946 139757686822784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0930 06:48:24.540361 139757686822784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0930 06:48:24.540497 139757686822784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0930 06:48:24.615461 139757686822784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0930 06:48:24.615590 139757686822784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0930 06:48:24.809296 139757686822784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0930 06:48:24.809470 139757686822784 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0930 06:48:25.004958 139757686822784 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0930 06:48:25.005116 139757686822784 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0930 06:48:25.376902 139757686822784 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0930 06:48:25.377112 139757686822784 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0930 06:48:26.069247 139757686822784 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0930 06:48:26.069473 139757686822784 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0930 06:48:26.783483 139757686822784 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0930 06:48:26.783707 139757686822784 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0930 06:48:26.996775 139757686822784 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0930 06:48:27.113557 139757686822784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0930 06:48:27.200360 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0930 06:48:27.200524 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0930 06:48:27.200591 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0930 06:48:27.202602 139757686822784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0930 06:48:27.251410 139757686822784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0930 06:48:27.251596 139757686822784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0930 06:48:27.521728 139757686822784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0930 06:48:27.521946 139757686822784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0930 06:48:27.958883 139757686822784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0930 06:48:27.959087 139757686822784 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0930 06:48:28.409993 139757686822784 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0930 06:48:28.410204 139757686822784 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0930 06:48:29.045834 139757686822784 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0930 06:48:29.046064 139757686822784 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0930 06:48:29.723290 139757686822784 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0930 06:48:29.723521 139757686822784 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0930 06:48:30.783738 139757686822784 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0930 06:48:30.783970 139757686822784 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0930 06:48:31.137467 139757686822784 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0930 06:48:31.184068 139757686822784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0930 06:48:31.313149 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0930 06:48:31.313342 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0930 06:48:31.313430 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0930 06:48:31.316860 139757686822784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0930 06:48:31.350671 139757686822784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0930 06:48:31.350853 139757686822784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0930 06:48:31.609819 139757686822784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0930 06:48:31.610003 139757686822784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0930 06:48:32.062717 139757686822784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0930 06:48:32.062977 139757686822784 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0930 06:48:32.568096 139757686822784 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0930 06:48:32.568331 139757686822784 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0930 06:48:33.317820 139757686822784 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0930 06:48:33.318053 139757686822784 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0930 06:48:34.019230 139757686822784 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0930 06:48:34.019448 139757686822784 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0930 06:48:34.781732 139757686822784 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0930 06:48:34.781958 139757686822784 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0930 06:48:35.135941 139757686822784 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0930 06:48:35.197800 139757686822784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0930 06:48:35.290820 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0930 06:48:35.291027 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0930 06:48:35.291120 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0930 06:48:35.293490 139757686822784 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0930 06:48:35.325399 139757686822784 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0930 06:48:35.325571 139757686822784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0930 06:48:35.586830 139757686822784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0930 06:48:35.587035 139757686822784 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0930 06:48:36.228960 139757686822784 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0930 06:48:36.229180 139757686822784 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0930 06:48:37.158735 139757686822784 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0930 06:48:37.158960 139757686822784 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0930 06:48:38.007783 139757686822784 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0930 06:48:38.008001 139757686822784 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0930 06:48:39.060914 139757686822784 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0930 06:48:39.061129 139757686822784 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0930 06:48:39.816221 139757686822784 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0930 06:48:39.816392 139757686822784 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0930 06:48:39.998548 139757686822784 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0930 06:48:40.037220 139757686822784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0930 06:48:40.102664 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0930 06:48:40.102821 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0930 06:48:40.102896 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0930 06:48:40.104330 139757686822784 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0930 06:48:40.123023 139757686822784 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0930 06:48:40.123135 139757686822784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0930 06:48:40.267308 139757686822784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0930 06:48:40.267446 139757686822784 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0930 06:48:40.606787 139757686822784 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0930 06:48:40.606942 139757686822784 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0930 06:48:40.968665 139757686822784 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0930 06:48:40.968924 139757686822784 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0930 06:48:41.525785 139757686822784 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0930 06:48:41.525967 139757686822784 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0930 06:48:42.111632 139757686822784 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0930 06:48:42.111812 139757686822784 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0930 06:48:42.833513 139757686822784 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0930 06:48:42.833695 139757686822784 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0930 06:48:43.034513 139757686822784 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0930 06:48:43.072011 139757686822784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0930 06:48:43.144051 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0930 06:48:43.144190 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0930 06:48:43.144260 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0930 06:48:43.145675 139757686822784 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0930 06:48:43.162854 139757686822784 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0930 06:48:43.162969 139757686822784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0930 06:48:43.365092 139757686822784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0930 06:48:43.365235 139757686822784 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0930 06:48:43.808056 139757686822784 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0930 06:48:43.808216 139757686822784 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0930 06:48:44.245003 139757686822784 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0930 06:48:44.245165 139757686822784 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0930 06:48:45.134127 139757686822784 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0930 06:48:45.134295 139757686822784 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0930 06:48:45.748216 139757686822784 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0930 06:48:45.748400 139757686822784 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0930 06:48:46.570965 139757686822784 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0930 06:48:46.571133 139757686822784 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0930 06:48:46.870177 139757686822784 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0930 06:48:46.909697 139757686822784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0930 06:48:46.992182 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0930 06:48:46.992346 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0930 06:48:46.992432 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0930 06:48:46.994287 139757686822784 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0930 06:48:47.012465 139757686822784 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0930 06:48:47.012574 139757686822784 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0930 06:48:47.225492 139757686822784 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0930 06:48:47.225652 139757686822784 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0930 06:48:47.742208 139757686822784 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0930 06:48:47.742377 139757686822784 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0930 06:48:48.282572 139757686822784 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0930 06:48:48.282737 139757686822784 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0930 06:48:49.018507 139757686822784 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0930 06:48:49.018692 139757686822784 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0930 06:48:49.748921 139757686822784 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0930 06:48:49.749097 139757686822784 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0930 06:48:50.742383 139757686822784 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0930 06:48:50.742555 139757686822784 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0930 06:48:51.019431 139757686822784 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0930 06:48:51.058649 139757686822784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0930 06:48:51.150790 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0930 06:48:51.150963 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0930 06:48:51.151035 139757686822784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0930 06:48:51.152500 139757686822784 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0930 06:48:51.173722 139757686822784 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0930 06:48:51.173873 139757686822784 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0930 06:48:51.697972 139757686822784 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0930 06:48:51.698141 139757686822784 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0930 06:48:52.320703 139757686822784 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0930 06:48:52.320921 139757686822784 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0930 06:48:52.993904 139757686822784 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0930 06:48:52.994088 139757686822784 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0930 06:48:53.862785 139757686822784 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0930 06:48:53.862948 139757686822784 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0930 06:48:54.804627 139757686822784 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0930 06:48:54.804812 139757686822784 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0930 06:48:56.002684 139757686822784 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0930 06:48:56.002873 139757686822784 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0930 06:48:56.403559 139757686822784 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0930 06:48:56.449660 139757686822784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 32.22s\n",
            "I0930 06:48:56.561339 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 32.22s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0930 06:48:56.586072 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0930 06:48:56.587693 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0930 06:48:56.588175 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0930 06:48:56.589554 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0930 06:48:56.590953 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0930 06:48:56.591468 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0930 06:48:56.592599 139757686822784 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 37.585s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMCZp4jJ5px2"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "4be0f083-dd8c-4809-d997-2d252ec8f8b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-09-30 06:48:57--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.194.128, 2607:f8b0:4001:c10::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.194.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90453990 (86M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v1_fp 100%[===================>]  86.26M   125MB/s    in 0.7s    \n",
            "\n",
            "2022-09-30 06:48:58 (125 MB/s) - ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [90453990/90453990]\n",
            "\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'object', 'id':1}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvnVNQF6KKvV",
        "outputId": "e0ed83ab-bcc5-4dab-8562-8bd8e8a10695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvf5WccwrFGq",
        "outputId": "aba10010-8377-46df-faa8-7e12e91098d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/inventory_images.zip\n",
            "   creating: inventory_images/\n",
            "   creating: inventory_images/test/\n",
            "  inflating: inventory_images/test/test_0.jpg  \n",
            "  inflating: inventory_images/test/test_1.jpg  \n",
            "  inflating: inventory_images/test/test_10.jpg  \n",
            "  inflating: inventory_images/test/test_11.jpg  \n",
            "  inflating: inventory_images/test/test_12.jpg  \n",
            "  inflating: inventory_images/test/test_13.jpg  \n",
            "  inflating: inventory_images/test/test_14.jpg  \n",
            "  inflating: inventory_images/test/test_15.jpg  \n",
            "  inflating: inventory_images/test/test_16.jpg  \n",
            "  inflating: inventory_images/test/test_17.jpg  \n",
            "  inflating: inventory_images/test/test_18.jpg  \n",
            "  inflating: inventory_images/test/test_19.jpg  \n",
            "  inflating: inventory_images/test/test_2.jpg  \n",
            "  inflating: inventory_images/test/test_20.jpg  \n",
            "  inflating: inventory_images/test/test_21.jpg  \n",
            "  inflating: inventory_images/test/test_22.jpg  \n",
            "  inflating: inventory_images/test/test_23.jpg  \n",
            "  inflating: inventory_images/test/test_24.jpg  \n",
            "  inflating: inventory_images/test/test_25.jpg  \n",
            "  inflating: inventory_images/test/test_26.jpg  \n",
            "  inflating: inventory_images/test/test_27.jpg  \n",
            "  inflating: inventory_images/test/test_28.jpg  \n",
            "  inflating: inventory_images/test/test_29.jpg  \n",
            "  inflating: inventory_images/test/test_3.jpg  \n",
            "  inflating: inventory_images/test/test_30.jpg  \n",
            "  inflating: inventory_images/test/test_31.jpg  \n",
            "  inflating: inventory_images/test/test_32.jpg  \n",
            "  inflating: inventory_images/test/test_33.jpg  \n",
            "  inflating: inventory_images/test/test_34.jpg  \n",
            "  inflating: inventory_images/test/test_35.jpg  \n",
            "  inflating: inventory_images/test/test_4.jpg  \n",
            "  inflating: inventory_images/test/test_5.jpg  \n",
            "  inflating: inventory_images/test/test_6.jpg  \n",
            "  inflating: inventory_images/test/test_7.jpg  \n",
            "  inflating: inventory_images/test/test_8.jpg  \n",
            "  inflating: inventory_images/test/test_9.jpg  \n",
            "   creating: inventory_images/train/\n",
            "  inflating: inventory_images/train/train_0.jpg  \n",
            "  inflating: inventory_images/train/train_1.jpg  \n",
            "  inflating: inventory_images/train/train_10.jpg  \n",
            "  inflating: inventory_images/train/train_100.jpg  \n",
            "  inflating: inventory_images/train/train_101.jpg  \n",
            "  inflating: inventory_images/train/train_102.jpg  \n",
            "  inflating: inventory_images/train/train_103.jpg  \n",
            "  inflating: inventory_images/train/train_104.jpg  \n",
            "  inflating: inventory_images/train/train_105.jpg  \n",
            "  inflating: inventory_images/train/train_106.jpg  \n",
            "  inflating: inventory_images/train/train_107.jpg  \n",
            "  inflating: inventory_images/train/train_108.jpg  \n",
            "  inflating: inventory_images/train/train_109.jpg  \n",
            "  inflating: inventory_images/train/train_11.jpg  \n",
            "  inflating: inventory_images/train/train_110.jpg  \n",
            "  inflating: inventory_images/train/train_111.jpg  \n",
            "  inflating: inventory_images/train/train_112.jpg  \n",
            "  inflating: inventory_images/train/train_113.jpg  \n",
            "  inflating: inventory_images/train/train_114.jpg  \n",
            "  inflating: inventory_images/train/train_115.jpg  \n",
            "  inflating: inventory_images/train/train_116.jpg  \n",
            "  inflating: inventory_images/train/train_117.jpg  \n",
            "  inflating: inventory_images/train/train_118.jpg  \n",
            "  inflating: inventory_images/train/train_119.jpg  \n",
            "  inflating: inventory_images/train/train_12.jpg  \n",
            "  inflating: inventory_images/train/train_120.jpg  \n",
            "  inflating: inventory_images/train/train_121.jpg  \n",
            "  inflating: inventory_images/train/train_122.jpg  \n",
            "  inflating: inventory_images/train/train_123.jpg  \n",
            "  inflating: inventory_images/train/train_124.jpg  \n",
            "  inflating: inventory_images/train/train_125.jpg  \n",
            "  inflating: inventory_images/train/train_126.jpg  \n",
            "  inflating: inventory_images/train/train_127.jpg  \n",
            "  inflating: inventory_images/train/train_128.jpg  \n",
            "  inflating: inventory_images/train/train_129.jpg  \n",
            "  inflating: inventory_images/train/train_13.jpg  \n",
            "  inflating: inventory_images/train/train_130.jpg  \n",
            "  inflating: inventory_images/train/train_131.jpg  \n",
            "  inflating: inventory_images/train/train_132.jpg  \n",
            "  inflating: inventory_images/train/train_133.jpg  \n",
            "  inflating: inventory_images/train/train_134.jpg  \n",
            "  inflating: inventory_images/train/train_135.jpg  \n",
            "  inflating: inventory_images/train/train_136.jpg  \n",
            "  inflating: inventory_images/train/train_137.jpg  \n",
            "  inflating: inventory_images/train/train_138.jpg  \n",
            "  inflating: inventory_images/train/train_139.jpg  \n",
            "  inflating: inventory_images/train/train_14.jpg  \n",
            "  inflating: inventory_images/train/train_140.jpg  \n",
            "  inflating: inventory_images/train/train_141.jpg  \n",
            "  inflating: inventory_images/train/train_142.jpg  \n",
            "  inflating: inventory_images/train/train_143.jpg  \n",
            "  inflating: inventory_images/train/train_144.jpg  \n",
            "  inflating: inventory_images/train/train_145.jpg  \n",
            "  inflating: inventory_images/train/train_146.jpg  \n",
            "  inflating: inventory_images/train/train_147.jpg  \n",
            "  inflating: inventory_images/train/train_148.jpg  \n",
            "  inflating: inventory_images/train/train_149.jpg  \n",
            "  inflating: inventory_images/train/train_15.jpg  \n",
            "  inflating: inventory_images/train/train_150.jpg  \n",
            "  inflating: inventory_images/train/train_151.jpg  \n",
            "  inflating: inventory_images/train/train_152.jpg  \n",
            "  inflating: inventory_images/train/train_153.jpg  \n",
            "  inflating: inventory_images/train/train_154.jpg  \n",
            "  inflating: inventory_images/train/train_155.jpg  \n",
            "  inflating: inventory_images/train/train_156.jpg  \n",
            "  inflating: inventory_images/train/train_157.jpg  \n",
            "  inflating: inventory_images/train/train_158.jpg  \n",
            "  inflating: inventory_images/train/train_159.jpg  \n",
            "  inflating: inventory_images/train/train_16.jpg  \n",
            "  inflating: inventory_images/train/train_160.jpg  \n",
            "  inflating: inventory_images/train/train_161.jpg  \n",
            "  inflating: inventory_images/train/train_162.jpg  \n",
            "  inflating: inventory_images/train/train_163.jpg  \n",
            "  inflating: inventory_images/train/train_164.jpg  \n",
            "  inflating: inventory_images/train/train_165.jpg  \n",
            "  inflating: inventory_images/train/train_166.jpg  \n",
            "  inflating: inventory_images/train/train_167.jpg  \n",
            "  inflating: inventory_images/train/train_168.jpg  \n",
            "  inflating: inventory_images/train/train_169.jpg  \n",
            "  inflating: inventory_images/train/train_17.jpg  \n",
            "  inflating: inventory_images/train/train_170.jpg  \n",
            "  inflating: inventory_images/train/train_171.jpg  \n",
            "  inflating: inventory_images/train/train_172.jpg  \n",
            "  inflating: inventory_images/train/train_173.jpg  \n",
            "  inflating: inventory_images/train/train_174.jpg  \n",
            "  inflating: inventory_images/train/train_175.jpg  \n",
            "  inflating: inventory_images/train/train_176.jpg  \n",
            "  inflating: inventory_images/train/train_177.jpg  \n",
            "  inflating: inventory_images/train/train_178.jpg  \n",
            "  inflating: inventory_images/train/train_179.jpg  \n",
            "  inflating: inventory_images/train/train_18.jpg  \n",
            "  inflating: inventory_images/train/train_180.jpg  \n",
            "  inflating: inventory_images/train/train_181.jpg  \n",
            "  inflating: inventory_images/train/train_182.jpg  \n",
            "  inflating: inventory_images/train/train_183.jpg  \n",
            "  inflating: inventory_images/train/train_184.jpg  \n",
            "  inflating: inventory_images/train/train_185.jpg  \n",
            "  inflating: inventory_images/train/train_186.jpg  \n",
            "  inflating: inventory_images/train/train_187.jpg  \n",
            "  inflating: inventory_images/train/train_188.jpg  \n",
            "  inflating: inventory_images/train/train_189.jpg  \n",
            "  inflating: inventory_images/train/train_19.jpg  \n",
            "  inflating: inventory_images/train/train_190.jpg  \n",
            "  inflating: inventory_images/train/train_191.jpg  \n",
            "  inflating: inventory_images/train/train_192.jpg  \n",
            "  inflating: inventory_images/train/train_193.jpg  \n",
            "  inflating: inventory_images/train/train_194.jpg  \n",
            "  inflating: inventory_images/train/train_195.jpg  \n",
            "  inflating: inventory_images/train/train_196.jpg  \n",
            "  inflating: inventory_images/train/train_197.jpg  \n",
            "  inflating: inventory_images/train/train_198.jpg  \n",
            "  inflating: inventory_images/train/train_199.jpg  \n",
            "  inflating: inventory_images/train/train_2.jpg  \n",
            "  inflating: inventory_images/train/train_20.jpg  \n",
            "  inflating: inventory_images/train/train_200.jpg  \n",
            "  inflating: inventory_images/train/train_22.jpg  \n",
            "  inflating: inventory_images/train/train_23.jpg  \n",
            "  inflating: inventory_images/train/train_24.jpg  \n",
            "  inflating: inventory_images/train/train_25.jpg  \n",
            "  inflating: inventory_images/train/train_26.jpg  \n",
            "  inflating: inventory_images/train/train_27.jpg  \n",
            "  inflating: inventory_images/train/train_28.jpg  \n",
            "  inflating: inventory_images/train/train_29.jpg  \n",
            "  inflating: inventory_images/train/train_3.jpg  \n",
            "  inflating: inventory_images/train/train_30.jpg  \n",
            "  inflating: inventory_images/train/train_31.jpg  \n",
            "  inflating: inventory_images/train/train_32.jpg  \n",
            "  inflating: inventory_images/train/train_33.jpg  \n",
            "  inflating: inventory_images/train/train_34.jpg  \n",
            "  inflating: inventory_images/train/train_35.jpg  \n",
            "  inflating: inventory_images/train/train_36.jpg  \n",
            "  inflating: inventory_images/train/train_37.jpg  \n",
            "  inflating: inventory_images/train/train_38.jpg  \n",
            "  inflating: inventory_images/train/train_39.jpg  \n",
            "  inflating: inventory_images/train/train_4.jpg  \n",
            "  inflating: inventory_images/train/train_41.jpg  \n",
            "  inflating: inventory_images/train/train_42.jpg  \n",
            "  inflating: inventory_images/train/train_43.jpg  \n",
            "  inflating: inventory_images/train/train_44.jpg  \n",
            "  inflating: inventory_images/train/train_45.jpg  \n",
            "  inflating: inventory_images/train/train_46.jpg  \n",
            "  inflating: inventory_images/train/train_47.jpg  \n",
            "  inflating: inventory_images/train/train_48.jpg  \n",
            "  inflating: inventory_images/train/train_49.jpg  \n",
            "  inflating: inventory_images/train/train_5.jpg  \n",
            "  inflating: inventory_images/train/train_50.jpg  \n",
            "  inflating: inventory_images/train/train_51.jpg  \n",
            "  inflating: inventory_images/train/train_52.jpg  \n",
            "  inflating: inventory_images/train/train_53.jpg  \n",
            "  inflating: inventory_images/train/train_54.jpg  \n",
            "  inflating: inventory_images/train/train_55.jpg  \n",
            "  inflating: inventory_images/train/train_56.jpg  \n",
            "  inflating: inventory_images/train/train_57.jpg  \n",
            "  inflating: inventory_images/train/train_58.jpg  \n",
            "  inflating: inventory_images/train/train_59.jpg  \n",
            "  inflating: inventory_images/train/train_6.jpg  \n",
            "  inflating: inventory_images/train/train_60.jpg  \n",
            "  inflating: inventory_images/train/train_61.jpg  \n",
            "  inflating: inventory_images/train/train_62.jpg  \n",
            "  inflating: inventory_images/train/train_63.jpg  \n",
            "  inflating: inventory_images/train/train_64.jpg  \n",
            "  inflating: inventory_images/train/train_65.jpg  \n",
            "  inflating: inventory_images/train/train_66.jpg  \n",
            "  inflating: inventory_images/train/train_67.jpg  \n",
            "  inflating: inventory_images/train/train_68.jpg  \n",
            "  inflating: inventory_images/train/train_69.jpg  \n",
            "  inflating: inventory_images/train/train_7.jpg  \n",
            "  inflating: inventory_images/train/train_70.jpg  \n",
            "  inflating: inventory_images/train/train_71.jpg  \n",
            "  inflating: inventory_images/train/train_72.jpg  \n",
            "  inflating: inventory_images/train/train_73.jpg  \n",
            "  inflating: inventory_images/train/train_74.jpg  \n",
            "  inflating: inventory_images/train/train_75.jpg  \n",
            "  inflating: inventory_images/train/train_76.jpg  \n",
            "  inflating: inventory_images/train/train_77.jpg  \n",
            "  inflating: inventory_images/train/train_78.jpg  \n",
            "  inflating: inventory_images/train/train_79.jpg  \n",
            "  inflating: inventory_images/train/train_8.jpg  \n",
            "  inflating: inventory_images/train/train_80.jpg  \n",
            "  inflating: inventory_images/train/train_81.jpg  \n",
            "  inflating: inventory_images/train/train_82.jpg  \n",
            "  inflating: inventory_images/train/train_83.jpg  \n",
            "  inflating: inventory_images/train/train_84.jpg  \n",
            "  inflating: inventory_images/train/train_85.jpg  \n",
            "  inflating: inventory_images/train/train_86.jpg  \n",
            "  inflating: inventory_images/train/train_87.jpg  \n",
            "  inflating: inventory_images/train/train_88.jpg  \n",
            "  inflating: inventory_images/train/train_89.jpg  \n",
            "  inflating: inventory_images/train/train_9.jpg  \n",
            "  inflating: inventory_images/train/train_90.jpg  \n",
            "  inflating: inventory_images/train/train_91.jpg  \n",
            "  inflating: inventory_images/train/train_92.jpg  \n",
            "  inflating: inventory_images/train/train_93.jpg  \n",
            "  inflating: inventory_images/train/train_94.jpg  \n",
            "  inflating: inventory_images/train/train_95.jpg  \n",
            "  inflating: inventory_images/train/train_96.jpg  \n",
            "  inflating: inventory_images/train/train_97.jpg  \n",
            "  inflating: inventory_images/train/train_98.jpg  \n",
            "  inflating: inventory_images/train/train_99.jpg  \n",
            "   creating: inventory_images/val/\n",
            "  inflating: inventory_images/val/val_0.jpg  \n",
            "  inflating: inventory_images/val/val_1.jpg  \n",
            "  inflating: inventory_images/val/val_10.jpg  \n",
            "  inflating: inventory_images/val/val_11.jpg  \n",
            "  inflating: inventory_images/val/val_12.jpg  \n",
            "  inflating: inventory_images/val/val_13.jpg  \n",
            "  inflating: inventory_images/val/val_14.jpg  \n",
            "  inflating: inventory_images/val/val_15.jpg  \n",
            "  inflating: inventory_images/val/val_16.jpg  \n",
            "  inflating: inventory_images/val/val_17.jpg  \n",
            "  inflating: inventory_images/val/val_18.jpg  \n",
            "  inflating: inventory_images/val/val_19.jpg  \n",
            "  inflating: inventory_images/val/val_2.jpg  \n",
            "  inflating: inventory_images/val/val_20.jpg  \n",
            "  inflating: inventory_images/val/val_21.jpg  \n",
            "  inflating: inventory_images/val/val_22.jpg  \n",
            "  inflating: inventory_images/val/val_23.jpg  \n",
            "  inflating: inventory_images/val/val_24.jpg  \n",
            "  inflating: inventory_images/val/val_25.jpg  \n",
            "  inflating: inventory_images/val/val_26.jpg  \n",
            "  inflating: inventory_images/val/val_27.jpg  \n",
            "  inflating: inventory_images/val/val_28.jpg  \n",
            "  inflating: inventory_images/val/val_29.jpg  \n",
            "  inflating: inventory_images/val/val_3.jpg  \n",
            "  inflating: inventory_images/val/val_30.jpg  \n",
            "  inflating: inventory_images/val/val_31.jpg  \n",
            "  inflating: inventory_images/val/val_32.jpg  \n",
            "  inflating: inventory_images/val/val_33.jpg  \n",
            "  inflating: inventory_images/val/val_34.jpg  \n",
            "  inflating: inventory_images/val/val_35.jpg  \n",
            "  inflating: inventory_images/val/val_36.jpg  \n",
            "  inflating: inventory_images/val/val_37.jpg  \n",
            "  inflating: inventory_images/val/val_38.jpg  \n",
            "  inflating: inventory_images/val/val_39.jpg  \n",
            "  inflating: inventory_images/val/val_4.jpg  \n",
            "  inflating: inventory_images/val/val_40.jpg  \n",
            "  inflating: inventory_images/val/val_41.jpg  \n",
            "  inflating: inventory_images/val/val_42.jpg  \n",
            "  inflating: inventory_images/val/val_43.jpg  \n",
            "  inflating: inventory_images/val/val_44.jpg  \n",
            "  inflating: inventory_images/val/val_45.jpg  \n",
            "  inflating: inventory_images/val/val_46.jpg  \n",
            "  inflating: inventory_images/val/val_47.jpg  \n",
            "  inflating: inventory_images/val/val_48.jpg  \n",
            "  inflating: inventory_images/val/val_49.jpg  \n",
            "  inflating: inventory_images/val/val_5.jpg  \n",
            "  inflating: inventory_images/val/val_50.jpg  \n",
            "  inflating: inventory_images/val/val_51.jpg  \n",
            "  inflating: inventory_images/val/val_52.jpg  \n",
            "  inflating: inventory_images/val/val_53.jpg  \n",
            "  inflating: inventory_images/val/val_54.jpg  \n",
            "  inflating: inventory_images/val/val_55.jpg  \n",
            "  inflating: inventory_images/val/val_56.jpg  \n",
            "  inflating: inventory_images/val/val_57.jpg  \n",
            "  inflating: inventory_images/val/val_58.jpg  \n",
            "  inflating: inventory_images/val/val_59.jpg  \n",
            "  inflating: inventory_images/val/val_6.jpg  \n",
            "  inflating: inventory_images/val/val_60.jpg  \n",
            "  inflating: inventory_images/val/val_61.jpg  \n",
            "  inflating: inventory_images/val/val_62.jpg  \n",
            "  inflating: inventory_images/val/val_63.jpg  \n",
            "  inflating: inventory_images/val/val_64.jpg  \n",
            "  inflating: inventory_images/val/val_65.jpg  \n",
            "  inflating: inventory_images/val/val_66.jpg  \n",
            "  inflating: inventory_images/val/val_67.jpg  \n",
            "  inflating: inventory_images/val/val_68.jpg  \n",
            "  inflating: inventory_images/val/val_69.jpg  \n",
            "  inflating: inventory_images/val/val_7.jpg  \n",
            "  inflating: inventory_images/val/val_70.jpg  \n",
            "  inflating: inventory_images/val/val_71.jpg  \n",
            "  inflating: inventory_images/val/val_72.jpg  \n",
            "  inflating: inventory_images/val/val_73.jpg  \n",
            "  inflating: inventory_images/val/val_74.jpg  \n",
            "  inflating: inventory_images/val/val_75.jpg  \n",
            "  inflating: inventory_images/val/val_8.jpg  \n",
            "  inflating: inventory_images/val/val_9.jpg  \n",
            "   creating: annotations/\n",
            "  inflating: annotations/test_labels.csv  \n",
            "  inflating: annotations/train_labels.csv  \n",
            "  inflating: annotations/val_labels.csv  \n"
          ]
        }
      ],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "!unzip \"/content/drive/MyDrive/inventory_images.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpb_BVUpfDD",
        "outputId": "f9233b30-57dc-46ff-9734-047b9e1efb5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl7retgQ4oh2",
        "outputId": "1aa5941e-8580-4316-e4db-b9ad3097c18a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-30 06:54:13.025861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-30 06:54:13.202644: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-09-30 06:54:13.894127: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-30 06:54:13.894239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-30 06:54:13.894260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-09-30 06:54:15.250251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:54:15.259922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:54:15.260604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Successfully created the TFRecords: /content/Tensorflow/workspace/annotations/train.record\n"
          ]
        }
      ],
      "source": [
        "!python /content/Tensorflow/scripts/generate_tfrecord.py --csv_input=/content/annotations/train_labels.csv  --output_path=/content/Tensorflow/workspace/annotations/train.record --image_dir=/content/inventory_images/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv9Zesa0Leyk",
        "outputId": "c7cf16db-b316-4bda-b12f-99e043ee9d0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-30 06:58:56.493650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-30 06:58:56.664589: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-09-30 06:58:57.366920: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-30 06:58:57.367037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-30 06:58:57.367059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-09-30 06:58:58.704358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:58:58.714339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-30 06:58:58.715068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Successfully created the TFRecords: /content/Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python /content/Tensorflow/scripts/generate_tfrecord.py --csv_input=/content/annotations/test_labels.csv  --output_path=/content/Tensorflow/workspace/annotations/test.record --image_dir=/content/inventory_images/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwFjeLN45px5",
        "outputId": "46121211-1659-48fb-f895-520b1d9e4c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (2022.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "edb068ce-b7c4-463a-d79c-bc4f86e5bc7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 640\n",
              "       width: 640\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v1_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 256\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " }, 'train_config': batch_size: 64\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.03999999910593033\n",
              "         total_steps: 25000\n",
              "         warmup_learning_rate: 0.013333000242710114\n",
              "         warmup_steps: 2000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 25000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2, 'train_input_config': tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }, 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false\n",
              " batch_size: 1, 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ], 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = 1\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DA052bTB4wh",
        "outputId": "35105a32-627b-41c7-9f18-f0784aa6c9f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model {\n",
            "  ssd {\n",
            "    num_classes: 1\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 640\n",
            "        width: 640\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: \"ssd_mobilenet_v1_fpn_keras\"\n",
            "      depth_multiplier: 1.0\n",
            "      min_depth: 16\n",
            "      conv_hyperparams {\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 4e-05\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          random_normal_initializer {\n",
            "            mean: 0.0\n",
            "            stddev: 0.01\n",
            "          }\n",
            "        }\n",
            "        activation: RELU_6\n",
            "        batch_norm {\n",
            "          decay: 0.997\n",
            "          scale: true\n",
            "          epsilon: 0.001\n",
            "        }\n",
            "      }\n",
            "      override_base_feature_extractor_hyperparams: true\n",
            "      fpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "      }\n",
            "    }\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        conv_hyperparams {\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 4e-05\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              mean: 0.0\n",
            "              stddev: 0.01\n",
            "            }\n",
            "          }\n",
            "          activation: RELU_6\n",
            "          batch_norm {\n",
            "            decay: 0.997\n",
            "            scale: true\n",
            "            epsilon: 0.001\n",
            "          }\n",
            "        }\n",
            "        depth: 256\n",
            "        num_layers_before_predictor: 4\n",
            "        kernel_size: 3\n",
            "        class_prediction_bias_init: -4.6\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        scales_per_octave: 2\n",
            "      }\n",
            "    }\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-08\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "        use_static_shapes: false\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    loss {\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          gamma: 2.0\n",
            "          alpha: 0.25\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "  }\n",
            "}\n",
            "train_config {\n",
            "  batch_size: 4\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_crop_image {\n",
            "      min_object_covered: 0.0\n",
            "      min_aspect_ratio: 0.75\n",
            "      max_aspect_ratio: 3.0\n",
            "      min_area: 0.75\n",
            "      max_area: 1.0\n",
            "      overlap_thresh: 0.0\n",
            "    }\n",
            "  }\n",
            "  sync_replicas: true\n",
            "  optimizer {\n",
            "    momentum_optimizer {\n",
            "      learning_rate {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 0.04\n",
            "          total_steps: 25000\n",
            "          warmup_learning_rate: 0.013333\n",
            "          warmup_steps: 2000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
            "  num_steps: 25000\n",
            "  startup_delay_steps: 0.0\n",
            "  replicas_to_aggregate: 8\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  fine_tune_checkpoint_version: V2\n",
            "}\n",
            "train_input_reader {\n",
            "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
            "  }\n",
            "}\n",
            "eval_config {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "  batch_size: 1\n",
            "}\n",
            "eval_input_reader {\n",
            "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(config_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "367bbc31-14f9-47dd-b945-cd3ea37f75ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=5000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGfahCn-Ogmj",
        "outputId": "16a1cb41-24f6-4f6f-a815-282c0d345ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 7s (63.0 MB/s)\n",
            "(Reading database ... 159447 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 159425 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "c347b15e-c197-4131-ccc4-b264851c61b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-30 07:11:26.882007: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-09-30 07:11:27.654637: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-30 07:11:27.654825: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-09-30 07:11:27.654847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-09-30 07:11:30.887186: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0930 07:11:30.903798 139903992600448 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0930 07:11:30.909452 139903992600448 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0930 07:11:30.909646 139903992600448 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0930 07:11:30.937515 139903992600448 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0930 07:11:30.945999 139903992600448 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0930 07:11:30.946218 139903992600448 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0930 07:11:30.946313 139903992600448 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0930 07:11:30.946382 139903992600448 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0930 07:11:30.953997 139903992600448 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0930 07:11:30.971177 139903992600448 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0930 07:11:37.725810 139903992600448 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0930 07:11:40.560133 139903992600448 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0930 07:11:42.147291 139903992600448 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2022-09-30 07:11:47.487318: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 95883264 exceeds 10% of free system memory.\n",
            "2022-09-30 07:11:47.605418: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 95883264 exceeds 10% of free system memory.\n",
            "2022-09-30 07:11:47.609298: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 95883264 exceeds 10% of free system memory.\n",
            "2022-09-30 07:11:47.832362: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 95883264 exceeds 10% of free system memory.\n",
            "2022-09-30 07:11:47.832867: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 95883264 exceeds 10% of free system memory.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.427644 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.430695 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.433833 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.435042 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.438964 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.440143 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.443084 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.444215 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.447968 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0930 07:12:13.449093 139903992600448 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0930 07:12:14.544593 139899130853120 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 100 per-step time 0.761s\n",
            "I0930 07:13:30.372287 139903992600448 model_lib_v2.py:707] Step 100 per-step time 0.761s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25633302,\n",
            " 'Loss/localization_loss': 0.23534656,\n",
            " 'Loss/regularization_loss': 0.7740236,\n",
            " 'Loss/total_loss': 1.2657032,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0930 07:13:30.372756 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.25633302,\n",
            " 'Loss/localization_loss': 0.23534656,\n",
            " 'Loss/regularization_loss': 0.7740236,\n",
            " 'Loss/total_loss': 1.2657032,\n",
            " 'learning_rate': 0.014666351}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 200 per-step time 0.472s\n",
            "I0930 07:14:17.513742 139903992600448 model_lib_v2.py:707] Step 200 per-step time 0.472s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24288687,\n",
            " 'Loss/localization_loss': 0.21473192,\n",
            " 'Loss/regularization_loss': 0.7731503,\n",
            " 'Loss/total_loss': 1.2307692,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0930 07:14:17.514146 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.24288687,\n",
            " 'Loss/localization_loss': 0.21473192,\n",
            " 'Loss/regularization_loss': 0.7731503,\n",
            " 'Loss/total_loss': 1.2307692,\n",
            " 'learning_rate': 0.0159997}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 300 per-step time 0.418s\n",
            "I0930 07:14:59.337184 139903992600448 model_lib_v2.py:707] Step 300 per-step time 0.418s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20635618,\n",
            " 'Loss/localization_loss': 0.18112135,\n",
            " 'Loss/regularization_loss': 0.772203,\n",
            " 'Loss/total_loss': 1.1596806,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0930 07:14:59.337657 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.20635618,\n",
            " 'Loss/localization_loss': 0.18112135,\n",
            " 'Loss/regularization_loss': 0.772203,\n",
            " 'Loss/total_loss': 1.1596806,\n",
            " 'learning_rate': 0.01733305}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 400 per-step time 0.405s\n",
            "I0930 07:15:39.850860 139903992600448 model_lib_v2.py:707] Step 400 per-step time 0.405s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2569564,\n",
            " 'Loss/localization_loss': 0.21982029,\n",
            " 'Loss/regularization_loss': 0.7711745,\n",
            " 'Loss/total_loss': 1.2479511,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0930 07:15:39.851247 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.2569564,\n",
            " 'Loss/localization_loss': 0.21982029,\n",
            " 'Loss/regularization_loss': 0.7711745,\n",
            " 'Loss/total_loss': 1.2479511,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 0.423s\n",
            "I0930 07:16:22.125158 139903992600448 model_lib_v2.py:707] Step 500 per-step time 0.423s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2239191,\n",
            " 'Loss/localization_loss': 0.19126293,\n",
            " 'Loss/regularization_loss': 0.7700724,\n",
            " 'Loss/total_loss': 1.1852545,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0930 07:16:22.125636 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.2239191,\n",
            " 'Loss/localization_loss': 0.19126293,\n",
            " 'Loss/regularization_loss': 0.7700724,\n",
            " 'Loss/total_loss': 1.1852545,\n",
            " 'learning_rate': 0.01999975}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 600 per-step time 0.476s\n",
            "I0930 07:17:09.691053 139903992600448 model_lib_v2.py:707] Step 600 per-step time 0.476s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1734057,\n",
            " 'Loss/localization_loss': 0.11934618,\n",
            " 'Loss/regularization_loss': 0.76890385,\n",
            " 'Loss/total_loss': 1.0616558,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0930 07:17:09.691451 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.1734057,\n",
            " 'Loss/localization_loss': 0.11934618,\n",
            " 'Loss/regularization_loss': 0.76890385,\n",
            " 'Loss/total_loss': 1.0616558,\n",
            " 'learning_rate': 0.0213331}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 700 per-step time 0.423s\n",
            "I0930 07:17:52.004441 139903992600448 model_lib_v2.py:707] Step 700 per-step time 0.423s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19413076,\n",
            " 'Loss/localization_loss': 0.13289076,\n",
            " 'Loss/regularization_loss': 0.7676548,\n",
            " 'Loss/total_loss': 1.0946763,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0930 07:17:52.004903 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.19413076,\n",
            " 'Loss/localization_loss': 0.13289076,\n",
            " 'Loss/regularization_loss': 0.7676548,\n",
            " 'Loss/total_loss': 1.0946763,\n",
            " 'learning_rate': 0.02266645}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 800 per-step time 0.414s\n",
            "I0930 07:18:33.405754 139903992600448 model_lib_v2.py:707] Step 800 per-step time 0.414s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16985255,\n",
            " 'Loss/localization_loss': 0.14338693,\n",
            " 'Loss/regularization_loss': 0.76632947,\n",
            " 'Loss/total_loss': 1.079569,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0930 07:18:33.406228 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.16985255,\n",
            " 'Loss/localization_loss': 0.14338693,\n",
            " 'Loss/regularization_loss': 0.76632947,\n",
            " 'Loss/total_loss': 1.079569,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 0.421s\n",
            "I0930 07:19:15.550446 139903992600448 model_lib_v2.py:707] Step 900 per-step time 0.421s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1839693,\n",
            " 'Loss/localization_loss': 0.14048707,\n",
            " 'Loss/regularization_loss': 0.76493835,\n",
            " 'Loss/total_loss': 1.0893948,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0930 07:19:15.550814 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.1839693,\n",
            " 'Loss/localization_loss': 0.14048707,\n",
            " 'Loss/regularization_loss': 0.76493835,\n",
            " 'Loss/total_loss': 1.0893948,\n",
            " 'learning_rate': 0.025333151}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 1000 per-step time 0.461s\n",
            "I0930 07:20:01.616894 139903992600448 model_lib_v2.py:707] Step 1000 per-step time 0.461s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17117015,\n",
            " 'Loss/localization_loss': 0.1295001,\n",
            " 'Loss/regularization_loss': 0.76350343,\n",
            " 'Loss/total_loss': 1.0641737,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0930 07:20:01.617367 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.17117015,\n",
            " 'Loss/localization_loss': 0.1295001,\n",
            " 'Loss/regularization_loss': 0.76350343,\n",
            " 'Loss/total_loss': 1.0641737,\n",
            " 'learning_rate': 0.0266665}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 1100 per-step time 0.423s\n",
            "I0930 07:20:43.908077 139903992600448 model_lib_v2.py:707] Step 1100 per-step time 0.423s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23927191,\n",
            " 'Loss/localization_loss': 0.17952833,\n",
            " 'Loss/regularization_loss': 0.7619847,\n",
            " 'Loss/total_loss': 1.180785,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0930 07:20:43.908464 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.23927191,\n",
            " 'Loss/localization_loss': 0.17952833,\n",
            " 'Loss/regularization_loss': 0.7619847,\n",
            " 'Loss/total_loss': 1.180785,\n",
            " 'learning_rate': 0.02799985}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 1200 per-step time 0.427s\n",
            "I0930 07:21:26.646103 139903992600448 model_lib_v2.py:707] Step 1200 per-step time 0.427s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19988188,\n",
            " 'Loss/localization_loss': 0.15249756,\n",
            " 'Loss/regularization_loss': 0.76040584,\n",
            " 'Loss/total_loss': 1.1127853,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0930 07:21:26.646479 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.19988188,\n",
            " 'Loss/localization_loss': 0.15249756,\n",
            " 'Loss/regularization_loss': 0.76040584,\n",
            " 'Loss/total_loss': 1.1127853,\n",
            " 'learning_rate': 0.0293332}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 1300 per-step time 0.430s\n",
            "I0930 07:22:09.668627 139903992600448 model_lib_v2.py:707] Step 1300 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16280486,\n",
            " 'Loss/localization_loss': 0.13529485,\n",
            " 'Loss/regularization_loss': 0.7587405,\n",
            " 'Loss/total_loss': 1.0568402,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0930 07:22:09.669090 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.16280486,\n",
            " 'Loss/localization_loss': 0.13529485,\n",
            " 'Loss/regularization_loss': 0.7587405,\n",
            " 'Loss/total_loss': 1.0568402,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.467s\n",
            "I0930 07:22:56.340129 139903992600448 model_lib_v2.py:707] Step 1400 per-step time 0.467s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15800954,\n",
            " 'Loss/localization_loss': 0.13013999,\n",
            " 'Loss/regularization_loss': 0.75700796,\n",
            " 'Loss/total_loss': 1.0451574,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0930 07:22:56.340656 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.15800954,\n",
            " 'Loss/localization_loss': 0.13013999,\n",
            " 'Loss/regularization_loss': 0.75700796,\n",
            " 'Loss/total_loss': 1.0451574,\n",
            " 'learning_rate': 0.0319999}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 1500 per-step time 0.442s\n",
            "I0930 07:23:40.491972 139903992600448 model_lib_v2.py:707] Step 1500 per-step time 0.442s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15436958,\n",
            " 'Loss/localization_loss': 0.108514726,\n",
            " 'Loss/regularization_loss': 0.75519925,\n",
            " 'Loss/total_loss': 1.0180836,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0930 07:23:40.492363 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.15436958,\n",
            " 'Loss/localization_loss': 0.108514726,\n",
            " 'Loss/regularization_loss': 0.75519925,\n",
            " 'Loss/total_loss': 1.0180836,\n",
            " 'learning_rate': 0.03333325}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 1600 per-step time 0.443s\n",
            "I0930 07:24:24.741917 139903992600448 model_lib_v2.py:707] Step 1600 per-step time 0.443s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14690433,\n",
            " 'Loss/localization_loss': 0.10382538,\n",
            " 'Loss/regularization_loss': 0.7533212,\n",
            " 'Loss/total_loss': 1.0040509,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0930 07:24:24.742322 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.14690433,\n",
            " 'Loss/localization_loss': 0.10382538,\n",
            " 'Loss/regularization_loss': 0.7533212,\n",
            " 'Loss/total_loss': 1.0040509,\n",
            " 'learning_rate': 0.034666598}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 1700 per-step time 0.422s\n",
            "I0930 07:25:06.996011 139903992600448 model_lib_v2.py:707] Step 1700 per-step time 0.422s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20425117,\n",
            " 'Loss/localization_loss': 0.15950201,\n",
            " 'Loss/regularization_loss': 0.7514077,\n",
            " 'Loss/total_loss': 1.115161,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0930 07:25:06.996373 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.20425117,\n",
            " 'Loss/localization_loss': 0.15950201,\n",
            " 'Loss/regularization_loss': 0.7514077,\n",
            " 'Loss/total_loss': 1.115161,\n",
            " 'learning_rate': 0.03599995}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 1800 per-step time 0.473s\n",
            "I0930 07:25:54.303710 139903992600448 model_lib_v2.py:707] Step 1800 per-step time 0.473s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16481245,\n",
            " 'Loss/localization_loss': 0.14831579,\n",
            " 'Loss/regularization_loss': 0.7494119,\n",
            " 'Loss/total_loss': 1.06254,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0930 07:25:54.304291 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.16481245,\n",
            " 'Loss/localization_loss': 0.14831579,\n",
            " 'Loss/regularization_loss': 0.7494119,\n",
            " 'Loss/total_loss': 1.06254,\n",
            " 'learning_rate': 0.037333302}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 1900 per-step time 0.423s\n",
            "I0930 07:26:36.622678 139903992600448 model_lib_v2.py:707] Step 1900 per-step time 0.423s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14816283,\n",
            " 'Loss/localization_loss': 0.097420625,\n",
            " 'Loss/regularization_loss': 0.74733555,\n",
            " 'Loss/total_loss': 0.99291897,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0930 07:26:36.623217 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.14816283,\n",
            " 'Loss/localization_loss': 0.097420625,\n",
            " 'Loss/regularization_loss': 0.74733555,\n",
            " 'Loss/total_loss': 0.99291897,\n",
            " 'learning_rate': 0.03866665}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 2000 per-step time 0.427s\n",
            "I0930 07:27:19.296140 139903992600448 model_lib_v2.py:707] Step 2000 per-step time 0.427s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13710506,\n",
            " 'Loss/localization_loss': 0.08198772,\n",
            " 'Loss/regularization_loss': 0.74518615,\n",
            " 'Loss/total_loss': 0.96427894,\n",
            " 'learning_rate': 0.04}\n",
            "I0930 07:27:19.296497 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.13710506,\n",
            " 'Loss/localization_loss': 0.08198772,\n",
            " 'Loss/regularization_loss': 0.74518615,\n",
            " 'Loss/total_loss': 0.96427894,\n",
            " 'learning_rate': 0.04}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 2100 per-step time 0.419s\n",
            "I0930 07:28:01.182204 139903992600448 model_lib_v2.py:707] Step 2100 per-step time 0.419s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1668646,\n",
            " 'Loss/localization_loss': 0.12266124,\n",
            " 'Loss/regularization_loss': 0.74302554,\n",
            " 'Loss/total_loss': 1.0325514,\n",
            " 'learning_rate': 0.039998136}\n",
            "I0930 07:28:01.182591 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.1668646,\n",
            " 'Loss/localization_loss': 0.12266124,\n",
            " 'Loss/regularization_loss': 0.74302554,\n",
            " 'Loss/total_loss': 1.0325514,\n",
            " 'learning_rate': 0.039998136}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 2200 per-step time 0.431s\n",
            "I0930 07:28:44.320962 139903992600448 model_lib_v2.py:707] Step 2200 per-step time 0.431s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11524951,\n",
            " 'Loss/localization_loss': 0.07117104,\n",
            " 'Loss/regularization_loss': 0.7408641,\n",
            " 'Loss/total_loss': 0.92728466,\n",
            " 'learning_rate': 0.039992537}\n",
            "I0930 07:28:44.321338 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.11524951,\n",
            " 'Loss/localization_loss': 0.07117104,\n",
            " 'Loss/regularization_loss': 0.7408641,\n",
            " 'Loss/total_loss': 0.92728466,\n",
            " 'learning_rate': 0.039992537}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.442s\n",
            "I0930 07:29:28.464335 139903992600448 model_lib_v2.py:707] Step 2300 per-step time 0.442s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11368196,\n",
            " 'Loss/localization_loss': 0.0688728,\n",
            " 'Loss/regularization_loss': 0.7387107,\n",
            " 'Loss/total_loss': 0.9212655,\n",
            " 'learning_rate': 0.03998321}\n",
            "I0930 07:29:28.464692 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.11368196,\n",
            " 'Loss/localization_loss': 0.0688728,\n",
            " 'Loss/regularization_loss': 0.7387107,\n",
            " 'Loss/total_loss': 0.9212655,\n",
            " 'learning_rate': 0.03998321}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 2400 per-step time 0.416s\n",
            "I0930 07:30:10.122750 139903992600448 model_lib_v2.py:707] Step 2400 per-step time 0.416s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1287577,\n",
            " 'Loss/localization_loss': 0.07662967,\n",
            " 'Loss/regularization_loss': 0.7365547,\n",
            " 'Loss/total_loss': 0.94194204,\n",
            " 'learning_rate': 0.039970152}\n",
            "I0930 07:30:10.123154 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.1287577,\n",
            " 'Loss/localization_loss': 0.07662967,\n",
            " 'Loss/regularization_loss': 0.7365547,\n",
            " 'Loss/total_loss': 0.94194204,\n",
            " 'learning_rate': 0.039970152}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 2500 per-step time 0.423s\n",
            "I0930 07:30:52.449089 139903992600448 model_lib_v2.py:707] Step 2500 per-step time 0.423s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09744648,\n",
            " 'Loss/localization_loss': 0.05539568,\n",
            " 'Loss/regularization_loss': 0.7343623,\n",
            " 'Loss/total_loss': 0.88720447,\n",
            " 'learning_rate': 0.039953373}\n",
            "I0930 07:30:52.451536 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.09744648,\n",
            " 'Loss/localization_loss': 0.05539568,\n",
            " 'Loss/regularization_loss': 0.7343623,\n",
            " 'Loss/total_loss': 0.88720447,\n",
            " 'learning_rate': 0.039953373}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 2600 per-step time 0.421s\n",
            "I0930 07:31:34.595857 139903992600448 model_lib_v2.py:707] Step 2600 per-step time 0.421s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1374274,\n",
            " 'Loss/localization_loss': 0.07719751,\n",
            " 'Loss/regularization_loss': 0.73218024,\n",
            " 'Loss/total_loss': 0.9468051,\n",
            " 'learning_rate': 0.03993287}\n",
            "I0930 07:31:34.596365 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.1374274,\n",
            " 'Loss/localization_loss': 0.07719751,\n",
            " 'Loss/regularization_loss': 0.73218024,\n",
            " 'Loss/total_loss': 0.9468051,\n",
            " 'learning_rate': 0.03993287}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 2700 per-step time 0.463s\n",
            "I0930 07:32:20.874670 139903992600448 model_lib_v2.py:707] Step 2700 per-step time 0.463s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15624677,\n",
            " 'Loss/localization_loss': 0.10804132,\n",
            " 'Loss/regularization_loss': 0.7300478,\n",
            " 'Loss/total_loss': 0.9943359,\n",
            " 'learning_rate': 0.039908648}\n",
            "I0930 07:32:20.875102 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.15624677,\n",
            " 'Loss/localization_loss': 0.10804132,\n",
            " 'Loss/regularization_loss': 0.7300478,\n",
            " 'Loss/total_loss': 0.9943359,\n",
            " 'learning_rate': 0.039908648}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 2800 per-step time 0.417s\n",
            "I0930 07:33:02.586364 139903992600448 model_lib_v2.py:707] Step 2800 per-step time 0.417s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12218134,\n",
            " 'Loss/localization_loss': 0.06878041,\n",
            " 'Loss/regularization_loss': 0.7279023,\n",
            " 'Loss/total_loss': 0.918864,\n",
            " 'learning_rate': 0.039880715}\n",
            "I0930 07:33:02.586744 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.12218134,\n",
            " 'Loss/localization_loss': 0.06878041,\n",
            " 'Loss/regularization_loss': 0.7279023,\n",
            " 'Loss/total_loss': 0.918864,\n",
            " 'learning_rate': 0.039880715}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 2900 per-step time 0.429s\n",
            "I0930 07:33:45.448400 139903992600448 model_lib_v2.py:707] Step 2900 per-step time 0.429s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13994008,\n",
            " 'Loss/localization_loss': 0.07209003,\n",
            " 'Loss/regularization_loss': 0.72577435,\n",
            " 'Loss/total_loss': 0.93780446,\n",
            " 'learning_rate': 0.039849065}\n",
            "I0930 07:33:45.448909 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.13994008,\n",
            " 'Loss/localization_loss': 0.07209003,\n",
            " 'Loss/regularization_loss': 0.72577435,\n",
            " 'Loss/total_loss': 0.93780446,\n",
            " 'learning_rate': 0.039849065}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3000 per-step time 0.419s\n",
            "I0930 07:34:27.404474 139903992600448 model_lib_v2.py:707] Step 3000 per-step time 0.419s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12105978,\n",
            " 'Loss/localization_loss': 0.06613461,\n",
            " 'Loss/regularization_loss': 0.7236315,\n",
            " 'Loss/total_loss': 0.9108259,\n",
            " 'learning_rate': 0.03981372}\n",
            "I0930 07:34:27.404888 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.12105978,\n",
            " 'Loss/localization_loss': 0.06613461,\n",
            " 'Loss/regularization_loss': 0.7236315,\n",
            " 'Loss/total_loss': 0.9108259,\n",
            " 'learning_rate': 0.03981372}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3100 per-step time 0.479s\n",
            "I0930 07:35:15.248336 139903992600448 model_lib_v2.py:707] Step 3100 per-step time 0.479s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.103391945,\n",
            " 'Loss/localization_loss': 0.061413035,\n",
            " 'Loss/regularization_loss': 0.7215044,\n",
            " 'Loss/total_loss': 0.8863094,\n",
            " 'learning_rate': 0.03977467}\n",
            "I0930 07:35:15.248697 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.103391945,\n",
            " 'Loss/localization_loss': 0.061413035,\n",
            " 'Loss/regularization_loss': 0.7215044,\n",
            " 'Loss/total_loss': 0.8863094,\n",
            " 'learning_rate': 0.03977467}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3200 per-step time 0.423s\n",
            "I0930 07:35:57.578320 139903992600448 model_lib_v2.py:707] Step 3200 per-step time 0.423s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.122119635,\n",
            " 'Loss/localization_loss': 0.06598841,\n",
            " 'Loss/regularization_loss': 0.7193883,\n",
            " 'Loss/total_loss': 0.90749633,\n",
            " 'learning_rate': 0.03973194}\n",
            "I0930 07:35:57.578748 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.122119635,\n",
            " 'Loss/localization_loss': 0.06598841,\n",
            " 'Loss/regularization_loss': 0.7193883,\n",
            " 'Loss/total_loss': 0.90749633,\n",
            " 'learning_rate': 0.03973194}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3300 per-step time 0.417s\n",
            "I0930 07:36:39.247322 139903992600448 model_lib_v2.py:707] Step 3300 per-step time 0.417s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13528213,\n",
            " 'Loss/localization_loss': 0.095717035,\n",
            " 'Loss/regularization_loss': 0.71727556,\n",
            " 'Loss/total_loss': 0.94827473,\n",
            " 'learning_rate': 0.03968552}\n",
            "I0930 07:36:39.247745 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.13528213,\n",
            " 'Loss/localization_loss': 0.095717035,\n",
            " 'Loss/regularization_loss': 0.71727556,\n",
            " 'Loss/total_loss': 0.94827473,\n",
            " 'learning_rate': 0.03968552}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3400 per-step time 0.418s\n",
            "I0930 07:37:21.000393 139903992600448 model_lib_v2.py:707] Step 3400 per-step time 0.418s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.102061935,\n",
            " 'Loss/localization_loss': 0.04600382,\n",
            " 'Loss/regularization_loss': 0.71516985,\n",
            " 'Loss/total_loss': 0.8632356,\n",
            " 'learning_rate': 0.039635435}\n",
            "I0930 07:37:21.000775 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.102061935,\n",
            " 'Loss/localization_loss': 0.04600382,\n",
            " 'Loss/regularization_loss': 0.71516985,\n",
            " 'Loss/total_loss': 0.8632356,\n",
            " 'learning_rate': 0.039635435}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3500 per-step time 0.467s\n",
            "I0930 07:38:07.751196 139903992600448 model_lib_v2.py:707] Step 3500 per-step time 0.467s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.099003464,\n",
            " 'Loss/localization_loss': 0.052015577,\n",
            " 'Loss/regularization_loss': 0.7130686,\n",
            " 'Loss/total_loss': 0.86408764,\n",
            " 'learning_rate': 0.03958168}\n",
            "I0930 07:38:07.751620 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.099003464,\n",
            " 'Loss/localization_loss': 0.052015577,\n",
            " 'Loss/regularization_loss': 0.7130686,\n",
            " 'Loss/total_loss': 0.86408764,\n",
            " 'learning_rate': 0.03958168}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3600 per-step time 0.421s\n",
            "I0930 07:38:49.880110 139903992600448 model_lib_v2.py:707] Step 3600 per-step time 0.421s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08870171,\n",
            " 'Loss/localization_loss': 0.044262048,\n",
            " 'Loss/regularization_loss': 0.7109649,\n",
            " 'Loss/total_loss': 0.8439287,\n",
            " 'learning_rate': 0.039524276}\n",
            "I0930 07:38:49.880485 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.08870171,\n",
            " 'Loss/localization_loss': 0.044262048,\n",
            " 'Loss/regularization_loss': 0.7109649,\n",
            " 'Loss/total_loss': 0.8439287,\n",
            " 'learning_rate': 0.039524276}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3700 per-step time 0.414s\n",
            "I0930 07:39:31.233562 139903992600448 model_lib_v2.py:707] Step 3700 per-step time 0.414s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12996669,\n",
            " 'Loss/localization_loss': 0.059250828,\n",
            " 'Loss/regularization_loss': 0.70886517,\n",
            " 'Loss/total_loss': 0.8980827,\n",
            " 'learning_rate': 0.03946323}\n",
            "I0930 07:39:31.234069 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.12996669,\n",
            " 'Loss/localization_loss': 0.059250828,\n",
            " 'Loss/regularization_loss': 0.70886517,\n",
            " 'Loss/total_loss': 0.8980827,\n",
            " 'learning_rate': 0.03946323}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3800 per-step time 0.415s\n",
            "I0930 07:40:12.787238 139903992600448 model_lib_v2.py:707] Step 3800 per-step time 0.415s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11520121,\n",
            " 'Loss/localization_loss': 0.06732856,\n",
            " 'Loss/regularization_loss': 0.7067906,\n",
            " 'Loss/total_loss': 0.8893204,\n",
            " 'learning_rate': 0.039398547}\n",
            "I0930 07:40:12.793880 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.11520121,\n",
            " 'Loss/localization_loss': 0.06732856,\n",
            " 'Loss/regularization_loss': 0.7067906,\n",
            " 'Loss/total_loss': 0.8893204,\n",
            " 'learning_rate': 0.039398547}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 3900 per-step time 0.460s\n",
            "I0930 07:40:58.828374 139903992600448 model_lib_v2.py:707] Step 3900 per-step time 0.460s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.113685995,\n",
            " 'Loss/localization_loss': 0.06374698,\n",
            " 'Loss/regularization_loss': 0.7047052,\n",
            " 'Loss/total_loss': 0.88213813,\n",
            " 'learning_rate': 0.039330248}\n",
            "I0930 07:40:58.828779 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.113685995,\n",
            " 'Loss/localization_loss': 0.06374698,\n",
            " 'Loss/regularization_loss': 0.7047052,\n",
            " 'Loss/total_loss': 0.88213813,\n",
            " 'learning_rate': 0.039330248}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4000 per-step time 0.422s\n",
            "I0930 07:41:41.010032 139903992600448 model_lib_v2.py:707] Step 4000 per-step time 0.422s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10561739,\n",
            " 'Loss/localization_loss': 0.053197756,\n",
            " 'Loss/regularization_loss': 0.70263106,\n",
            " 'Loss/total_loss': 0.8614462,\n",
            " 'learning_rate': 0.039258346}\n",
            "I0930 07:41:41.010456 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.10561739,\n",
            " 'Loss/localization_loss': 0.053197756,\n",
            " 'Loss/regularization_loss': 0.70263106,\n",
            " 'Loss/total_loss': 0.8614462,\n",
            " 'learning_rate': 0.039258346}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4100 per-step time 0.432s\n",
            "I0930 07:42:24.205916 139903992600448 model_lib_v2.py:707] Step 4100 per-step time 0.432s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09757363,\n",
            " 'Loss/localization_loss': 0.047968455,\n",
            " 'Loss/regularization_loss': 0.7005564,\n",
            " 'Loss/total_loss': 0.8460985,\n",
            " 'learning_rate': 0.03918285}\n",
            "I0930 07:42:24.206459 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.09757363,\n",
            " 'Loss/localization_loss': 0.047968455,\n",
            " 'Loss/regularization_loss': 0.7005564,\n",
            " 'Loss/total_loss': 0.8460985,\n",
            " 'learning_rate': 0.03918285}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4200 per-step time 0.426s\n",
            "I0930 07:43:06.753958 139903992600448 model_lib_v2.py:707] Step 4200 per-step time 0.426s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10278877,\n",
            " 'Loss/localization_loss': 0.044761635,\n",
            " 'Loss/regularization_loss': 0.6984914,\n",
            " 'Loss/total_loss': 0.8460418,\n",
            " 'learning_rate': 0.03910377}\n",
            "I0930 07:43:06.754430 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.10278877,\n",
            " 'Loss/localization_loss': 0.044761635,\n",
            " 'Loss/regularization_loss': 0.6984914,\n",
            " 'Loss/total_loss': 0.8460418,\n",
            " 'learning_rate': 0.03910377}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4300 per-step time 0.430s\n",
            "I0930 07:43:49.776138 139903992600448 model_lib_v2.py:707] Step 4300 per-step time 0.430s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.099748455,\n",
            " 'Loss/localization_loss': 0.061501876,\n",
            " 'Loss/regularization_loss': 0.6964453,\n",
            " 'Loss/total_loss': 0.8576956,\n",
            " 'learning_rate': 0.039021127}\n",
            "I0930 07:43:49.776523 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.099748455,\n",
            " 'Loss/localization_loss': 0.061501876,\n",
            " 'Loss/regularization_loss': 0.6964453,\n",
            " 'Loss/total_loss': 0.8576956,\n",
            " 'learning_rate': 0.039021127}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4400 per-step time 0.455s\n",
            "I0930 07:44:35.213856 139903992600448 model_lib_v2.py:707] Step 4400 per-step time 0.455s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10825415,\n",
            " 'Loss/localization_loss': 0.047701024,\n",
            " 'Loss/regularization_loss': 0.6944219,\n",
            " 'Loss/total_loss': 0.8503771,\n",
            " 'learning_rate': 0.03893494}\n",
            "I0930 07:44:35.214242 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.10825415,\n",
            " 'Loss/localization_loss': 0.047701024,\n",
            " 'Loss/regularization_loss': 0.6944219,\n",
            " 'Loss/total_loss': 0.8503771,\n",
            " 'learning_rate': 0.03893494}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4500 per-step time 0.423s\n",
            "I0930 07:45:17.455369 139903992600448 model_lib_v2.py:707] Step 4500 per-step time 0.423s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.105107136,\n",
            " 'Loss/localization_loss': 0.055890314,\n",
            " 'Loss/regularization_loss': 0.6923927,\n",
            " 'Loss/total_loss': 0.85339016,\n",
            " 'learning_rate': 0.03884522}\n",
            "I0930 07:45:17.455757 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.105107136,\n",
            " 'Loss/localization_loss': 0.055890314,\n",
            " 'Loss/regularization_loss': 0.6923927,\n",
            " 'Loss/total_loss': 0.85339016,\n",
            " 'learning_rate': 0.03884522}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4600 per-step time 0.428s\n",
            "I0930 07:46:00.258220 139903992600448 model_lib_v2.py:707] Step 4600 per-step time 0.428s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09584574,\n",
            " 'Loss/localization_loss': 0.048963606,\n",
            " 'Loss/regularization_loss': 0.69038826,\n",
            " 'Loss/total_loss': 0.83519757,\n",
            " 'learning_rate': 0.03875198}\n",
            "I0930 07:46:00.258736 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.09584574,\n",
            " 'Loss/localization_loss': 0.048963606,\n",
            " 'Loss/regularization_loss': 0.69038826,\n",
            " 'Loss/total_loss': 0.83519757,\n",
            " 'learning_rate': 0.03875198}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4700 per-step time 0.415s\n",
            "I0930 07:46:41.694824 139903992600448 model_lib_v2.py:707] Step 4700 per-step time 0.415s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0645939,\n",
            " 'Loss/localization_loss': 0.039498214,\n",
            " 'Loss/regularization_loss': 0.6883856,\n",
            " 'Loss/total_loss': 0.7924777,\n",
            " 'learning_rate': 0.038655244}\n",
            "I0930 07:46:41.695211 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.0645939,\n",
            " 'Loss/localization_loss': 0.039498214,\n",
            " 'Loss/regularization_loss': 0.6883856,\n",
            " 'Loss/total_loss': 0.7924777,\n",
            " 'learning_rate': 0.038655244}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4800 per-step time 0.463s\n",
            "I0930 07:47:28.039208 139903992600448 model_lib_v2.py:707] Step 4800 per-step time 0.463s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.124061994,\n",
            " 'Loss/localization_loss': 0.07054949,\n",
            " 'Loss/regularization_loss': 0.6864014,\n",
            " 'Loss/total_loss': 0.8810129,\n",
            " 'learning_rate': 0.038555026}\n",
            "I0930 07:47:28.039565 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.124061994,\n",
            " 'Loss/localization_loss': 0.07054949,\n",
            " 'Loss/regularization_loss': 0.6864014,\n",
            " 'Loss/total_loss': 0.8810129,\n",
            " 'learning_rate': 0.038555026}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "INFO:tensorflow:Step 4900 per-step time 0.424s\n",
            "I0930 07:48:10.464323 139903992600448 model_lib_v2.py:707] Step 4900 per-step time 0.424s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.072447345,\n",
            " 'Loss/localization_loss': 0.027309353,\n",
            " 'Loss/regularization_loss': 0.68440944,\n",
            " 'Loss/total_loss': 0.78416616,\n",
            " 'learning_rate': 0.038451348}\n",
            "I0930 07:48:10.464731 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.072447345,\n",
            " 'Loss/localization_loss': 0.027309353,\n",
            " 'Loss/regularization_loss': 0.68440944,\n",
            " 'Loss/total_loss': 0.78416616,\n",
            " 'learning_rate': 0.038451348}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.418s\n",
            "I0930 07:48:52.314579 139903992600448 model_lib_v2.py:707] Step 5000 per-step time 0.418s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09848405,\n",
            " 'Loss/localization_loss': 0.055470403,\n",
            " 'Loss/regularization_loss': 0.6824322,\n",
            " 'Loss/total_loss': 0.8363866,\n",
            " 'learning_rate': 0.038344227}\n",
            "I0930 07:48:52.315008 139903992600448 model_lib_v2.py:708] {'Loss/classification_loss': 0.09848405,\n",
            " 'Loss/localization_loss': 0.055470403,\n",
            " 'Loss/regularization_loss': 0.6824322,\n",
            " 'Loss/total_loss': 0.8363866,\n",
            " 'learning_rate': 0.038344227}\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
            "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsgEPx9pfDH",
        "outputId": "57795864-a735-4810-e293-5b2afed82dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqTV2jGBpfDH",
        "outputId": "589b9a05-6db7-4d8c-ef4a-91bc8809de5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-08-01 01:30:55.699803: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0801 01:30:58.087321 140490526218112 model_lib_v2.py:1082] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0801 01:30:58.087514 140490526218112 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0801 01:30:58.087595 140490526218112 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0801 01:30:58.087681 140490526218112 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0801 01:30:58.087795 140490526218112 model_lib_v2.py:1103] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2021-08-01 01:30:58.093529: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-08-01 01:30:58.125008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-01 01:30:58.128085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-08-01 01:30:58.128332: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-01 01:30:58.136890: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-08-01 01:30:58.136979: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-08-01 01:30:58.139539: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-01 01:30:58.140290: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-01 01:30:58.143411: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-01 01:30:58.144154: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-08-01 01:30:58.144432: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-08-01 01:30:58.144547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-01 01:30:58.145228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-01 01:30:58.145833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-08-01 01:30:58.146164: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-08-01 01:30:58.146415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-01 01:30:58.147030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-08-01 01:30:58.147117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-01 01:30:58.147782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-01 01:30:58.148376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-08-01 01:30:58.148432: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-08-01 01:30:58.680093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-01 01:30:58.680153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-08-01 01:30:58.680171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-08-01 01:30:58.680381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-01 01:30:58.681075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-01 01:30:58.681753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-01 01:30:58.682345: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-08-01 01:30:58.682398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0801 01:30:58.705155 140490526218112 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0801 01:30:58.705394 140490526218112 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0801 01:30:58.705489 140490526218112 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0801 01:30:58.705563 140490526218112 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0801 01:30:58.706863 140490526218112 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0801 01:30:58.724401 140490526218112 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0801 01:31:02.554151 140490526218112 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0801 01:31:03.711641 140490526218112 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "I0801 01:31:06.414273 140490526218112 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet\n",
            "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-6\n",
            "I0801 01:31:06.415407 140490526218112 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/my_ssd_mobnet/ckpt-6\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "2021-08-01 01:31:06.490237: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-08-01 01:31:06.490826: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000185000 Hz\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\n",
            "    func_outputs = python_func(*func_args, **func_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\n",
            "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 982, in wrapper\n",
            "    user_requested=True,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/tmpf90oju2d.py\", line 20, in tf__compute_eval_dict\n",
            "    (losses_dict, prediction_dict) = ag__.converted_call(ag__.ld(_compute_losses_and_predictions_dicts), (ag__.ld(detection_model), ag__.ld(features), ag__.ld(labels), ag__.ld(add_regularization_loss)), None, fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 446, in converted_call\n",
            "    result = converted_f(*effective_args)\n",
            "  File \"/tmp/tmpzdy6qrva.py\", line 14, in tf___compute_losses_and_predictions_dicts\n",
            "    prediction_dict = ag__.converted_call(ag__.ld(model).predict, (ag__.ld(preprocessed_images), ag__.ld(features)[ag__.ld(fields).InputDataFields.true_image_shape]), dict(**ag__.converted_call(ag__.ld(model).get_side_inputs, (ag__.ld(features),), None, fscope)), fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/tmp2odgn33d.py\", line 49, in tf__predict\n",
            "    boxlist_list = ag__.converted_call(ag__.ld(self)._anchor_generator.generate, (ag__.ld(feature_map_spatial_dims),), dict(im_height=ag__.ld(image_shape)[1], im_width=ag__.ld(image_shape)[2]), fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/tmp_ri1pd8i.py\", line 26, in tf__generate\n",
            "    anchors_list = ag__.converted_call(ag__.ld(self)._generate, (ag__.ld(feature_map_shape_list),), dict(**ag__.ld(params)), fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/tmpp8ci79jy.py\", line 124, in tf___generate\n",
            "    ag__.for_stmt(ag__.converted_call(ag__.ld(zip), (ag__.ld(feature_map_shape_list), ag__.ld(self)._anchor_grid_info), None, fscope), None, loop_body, get_state_6, set_state_6, (), {'iterate_names': '(feat_shape, grid_info)'})\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 443, in for_stmt\n",
            "    _py_for_stmt(iter_, extra_test, body, None, None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 472, in _py_for_stmt\n",
            "    body(target)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 458, in protected_body\n",
            "    original_body(protected_iter)\n",
            "  File \"/tmp/tmpp8ci79jy.py\", line 80, in loop_body\n",
            "    (anchor_grid,) = ag__.converted_call(ag__.ld(ag).generate, (), dict(feature_map_shape_list=[(ag__.ld(feat_h), ag__.ld(feat_w))]), fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/tmp_ri1pd8i.py\", line 26, in tf__generate\n",
            "    anchors_list = ag__.converted_call(ag__.ld(self)._generate, (ag__.ld(feature_map_shape_list),), dict(**ag__.ld(params)), fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 444, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/tmp2kp3xnsz.py\", line 45, in tf___generate\n",
            "    anchors = ag__.converted_call(ag__.ld(tile_anchors), (ag__.ld(grid_height), ag__.ld(grid_width), ag__.ld(scales_grid), ag__.ld(aspect_ratios_grid), ag__.ld(self)._base_anchor_size, ag__.ld(self)._anchor_stride, ag__.ld(self)._anchor_offset), None, fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 446, in converted_call\n",
            "    result = converted_f(*effective_args)\n",
            "  File \"/tmp/tmpok0h1oe0.py\", line 18, in tf__tile_anchors\n",
            "    (x_centers, y_centers) = ag__.converted_call(ag__.ld(ops).meshgrid, (ag__.ld(x_centers), ag__.ld(y_centers)), None, fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 446, in converted_call\n",
            "    result = converted_f(*effective_args)\n",
            "  File \"/tmp/tmp5zx_n01n.py\", line 18, in tf__meshgrid\n",
            "    ygrid = ag__.converted_call(ag__.ld(tf).tile, (ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(y), ag__.ld(y_exp_shape)), None, fscope), ag__.ld(x_exp_shape)), None, fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 336, in converted_call\n",
            "    return _call_unconverted(f, args, kwargs, options, False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 464, in _call_unconverted\n",
            "    return f(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
            "    return target(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 195, in reshape\n",
            "    result = gen_array_ops.reshape(tensor, shape, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8398, in reshape\n",
            "    \"Reshape\", tensor=tensor, shape=shape, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 750, in _apply_op_helper\n",
            "    attrs=attr_protos, op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 601, in _create_op_internal\n",
            "    compute_device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3565, in _create_op_internal\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2042, in __init__\n",
            "    control_input_ops, op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1872, in _create_c_op\n",
            "    for name, attr_value in node_def.attr.items():\n",
            "  File \"/usr/lib/python3.7/_collections_abc.py\", line 744, in __iter__\n",
            "    yield (key, self._mapping[key])\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 115, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 90, in main\n",
            "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1157, in eval_continuously\n",
            "    global_step=global_step,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 932, in eager_eval_loop\n",
            "    compute_eval_dict, args=(features, labels))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1285, in run\n",
            "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2833, in call_for_each_replica\n",
            "    return self._call_for_each_replica(fn, args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 3608, in _call_for_each_replica\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\n",
            "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 764, in _initialize\n",
            "    *args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\n",
            "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\n",
            "    graph_function = self._create_graph_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3289, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1040, in func_graph_from_py_func\n",
            "    func_graph.variables = variables\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\", line 411, in __exit__\n",
            "    for inp, resource_type in _get_resource_inputs(op):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\", line 534, in _get_resource_inputs\n",
            "    reads, writes = utils.get_read_write_resource_inputs(op)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\", line 109, in get_read_write_resource_inputs\n",
            "    read_only_input_indices = op.get_attr(READ_ONLY_RESOURCE_INPUTS_ATTR)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2560, in get_attr\n",
            "    pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 294, in __init__\n",
            "    super(InvalidArgumentError, self).__init__(node_def, op, message,\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn1MHRE35pyC"
      },
      "outputs": [],
      "source": [
        "# Prevent GPU complete consumption\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try: \n",
        "        tf.config.experimental.set_virtual_device_configuration(\n",
        "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "    except RunTimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-6')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = \"/content/inventory_images/test/test_0.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vfzm-lebt6q"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tpzn1SMry1yK",
        "outputId": "cb4aa4a9-146b-474a-b5e9-c376454bbdb5"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=200,\n",
        "            min_score_thresh=.1,\n",
        "            agnostic_mode=False)\n",
        "cv2_imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d2LzcuG5pyF",
        "outputId": "80080b3d-905e-43f4-af54-81f10cb4827a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['detection_boxes', 'detection_scores', 'detection_classes', 'raw_detection_boxes', 'raw_detection_scores', 'detection_multiclass_scores', 'detection_anchor_indices', 'num_detections'])"
            ]
          },
          "execution_count": 77,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "detections.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#end"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4_YRZu7npfDH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
